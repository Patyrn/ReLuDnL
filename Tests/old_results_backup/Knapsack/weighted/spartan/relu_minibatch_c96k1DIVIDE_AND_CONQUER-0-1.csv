Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7674.81 460.90999999999985 357.1249999999977
0.0 1.0 7.148676633834839 89.2199999999998 394.57499999999936 269.25999999999976
0.0 2.0 13.620708465576172 163.7800000000002 280.37500000000045 181.26999999999862
0.0 3.0 18.85149097442627 221.3149999999996 492.420000000001 411.8299999999981
0.0 4.0 23.3863844871521 166.7449999999999 697.2500000000009 329.67499999999745
0.0 5.0 29.53865146636963 435.27999999999884 697.2500000000009 329.67499999999745
0.0 6.0 34.54021596908569 178.1249999999991 445.6550000000002 336.46999999999935
0.0 7.0 42.37230682373047 362.8850000000002 445.6550000000002 336.46999999999935
0.0 8.0 47.32416653633118 159.25 731.3050000000021 389.00500000000056
0.0 9.0 52.35952615737915 169.59499999999844 532.6450000000018 420.9900000000007
0.0 10.0 58.005797386169434 188.3149999999996 532.6450000000018 420.9900000000007
0.0 11.0 63.49956011772156 154.8599999999983 310.78500000000076 254.76499999999942
0.0 12.0 68.63828086853027 114.61000000000013 310.78500000000076 254.76499999999942
0.0 13.0 76.4614086151123 153.79999999999927 310.78500000000076 254.76499999999942
0.0 14.0 88.87000846862793 105.72999999999956 310.78500000000076 254.76499999999942
0.0 15.0 94.22962951660156 166.9399999999996 318.4300000000003 196.85499999999956
0.0 16.0 98.93618583679199 125.09499999999935 547.6250000000005 374.0649999999996
0.0 17.0 130.07671117782593 126.13499999999976 547.6250000000005 374.0649999999996
1.0 18.0 135.14045572280884 261.33000000000084 405.8650000000016 331.3550000000005
1.0 19.0 140.08386611938477 125.09499999999935 599.3850000000007 398.4300000000003
1.0 20.0 173.69954824447632 357.05499999999984 599.3850000000007 398.4300000000003
1.0 21.0 181.0011830329895 131.2800000000002 279.8999999999992 308.0749999999989
1.0 22.0 186.90844631195068 153.75500000000102 396.8899999999994 284.76499999999896
1.0 23.0 193.34521222114563 144.83000000000084 396.8899999999994 284.76499999999896
1.0 24.0 199.1106390953064 107.50499999999965 370.1299999999992 303.21499999999924
1.0 25.0 205.4380271434784 82.13500000000113 311.1950000000015 256.1149999999993
1.0 26.0 211.43664050102234 220.07999999999947 311.1950000000015 256.1149999999993
1.0 27.0 217.28297233581543 115.22499999999945 257.52500000000146 210.45499999999902
1.0 28.0 225.95925331115723 198.35499999999865 257.52500000000146 210.45499999999902
1.0 29.0 231.58139729499817 63.86500000000069 257.52500000000146 210.45499999999902
1.0 30.0 237.9837839603424 103.50499999999965 306.73999999999796 207.85999999999876
1.0 31.0 243.62422394752502 126.06500000000005 306.73999999999796 207.85999999999876
1.0 32.0 249.68115377426147 89.80999999999995 306.73999999999796 207.85999999999876
1.0 33.0 255.67980456352234 68.82499999999982 327.93000000000075 310.12499999999864
1.0 34.0 261.8011198043823 79.16999999999962 324.1200000000017 316.6100000000001
2.0 35.0 268.16288805007935 84.44499999999925 360.9899999999993 265.3950000000009
2.0 36.0 296.4242389202118 62.89500000000044 321.5999999999999 310.03499999999804
2.0 37.0 352.31150007247925 150.02000000000044 321.5999999999999 310.03499999999804
2.0 38.0 358.9719407558441 219.4499999999989 345.0499999999988 238.8849999999993
2.0 39.0 469.17169880867004 141.98500000000058 345.0499999999988 238.8849999999993
2.0 40.0 533.4447300434113 103.51999999999953 359.5699999999997 244.51000000000022
2.0 41.0 541.8613464832306 180.52499999999918 327.93000000000075 292.2049999999981
2.0 42.0 548.230343580246 92.13999999999942 345.3499999999999 261.15499999999975
2.0 43.0 554.9158983230591 120.13499999999931 345.3499999999999 261.15499999999975
2.0 44.0 560.8332550525665 100.33999999999924 412.9149999999995 443.3399999999979
2.0 45.0 570.2805752754211 57.42000000000144 535.6000000000004 506.0849999999991
2.0 46.0 696.4245300292969 421.3999999999992 535.6000000000004 506.0849999999991
2.0 47.0 824.512622833252 651.659999999999 535.6000000000004 506.0849999999991
2.0 48.0 835.1276326179504 82.80000000000109 535.6000000000004 506.0849999999991
2.0 49.0 844.0459492206573 98.06500000000051 535.6000000000004 506.0849999999991
2.0 50.0 869.547890663147 106.53499999999985 369.5499999999993 428.1599999999985
2.0 51.0 925.8840618133545 282.4249999999988 445.71999999999935 460.5199999999995
3.0 52.0 936.6238102912903 78.32500000000073 358.0649999999996 413.199999999998
3.0 53.0 947.5847539901733 106.97500000000036 395.13000000000056 292.38499999999885
3.0 54.0 955.913542509079 93.59999999999991 389.2649999999994 292.38499999999885
3.0 55.0 1046.6365931034088 136.00000000000045 389.2649999999994 292.38499999999885
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7764.099999999999 370.5649999999996 283.34000000000015
0.0 1.0 6.188399791717529 121.88000000000011 350.59000000000015 231.32500000000027
0.0 2.0 12.665006160736084 185.7899999999986 651.3850000000002 349.6399999999999
0.0 3.0 22.017385005950928 133.70499999999902 260.1749999999993 168.94000000000142
0.0 4.0 28.850447416305542 72.71000000000004 288.5749999999989 271.8349999999982
0.0 5.0 34.66029238700867 210.15499999999975 288.5749999999989 271.8349999999982
0.0 6.0 40.53364825248718 110.79999999999927 279.6949999999997 231.20999999999913
0.0 7.0 57.294901609420776 259.8599999999997 279.6949999999997 231.20999999999913
0.0 8.0 70.64052605628967 87.40500000000065 310.9500000000003 205.6550000000011
0.0 9.0 87.41463947296143 151.77999999999975 308.5949999999998 205.6550000000011
0.0 10.0 98.77033019065857 203.48999999999933 308.5949999999998 205.6550000000011
0.0 11.0 121.06662011146545 95.07500000000073 476.2949999999996 471.1049999999991
0.0 12.0 135.06671571731567 130.09499999999935 476.2949999999996 471.1049999999991
0.0 13.0 153.91173028945923 246.83000000000084 476.2949999999996 471.1049999999991
0.0 14.0 171.72191500663757 503.8599999999992 476.2949999999996 471.1049999999991
0.0 15.0 191.85337686538696 395.87999999999965 476.2949999999996 471.1049999999991
0.0 16.0 201.22098517417908 62.42499999999927 356.400000000001 250.46499999999924
0.0 17.0 207.13826727867126 36.85499999999956 356.400000000001 250.46499999999924
1.0 18.0 220.6251196861267 251.53499999999804 356.400000000001 250.46499999999924
1.0 19.0 225.7362768650055 62.42499999999927 356.400000000001 250.46499999999924
1.0 20.0 241.56556034088135 306.6449999999991 356.400000000001 250.46499999999924
1.0 21.0 249.05988597869873 225.5749999999989 520.2950000000001 650.5999999999985
1.0 22.0 259.66921520233154 175.6299999999992 399.3550000000005 451.25000000000045
1.0 23.0 399.1591143608093 254.4000000000001 399.3550000000005 451.25000000000045
1.0 24.0 656.059769153595 65.65500000000065 388.83999999999924 387.2299999999991
1.0 25.0 894.1611652374268 135.75999999999976 338.25 281.09499999999844
1.0 26.0 1231.0109515190125 167.5 338.25 281.09499999999844
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7718.220000000001 465.3250000000007 272.7699999999991
0.0 1.0 6.904680967330933 181.16500000000087 440.97000000000116 254.17999999999938
0.0 2.0 12.73913049697876 86.1850000000004 624.5449999999996 315.3900000000003
0.0 3.0 18.214505910873413 107.21499999999924 453.47000000000025 409.3299999999995
0.0 4.0 23.473308563232422 121.61000000000149 413.2599999999993 324.7099999999991
0.0 5.0 27.98371410369873 203.53999999999905 413.2599999999993 324.7099999999991
0.0 6.0 33.01031446456909 95.48499999999967 339.92500000000064 460.0049999999992
0.0 7.0 38.307570457458496 345.855 339.92500000000064 460.0049999999992
0.0 8.0 43.609151124954224 77.56500000000051 341.7600000000007 334.0100000000007
0.0 9.0 48.87600660324097 171.92999999999938 393.65500000000156 433.6049999999991
0.0 10.0 54.369786977767944 232.2150000000006 393.65500000000156 433.6049999999991
0.0 11.0 59.90687680244446 126.98000000000047 314.81500000000096 334.0100000000007
0.0 12.0 65.19729590415955 79.15499999999929 314.81500000000096 334.0100000000007
0.0 13.0 70.87335085868835 146.2199999999998 314.81500000000096 334.0100000000007
0.0 14.0 76.07685804367065 162.04500000000053 314.81500000000096 334.0100000000007
0.0 15.0 81.32289171218872 242.79000000000042 327.7600000000016 350.28000000000065
0.0 16.0 86.36712169647217 53.13999999999851 359.5549999999994 331.2850000000012
0.0 17.0 95.74674201011658 69.84499999999935 359.5549999999994 331.2850000000012
1.0 18.0 101.07687044143677 242.79000000000042 321.43000000000075 350.28000000000065
1.0 19.0 106.25493907928467 53.13999999999851 359.5549999999994 331.2850000000012
1.0 20.0 111.87671327590942 260.0050000000001 359.5549999999994 331.2850000000012
1.0 21.0 117.81575679779053 126.19999999999982 352.3200000000015 288.9900000000007
1.0 22.0 123.16375231742859 155.92000000000007 429.3000000000011 384.1650000000004
1.0 23.0 135.6080141067505 252.49000000000024 429.3000000000011 384.1650000000004
1.0 24.0 141.40596842765808 86.83000000000175 392.03999999999996 379.2350000000001
1.0 25.0 146.74315214157104 93.58500000000095 378.2600000000007 364.94500000000016
1.0 26.0 154.05955982208252 251.20500000000038 378.2600000000007 364.94500000000016
1.0 27.0 159.27179479599 89.17999999999938 406.85499999999956 315.6049999999991
1.0 28.0 180.6810700893402 340.24999999999955 406.85499999999956 315.6049999999991
1.0 29.0 186.02169632911682 59.01000000000022 406.85499999999956 315.6049999999991
1.0 30.0 191.11387753486633 87.38499999999931 375.34499999999935 356.6149999999998
1.0 31.0 196.37125611305237 172.89499999999907 375.34499999999935 356.6149999999998
1.0 32.0 201.49801802635193 56.715000000000146 375.34499999999935 356.6149999999998
1.0 33.0 206.71201348304749 71.88999999999987 568.6499999999992 354.4600000000005
1.0 34.0 224.93663954734802 213.76999999999998 417.2500000000002 270.2449999999999
2.0 35.0 243.19093298912048 213.76999999999998 417.2500000000002 270.2449999999999
2.0 36.0 251.26013159751892 56.68999999999778 546.9750000000001 308.16000000000076
2.0 37.0 256.63774728775024 571.5999999999995 546.9750000000001 308.16000000000076
2.0 38.0 262.1859724521637 276.3300000000013 546.9750000000001 308.16000000000076
2.0 39.0 268.1154508590698 278.9449999999997 546.9750000000001 308.16000000000076
2.0 40.0 273.3810148239136 103.34500000000025 322.40499999999975 379.00999999999976
2.0 41.0 278.31663155555725 227.66000000000167 416.6049999999991 499.8850000000011
2.0 42.0 283.21787786483765 81.90999999999894 363.3600000000006 294.5249999999969
2.0 43.0 288.4145896434784 120.13499999999931 363.3600000000006 294.5249999999969
2.0 44.0 294.45459723472595 110.22499999999945 330.02 326.0100000000007
2.0 45.0 299.6424639225006 67.57999999999902 346.85499999999956 498.6949999999979
2.0 46.0 304.6726121902466 227.66500000000178 346.85499999999956 498.6949999999979
2.0 47.0 310.48201084136963 444.8099999999995 346.85499999999956 498.6949999999979
2.0 48.0 315.8054027557373 85.90499999999975 346.85499999999956 498.6949999999979
2.0 49.0 321.20381712913513 53.73999999999842 346.85499999999956 498.6949999999979
2.0 50.0 326.4729208946228 102.42499999999973 382.58999999999924 470.0199999999995
2.0 51.0 332.2890405654907 171.6900000000005 328.6999999999989 333.37500000000045
3.0 52.0 380.6913552284241 148.45500000000038 437.81500000000096 382.26499999999896
3.0 53.0 415.3396370410919 107.46499999999969 355.25999999999976 277.7399999999998
3.0 54.0 421.5792429447174 143.95499999999993 341.2599999999993 239.4399999999996
3.0 55.0 432.7672836780548 203.4650000000006 341.2599999999993 239.4399999999996
3.0 56.0 565.3702664375305 135.72500000000036 374.9600000000014 275.4200000000001
3.0 57.0 573.7602422237396 137.65499999999975 334.62500000000136 277.7399999999998
3.0 58.0 590.36767578125 119.31500000000051 346.1499999999992 294.5249999999978
3.0 59.0 597.2133753299713 259.4550000000004 346.1499999999992 294.5249999999978
3.0 60.0 613.1205012798309 163.37499999999818 346.1499999999992 294.5249999999978
3.0 61.0 620.9194238185883 54.42499999999882 346.1499999999992 294.5249999999978
3.0 62.0 628.9976921081543 98.14000000000033 358.7649999999994 265.4349999999995
3.0 63.0 666.4156186580658 103.16000000000031 440.0449999999996 476.0799999999995
3.0 64.0 693.5179932117462 88.72499999999945 438.8850000000002 473.5149999999999
3.0 65.0 777.6007676124573 68.58000000000038 438.8850000000002 473.5149999999999
3.0 66.0 948.2603454589844 192.04499999999916 438.8850000000002 473.5149999999999
3.0 67.0 1149.0401813983917 161.51999999999998 438.8850000000002 473.5149999999999
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7721.0599999999995 409.72000000000025 302.5249999999987
0.0 1.0 6.226752281188965 189.39499999999907 402.10499999999956 307.3999999999987
0.0 2.0 20.952555656433105 108.24499999999944 373.72500000000036 299.0
0.0 3.0 26.08312177658081 160.4050000000002 697.8850000000011 594.4500000000003
0.0 4.0 40.28061294555664 154.21000000000004 429.4399999999996 321.79499999999825
0.0 5.0 54.82640624046326 189.94000000000005 429.4399999999996 321.79499999999825
0.0 6.0 74.01973557472229 118.46499999999742 572.6049999999996 338.8150000000005
0.0 7.0 124.16867017745972 392.66499999999996 572.6049999999996 338.8150000000005
0.0 8.0 134.2803282737732 129.07999999999993 450.6900000000005 350.28000000000065
0.0 9.0 149.65019392967224 167.58499999999913 497.03000000000156 262.9549999999999
0.0 10.0 224.88622856140137 259.31500000000005 497.03000000000156 262.9549999999999
0.0 11.0 231.342205286026 89.26000000000022 457.66000000000076 552.6399999999985
0.0 12.0 241.34879350662231 343.9299999999994 457.66000000000076 552.6399999999985
0.0 13.0 254.73677563667297 166.6599999999994 457.66000000000076 552.6399999999985
0.0 14.0 263.0576286315918 387.4700000000007 457.66000000000076 552.6399999999985
0.0 15.0 279.8405349254608 493.6399999999994 457.66000000000076 552.6399999999985
0.0 16.0 287.68456625938416 63.90000000000009 699.0499999999993 262.08500000000004
0.0 17.0 632.6227037906647 429.8350000000014 699.0499999999993 262.08500000000004
1.0 18.0 652.4306557178497 207.14500000000044 699.0499999999993 262.08500000000004
1.0 19.0 666.0902841091156 63.90000000000009 729.190000000001 262.08500000000004
1.0 20.0 919.8255779743195 782.9299999999994 729.190000000001 262.08500000000004
1.0 21.0 927.0072824954987 150.02000000000044 428.27000000000044 433.04499999999916
1.0 22.0 965.3547005653381 213.1050000000032 428.27000000000044 433.04499999999916
1.0 23.0 997.6433825492859 185.58500000000004 428.27000000000044 433.04499999999916
1.0 24.0 1007.1263289451599 81.91499999999905 382.4800000000005 332.99999999999955
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7765.839999999998 333.94500000000244 294.0599999999986
0.0 1.0 7.968225002288818 125.19999999999891 323.7049999999995 252.60000000000082
0.0 2.0 15.071232318878174 93.46499999999969 341.77 260.02499999999964
0.0 3.0 21.65571093559265 121.51999999999953 316.1350000000007 216.53999999999905
0.0 4.0 70.2054660320282 65.65500000000065 355.4699999999998 296.3999999999987
0.0 5.0 74.87376236915588 159.60499999999956 355.4699999999998 296.3999999999987
0.0 6.0 81.30552887916565 81.29999999999927 307.92999999999984 187.05500000000075
0.0 7.0 92.45921349525452 321.3900000000003 307.92999999999984 187.05500000000075
0.0 8.0 101.76639413833618 85.17999999999938 300.8800000000001 190.96000000000095
0.0 9.0 112.56765842437744 131.19000000000005 363.2399999999998 209.72999999999956
0.0 10.0 134.69245314598083 103.01999999999998 363.2399999999998 209.72999999999956
0.0 11.0 142.21473860740662 95.07500000000073 363.9900000000007 201.16000000000076
0.0 12.0 155.5726125240326 95.59500000000025 363.9900000000007 201.16000000000076
0.0 13.0 182.48565006256104 134.82999999999993 363.9900000000007 201.16000000000076
0.0 14.0 203.16521692276 170.78000000000156 363.9900000000007 201.16000000000076
0.0 15.0 226.65705752372742 199.79000000000042 363.9900000000007 201.16000000000076
0.0 16.0 240.101886510849 47.854999999997744 368.3200000000006 190.96000000000095
0.0 17.0 428.1952118873596 37.54500000000007 368.3200000000006 190.96000000000095
1.0 18.0 621.1055958271027 214.23500000000058 368.3200000000006 190.96000000000095
1.0 19.0 761.1585469245911 42.48000000000002 370.20500000000084 190.96000000000095
1.0 20.0 914.0862944126129 275.8349999999996 370.20500000000084 190.96000000000095
1.0 21.0 1027.9910655021667 127.37999999999965 349.5400000000009 197.7400000000007
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7789.48 407.1300000000019 297.5799999999999
0.0 1.0 6.284459590911865 137.7700000000009 600.9999999999982 491.5750000000007
0.0 2.0 12.343684196472168 100.69499999999971 308.59000000000015 187.05500000000075
0.0 3.0 42.72127175331116 158.1850000000004 388.9549999999995 344.53999999999905
0.0 4.0 47.281875133514404 85.36499999999978 265.3249999999989 189.5
0.0 5.0 69.98450231552124 92.8700000000008 265.3249999999989 189.5
0.0 6.0 77.9431676864624 121.91999999999916 277.6400000000003 308.79999999999836
0.0 7.0 315.55830550193787 254.1250000000009 277.6400000000003 308.79999999999836
0.0 8.0 385.58912086486816 62.095000000000255 302.9550000000004 252.0699999999997
0.0 9.0 391.8950273990631 124.8449999999998 294.96000000000095 235.19000000000005
0.0 10.0 398.6841514110565 132.18499999999813 294.96000000000095 235.19000000000005
0.0 11.0 406.58034777641296 89.26000000000022 285.6800000000003 200.36999999999944
0.0 12.0 413.23516607284546 98.24000000000069 285.6800000000003 200.36999999999944
0.0 13.0 424.97938895225525 162.02999999999975 285.6800000000003 200.36999999999944
0.0 14.0 436.1343913078308 93.51999999999998 285.6800000000003 200.36999999999944
0.0 15.0 449.95689487457275 194.99499999999944 285.6800000000003 200.36999999999944
0.0 16.0 456.2314646244049 82.53000000000065 314.81500000000096 307.1749999999988
0.0 17.0 462.8709497451782 55.664999999999964 314.81500000000096 307.1749999999988
1.0 18.0 484.9393229484558 212.2499999999991 314.81500000000096 307.1749999999988
1.0 19.0 491.4607365131378 82.53000000000065 314.81500000000096 307.1749999999988
1.0 20.0 511.2827651500702 200.75000000000045 314.81500000000096 307.1749999999988
1.0 21.0 642.1470534801483 100.33999999999924 381.44999999999936 350.28000000000065
1.0 22.0 939.1667973995209 149.04000000000087 335.94000000000096 196.5600000000004
1.0 23.0 1005.1756670475006 93.91000000000076 335.94000000000096 196.5600000000004
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7770.289999999998 401.87000000000126 293.3550000000005
0.0 1.0 8.327701568603516 139.37499999999864 346.9849999999997 275.84499999999844
0.0 2.0 18.736151933670044 155.04500000000007 456.83000000000084 241.97999999999956
0.0 3.0 27.70867085456848 103.89499999999998 408.5050000000001 340.5550000000003
0.0 4.0 36.13861560821533 62.56000000000131 406.34000000000106 313.8199999999997
0.0 5.0 44.02898955345154 316.3849999999993 406.34000000000106 313.8199999999997
0.0 6.0 52.677618741989136 94.33500000000004 352.8699999999985 246.14499999999816
0.0 7.0 63.413370847702026 308.02 352.8699999999985 246.14499999999816
0.0 8.0 73.36582779884338 67.224999999999 329.7850000000012 294.4499999999998
0.0 9.0 83.07652997970581 141.77000000000044 325.5600000000004 299.3899999999999
0.0 10.0 91.61037302017212 262.9849999999997 325.5600000000004 299.3899999999999
0.0 11.0 100.80692553520203 129.9350000000004 336.8500000000013 257.41499999999996
0.0 12.0 111.06211423873901 87.75500000000056 336.8500000000013 257.41499999999996
0.0 13.0 152.04327988624573 161.82999999999993 336.8500000000013 257.41499999999996
0.0 14.0 158.92297673225403 164.68500000000085 336.8500000000013 257.41499999999996
0.0 15.0 166.486634016037 247.85499999999956 336.8500000000013 257.41499999999996
0.0 16.0 173.63261485099792 45.27999999999838 342.90500000000065 271.91499999999996
0.0 17.0 181.47068524360657 54.68499999999949 342.90500000000065 271.91499999999996
1.0 18.0 190.55253100395203 199.98000000000002 342.90500000000065 271.91499999999996
1.0 19.0 198.95981240272522 45.27999999999838 345.96000000000095 241.02499999999873
1.0 20.0 207.45526885986328 256.5949999999998 345.96000000000095 241.02499999999873
1.0 21.0 217.19563508033752 90.15999999999985 380.7450000000008 410.91499999999814
1.0 22.0 230.42785668373108 143.57999999999902 522.6600000000003 324.04999999999836
1.0 23.0 246.02716898918152 315.77999999999975 522.6600000000003 324.04999999999836
1.0 24.0 268.979608297348 107.6299999999992 404.7350000000001 288.699999999998
1.0 25.0 5871.13006567955 175.06000000000085 447.20500000000175 290.4049999999979
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7722.6 408.5049999999992 315.3899999999976
0.0 1.0 7.171570539474487 218.29999999999927 365.3849999999993 255.52500000000055
0.0 2.0 13.367951154708862 80.28500000000076 375.78999999999996 306.5149999999999
0.0 3.0 19.77869439125061 110.03999999999996 295.62499999999955 277.2099999999991
0.0 4.0 26.128661394119263 111.50000000000091 346.650000000001 277.2099999999991
0.0 5.0 31.397916316986084 120.97000000000025 346.650000000001 277.2099999999991
0.0 6.0 38.20620536804199 167.6949999999997 357.19000000000005 304.4499999999989
0.0 7.0 44.10693335533142 364.7300000000009 357.19000000000005 304.4499999999989
0.0 8.0 50.093570709228516 92.55500000000075 344.6650000000009 304.4499999999989
0.0 9.0 56.531408071517944 182.8399999999997 324.65999999999985 304.4499999999989
0.0 10.0 62.75456094741821 115.53499999999894 324.65999999999985 304.4499999999989
0.0 11.0 68.77606129646301 89.26000000000022 336.15000000000055 311.56000000000085
0.0 12.0 74.78468775749207 100.13500000000022 336.15000000000055 311.56000000000085
0.0 13.0 80.60384607315063 149.37999999999965 336.15000000000055 311.56000000000085
0.0 14.0 85.51740026473999 103.56499999999915 336.15000000000055 311.56000000000085
0.0 15.0 91.50407671928406 221.59499999999935 316.27999999999975 284.6650000000009
0.0 16.0 96.69437956809998 113.53999999999996 375.6350000000011 324.8649999999989
0.0 17.0 102.0609519481659 80.85999999999876 375.6350000000011 324.8649999999989
1.0 18.0 107.56187748908997 224.13999999999987 375.6350000000011 324.8649999999989
1.0 19.0 113.03347444534302 113.53999999999996 375.6350000000011 324.8649999999989
1.0 20.0 118.76611328125 228.06999999999925 375.6350000000011 324.8649999999989
1.0 21.0 125.04302954673767 97.4350000000004 354.27000000000135 304.4499999999989
1.0 22.0 130.32842302322388 185.89999999999964 367.4300000000003 278.0500000000002
1.0 23.0 181.82572317123413 145.35500000000047 367.4300000000003 278.0500000000002
1.0 24.0 199.14326357841492 77.80499999999938 367.4300000000003 278.0500000000002
1.0 25.0 205.9541153907776 93.58500000000095 334.07500000000164 293.65999999999894
1.0 26.0 470.84100317955017 233.73499999999967 334.07500000000164 293.65999999999894
1.0 27.0 670.0646138191223 156.53000000000065 334.0550000000003 206.37999999999965
1.0 28.0 895.4295210838318 113.88999999999987 334.0550000000003 206.37999999999965
1.0 29.0 981.7517468929291 39.775000000000546 334.0550000000003 206.37999999999965
1.0 30.0 1069.7041828632355 100.20499999999993 289.6650000000009 293.65999999999894
