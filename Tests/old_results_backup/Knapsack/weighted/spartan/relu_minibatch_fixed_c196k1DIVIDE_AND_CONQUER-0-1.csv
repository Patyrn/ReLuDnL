Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 13099.68 67.1850000000004 84.63500000000113
0.0 1.0 10.5246901512146 116.1150000000016 67.1850000000004 84.63500000000113
0.0 2.0 20.582921266555786 44.05000000000018 85.27999999999975 122.39999999999873
0.0 3.0 67.37085771560669 24.1899999999996 292.9349999999995 351.46999999999935
0.0 4.0 128.9106571674347 102.1899999999996 505.46000000000004 396.2300000000005
0.0 5.0 145.698646068573 229.66499999999996 505.46000000000004 396.2300000000005
0.0 6.0 161.5589475631714 54.26500000000033 77.84500000000025 108.79500000000098
0.0 7.0 210.80142879486084 128.66499999999814 154.42499999999836 142.23000000000047
0.0 8.0 229.66867184638977 121.98000000000047 164.53999999999814 213.25
0.0 9.0 255.3052942752838 66.6150000000016 133.13500000000204 148.32500000000073
0.0 10.0 265.0626473426819 118.07499999999891 133.13500000000204 148.32500000000073
0.0 11.0 440.85804533958435 39.39999999999873 146.10499999999956 203.95499999999902
0.0 12.0 591.0163376331329 61.00500000000011 146.10499999999956 203.95499999999902
0.0 13.0 1534.8184127807617 33.17000000000098 146.10499999999956 203.95499999999902
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 13085.750000000002 116.72000000000025 104.94000000000051
0.0 1.0 12.91171646118164 109.46000000000004 116.72000000000025 104.94000000000051
0.0 2.0 74.73183250427246 58.48999999999978 133.72999999999956 129.16000000000076
0.0 3.0 118.94593524932861 39.534999999999854 108.89500000000044 124.88000000000011
0.0 4.0 128.77932024002075 33.92000000000007 108.89500000000044 122.14999999999964
0.0 5.0 144.14814949035645 71.12999999999829 108.89500000000044 122.14999999999964
0.0 6.0 154.2553300857544 42.900000000000546 45.50999999999976 54.36999999999898
0.0 7.0 163.95073413848877 115.19499999999971 99.17499999999927 73.86000000000058
0.0 8.0 313.8942611217499 34.199999999998 133.72999999999956 79.33999999999924
0.0 9.0 493.8697006702423 44.8149999999996 283.39500000000226 186.41499999999905
0.0 10.0 520.846583366394 151.1249999999991 283.39500000000226 186.41499999999905
0.0 11.0 551.4011011123657 48.10500000000047 106.42999999999938 128.9950000000008
0.0 12.0 580.3527779579163 62.36499999999978 106.42999999999938 128.9950000000008
0.0 13.0 600.407776594162 107.52000000000044 106.42999999999938 128.9950000000008
0.0 14.0 619.8945837020874 52.0649999999996 106.42999999999938 128.9950000000008
0.0 15.0 640.5506799221039 102.96999999999935 409.8750000000018 213.10999999999967
0.0 16.0 680.2658474445343 149.09000000000106 409.8750000000018 213.10999999999967
0.0 17.0 705.1457512378693 566.29 409.8750000000018 213.10999999999967
1.0 18.0 856.7349848747253 102.96999999999935 409.8750000000018 213.10999999999967
1.0 19.0 898.511953830719 149.09000000000106 409.8750000000018 213.10999999999967
1.0 20.0 1172.4238033294678 210.35999999999967 173.11499999999887 151.22000000000116
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 13084.45 103.26999999999953 138.76999999999953
0.0 1.0 11.35036826133728 135.3199999999997 103.26999999999953 138.76999999999953
0.0 2.0 53.677011489868164 13.199999999999818 114.47500000000036 89.34999999999854
0.0 3.0 63.900408029556274 41.36999999999989 135.5550000000003 266.8599999999997
0.0 4.0 85.9238498210907 59.95999999999822 113.57999999999993 107.44000000000051
0.0 5.0 119.12235832214355 98.6949999999988 113.57999999999993 107.44000000000051
0.0 6.0 148.62214255332947 61.970000000000255 207.64500000000135 143.9350000000004
0.0 7.0 170.12516117095947 283.5549999999994 182.85500000000047 168.59499999999935
0.0 8.0 205.50264430046082 34.64499999999953 113.09500000000025 99.85000000000127
0.0 9.0 230.18329310417175 78.74499999999807 167.41499999999996 131.3899999999985
0.0 10.0 250.23908114433289 100.51499999999942 167.41499999999996 131.3899999999985
0.0 11.0 263.50538444519043 94.22000000000025 131.8699999999999 114.46999999999844
0.0 12.0 276.8705177307129 122.17499999999927 131.8699999999999 114.46999999999844
0.0 13.0 294.4449243545532 156.3899999999985 131.8699999999999 114.46999999999844
0.0 14.0 312.0087058544159 87.69499999999971 131.8699999999999 114.46999999999844
0.0 15.0 328.4595263004303 79.54000000000087 114.1200000000008 89.01499999999942
0.0 16.0 337.8162536621094 62.595000000001164 114.1200000000008 89.01499999999942
0.0 17.0 347.9063913822174 63.14499999999953 114.1200000000008 89.01499999999942
1.0 18.0 361.73956274986267 79.54000000000087 114.1200000000008 89.01499999999942
1.0 19.0 371.3982529640198 62.595000000001164 114.1200000000008 89.01499999999942
1.0 20.0 383.912392616272 186.6800000000012 114.1200000000008 89.01499999999942
1.0 21.0 394.60406494140625 31.93999999999869 110.58000000000084 93.48000000000047
1.0 22.0 408.4172329902649 75.41499999999905 145.83000000000084 134.3100000000004
1.0 23.0 431.19052243232727 142.4549999999972 145.83000000000084 134.3100000000004
1.0 24.0 442.0815153121948 126.2549999999992 1750.0349999999999 1929.005
1.0 25.0 451.846479177475 119.39000000000033 302.54499999999916 341.02499999999964
1.0 26.0 469.160302400589 156.1850000000004 302.54499999999916 341.02499999999964
1.0 27.0 488.0047709941864 65.50499999999829 123.48499999999967 115.47999999999956
1.0 28.0 516.3471305370331 206.71999999999935 123.48499999999967 115.47999999999956
1.0 29.0 526.1790902614594 56.029999999999745 123.48499999999967 115.47999999999956
1.0 30.0 538.1645708084106 46.85000000000127 681.6449999999995 805.0
1.0 31.0 553.2581887245178 724.3200000000024 681.6449999999995 805.0
1.0 32.0 563.6720106601715 82.49499999999989 681.6449999999995 805.0
1.0 33.0 583.147910118103 96.1200000000008 186.33999999999924 197.61000000000058
1.0 34.0 623.1096563339233 28.104999999999563 185.3149999999987 197.61000000000058
2.0 35.0 647.1383469104767 28.104999999999563 185.3149999999987 197.61000000000058
2.0 36.0 670.0535008907318 73.29999999999927 185.3149999999987 197.61000000000058
2.0 37.0 745.6514642238617 94.76000000000022 185.3149999999987 197.61000000000058
2.0 38.0 806.862048625946 69.23000000000047 83.96500000000015 83.68499999999949
2.0 39.0 860.1638290882111 79.57500000000073 83.96500000000015 83.68499999999949
2.0 40.0 875.9924049377441 59.05000000000109 83.96500000000015 83.68499999999949
2.0 41.0 891.8105568885803 75.41499999999905 83.96500000000015 83.68499999999949
2.0 42.0 905.532999753952 46.85000000000127 611.1500000000015 732.6650000000009
2.0 43.0 938.6669497489929 667.4649999999992 611.1500000000015 732.6650000000009
2.0 44.0 961.4139668941498 31.93999999999869 83.96500000000015 64.04000000000087
2.0 45.0 1022.5611505508423 87.28999999999996 931.2800000000007 1306.8000000000002
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 13108.109999999999 101.25000000000182 65.82999999999993
0.0 1.0 17.13916778564453 150.6900000000005 101.25000000000182 65.82999999999993
0.0 2.0 30.626853704452515 49.68999999999869 117.22499999999945 98.69000000000051
0.0 3.0 54.049832344055176 68.31500000000051 147.41499999999996 156.6299999999992
0.0 4.0 87.00829458236694 75.97000000000116 195.17000000000007 205.82999999999993
0.0 5.0 191.81016206741333 140.00000000000182 195.17000000000007 205.82999999999993
0.0 6.0 221.35583019256592 111.57999999999811 206.8650000000016 199.5650000000005
0.0 7.0 483.87518286705017 569.0800000000008 553.5750000000016 482.21999999999935
0.0 8.0 542.6380546092987 66.28000000000065 157.36499999999978 186.23499999999967
0.0 9.0 568.40260887146 79.55500000000029 148.78999999999996 181.0099999999993
0.0 10.0 612.8054265975952 101.31500000000051 148.78999999999996 181.0099999999993
0.0 11.0 624.9522018432617 115.48000000000047 129.20499999999993 131.5600000000004
0.0 12.0 667.7108697891235 156.22999999999774 129.20499999999993 131.5600000000004
0.0 13.0 723.8577830791473 96.29500000000007 129.20499999999993 131.5600000000004
0.0 14.0 775.8354058265686 48.86999999999989 129.20499999999993 131.5600000000004
0.0 15.0 862.4141361713409 33.45499999999902 82.76500000000033 71.75
0.0 16.0 1034.5825066566467 101.85499999999956 82.76500000000033 71.75
