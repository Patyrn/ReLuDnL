Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7831.599999999999 133.26499999999896 86.99499999999898
0.0 1.0 27.197569608688354 102.88000000000056 231.07499999999982 82.09499999999935
0.0 2.0 218.10188055038452 73.46999999999935 216.625 76.51999999999907
0.0 3.0 315.01034450531006 315.00000000000045 216.625 76.51999999999907
0.0 4.0 444.68038511276245 156.48000000000093 115.95500000000038 160.79500000000007
0.0 5.0 461.66923809051514 136.0550000000003 86.95499999999947 110.89499999999953
0.0 6.0 479.8409626483917 249.92999999999984 86.95499999999947 110.89499999999953
0.0 7.0 529.9372909069061 197.36499999999978 86.95499999999947 110.89499999999953
0.0 8.0 542.0289506912231 79.15499999999929 86.95499999999947 110.89499999999953
0.0 9.0 553.3183975219727 132.0850000000005 100.65499999999975 97.85499999999956
0.0 10.0 564.4627828598022 102.84499999999935 100.65499999999975 97.85499999999956
0.0 11.0 575.6074454784393 100.63000000000102 100.65499999999975 97.85499999999956
0.0 12.0 586.2794947624207 362.4700000000007 100.65499999999975 97.85499999999956
0.0 13.0 632.595766544342 154.15000000000055 94.29499999999962 139.19999999999982
0.0 14.0 643.6213159561157 259.93499999999904 522.2600000000007 344.17500000000155
0.0 15.0 655.3151535987854 153.37500000000136 522.2600000000007 344.17500000000155
0.0 16.0 669.5667881965637 390.9200000000001 106.23000000000047 160.79500000000007
0.0 17.0 721.421549320221 179.51499999999987 106.23000000000047 160.79500000000007
1.0 18.0 737.886157989502 112.04499999999962 106.23000000000047 160.79500000000007
1.0 19.0 753.1716496944427 301.4150000000009 138.12999999999874 163.30499999999984
1.0 20.0 766.3419477939606 324.2200000000007 138.12999999999874 163.30499999999984
1.0 21.0 778.9030721187592 296.2550000000001 138.12999999999874 163.30499999999984
1.0 22.0 791.6114492416382 116.13999999999942 188.5299999999993 89.41999999999916
1.0 23.0 803.151775598526 92.02500000000146 188.5299999999993 89.41999999999916
1.0 24.0 827.4381182193756 64.72000000000025 124.20999999999913 148.79500000000007
1.0 25.0 853.2106053829193 113.48500000000013 124.20999999999913 148.79500000000007
1.0 26.0 871.7161853313446 241.30499999999984 132.43499999999904 103.85999999999922
1.0 27.0 905.1871418952942 105.55499999999938 124.85000000000036 85.11499999999978
1.0 28.0 970.2177939414978 152.88999999999942 129.7550000000001 85.91999999999916
1.0 29.0 982.9982500076294 178.0349999999994 129.7550000000001 85.91999999999916
1.0 30.0 1248.8814845085144 107.54499999999916 129.7550000000001 85.91999999999916
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7840.780000000002 97.77499999999918 70.1049999999982
0.0 1.0 14.658488750457764 117.6200000000008 109.86500000000024 90.41000000000076
0.0 2.0 23.895156860351562 58.10999999999967 127.56500000000051 113.80499999999938
0.0 3.0 59.94780659675598 291.0350000000003 127.56500000000051 113.80499999999938
0.0 4.0 69.68594861030579 50.64500000000044 123.40000000000055 102.86499999999887
0.0 5.0 113.94509768486023 89.46999999999935 220.30499999999938 94.36499999999978
0.0 6.0 142.91101551055908 97.33499999999958 220.30499999999938 94.36499999999978
0.0 7.0 163.17960166931152 215.82500000000073 220.30499999999938 94.36499999999978
0.0 8.0 179.81625509262085 47.62500000000091 220.30499999999938 94.36499999999978
0.0 9.0 250.61372685432434 132.0850000000005 336.7200000000007 388.5399999999986
0.0 10.0 261.1936218738556 453.369999999999 336.7200000000007 388.5399999999986
0.0 11.0 310.52976274490356 87.51000000000113 336.7200000000007 388.5399999999986
0.0 12.0 328.2582457065582 554.1500000000005 336.7200000000007 388.5399999999986
0.0 13.0 340.73333764076233 249.84000000000015 200.98999999999887 91.70499999999902
0.0 14.0 349.48163414001465 241.67999999999756 195.26999999999862 74.17999999999938
0.0 15.0 365.8769781589508 153.84500000000025 195.26999999999862 74.17999999999938
0.0 16.0 402.56177854537964 427.8749999999991 151.54999999999882 101.71500000000015
0.0 17.0 413.9781789779663 216.94999999999936 151.54999999999882 101.71500000000015
1.0 18.0 431.5158007144928 176.60499999999956 151.54999999999882 101.71500000000015
1.0 19.0 440.9952001571655 427.8749999999991 151.54999999999882 101.71500000000015
1.0 20.0 451.782781124115 543.1799999999998 151.54999999999882 101.71500000000015
1.0 21.0 463.2482359409332 410.7250000000013 151.54999999999882 101.71500000000015
1.0 22.0 473.5345103740692 141.70000000000027 200.5949999999989 90.875
1.0 23.0 484.11401176452637 173.01000000000022 200.5949999999989 90.875
1.0 24.0 492.9175806045532 77.1850000000004 391.5050000000001 141.28500000000076
1.0 25.0 501.23806405067444 186.39000000000078 391.5050000000001 141.28500000000076
1.0 26.0 508.7756600379944 585.2250000000004 391.5050000000001 141.28500000000076
1.0 27.0 517.3698987960815 153.35000000000082 324.31500000000096 113.17000000000098
1.0 28.0 524.8537130355835 161.8750000000009 120.94500000000016 149.8849999999993
1.0 29.0 632.8522646427155 199.1599999999994 120.94500000000016 149.8849999999993
1.0 30.0 646.7509572505951 156.00499999999965 120.94500000000016 149.8849999999993
1.0 31.0 671.1839241981506 304.8749999999982 207.85999999999967 116.19499999999971
1.0 32.0 753.6581544876099 556.4250000000002 207.85999999999967 116.19499999999971
1.0 33.0 764.871913433075 82.67499999999882 207.85999999999967 116.19499999999971
1.0 34.0 774.6735904216766 114.01499999999942 149.8399999999997 88.99000000000069
2.0 35.0 800.7882936000824 82.79999999999973 176.71000000000095 90.13999999999942
2.0 36.0 837.5437726974487 305.3149999999996 176.71000000000095 90.13999999999942
2.0 37.0 932.0854232311249 132.99500000000035 176.71000000000095 90.13999999999942
2.0 38.0 956.9164206981659 149.97500000000036 176.71000000000095 90.13999999999942
2.0 39.0 984.1822304725647 198.91500000000224 156.51999999999953 215.63500000000022
2.0 40.0 1020.0014040470123 164.50000000000045 156.51999999999953 215.63500000000022
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7830.579999999999 128.0200000000009 80.23499999999967
0.0 1.0 15.519469499588013 109.29499999999962 229.07499999999936 87.52999999999975
0.0 2.0 29.77455711364746 64.17000000000007 150.22000000000025 88.74000000000024
0.0 3.0 154.33918142318726 230.12000000000035 150.22000000000025 88.74000000000024
0.0 4.0 167.89070320129395 53.51499999999942 239.28000000000065 131.20499999999947
0.0 5.0 181.5578396320343 104.56999999999971 351.69499999999925 166.20000000000027
0.0 6.0 205.65221977233887 115.84999999999945 351.69499999999925 166.20000000000027
0.0 7.0 225.17402029037476 322.59499999999935 351.69499999999925 166.20000000000027
0.0 8.0 237.2462933063507 48.82000000000062 351.69499999999925 166.20000000000027
0.0 9.0 299.4616115093231 122.38000000000011 254.96500000000106 149.4350000000004
0.0 10.0 528.4636263847351 263.625 254.96500000000106 149.4350000000004
0.0 11.0 596.6045422554016 340.16000000000076 254.96500000000106 149.4350000000004
0.0 12.0 752.1428165435791 795.3499999999985 254.96500000000106 149.4350000000004
0.0 13.0 964.2154805660248 262.5899999999997 254.96500000000106 149.4350000000004
0.0 14.0 979.1912026405334 243.52999999999838 302.7900000000004 144.57000000000062
0.0 15.0 1156.0194652080536 136.30999999999995 275.4949999999999 142.1850000000004
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7842.009999999999 126.65000000000055 77.7549999999992
0.0 1.0 9.997131586074829 93.64000000000033 148.46000000000004 96.32999999999993
0.0 2.0 18.101730346679688 60.339999999999236 178.58000000000038 151.2549999999992
0.0 3.0 59.46754169464111 264.1100000000001 178.58000000000038 151.2549999999992
0.0 4.0 67.59480381011963 54.620000000000346 195.14999999999964 114.27000000000044
0.0 5.0 83.87541151046753 290.84000000000015 491.2099999999996 410.4850000000006
0.0 6.0 92.37398648262024 92.06499999999915 491.2099999999996 410.4850000000006
0.0 7.0 134.0608582496643 624.9500000000003 491.2099999999996 410.4850000000006
0.0 8.0 143.302170753479 131.2849999999994 491.2099999999996 410.4850000000006
0.0 9.0 152.18697476387024 115.19000000000051 159.81499999999915 87.52999999999975
0.0 10.0 158.68967723846436 108.78999999999951 159.81499999999915 87.52999999999975
0.0 11.0 174.4345953464508 111.92500000000064 159.81499999999915 87.52999999999975
0.0 12.0 181.1858570575714 388.9800000000005 159.81499999999915 87.52999999999975
0.0 13.0 232.03723335266113 261.8099999999995 150.3149999999987 87.52999999999975
0.0 14.0 239.23499751091003 251.45999999999913 238.00500000000056 86.17999999999938
0.0 15.0 249.61451649665833 136.78000000000065 238.00500000000056 86.17999999999938
0.0 16.0 257.4847106933594 399.85499999999956 284.9650000000006 100.21500000000015
0.0 17.0 264.14382147789 346.1050000000009 284.9650000000006 100.21500000000015
1.0 18.0 274.0095272064209 142.13500000000022 284.9650000000006 100.21500000000015
1.0 19.0 281.9412145614624 399.85499999999956 284.9650000000006 100.21500000000015
1.0 20.0 289.39759707450867 339.8450000000007 284.9650000000006 100.21500000000015
1.0 21.0 329.82823061943054 324.5799999999999 284.9650000000006 100.21500000000015
1.0 22.0 336.7514669895172 108.11499999999978 200.69500000000016 85.30999999999949
1.0 23.0 343.44096541404724 169.4099999999994 200.69500000000016 85.30999999999949
1.0 24.0 350.19794511795044 50.64500000000044 125.18000000000029 87.52999999999975
1.0 25.0 357.56621742248535 55.28500000000122 125.18000000000029 87.52999999999975
1.0 26.0 377.63943696022034 202.86000000000058 99.62999999999965 92.64000000000033
1.0 27.0 384.6485688686371 184.94999999999982 257.3449999999998 218.70999999999867
1.0 28.0 391.9458465576172 234.55499999999938 264.27500000000055 216.7899999999995
1.0 29.0 400.8903663158417 368.37999999999965 264.27500000000055 216.7899999999995
1.0 30.0 407.3792884349823 122.21499999999924 264.27500000000055 216.7899999999995
1.0 31.0 414.29676723480225 316.03499999999804 176.07999999999993 195.20499999999993
1.0 32.0 421.4367434978485 476.41499999999905 176.07999999999993 195.20499999999993
1.0 33.0 428.03366470336914 113.72000000000071 176.07999999999993 195.20499999999993
1.0 34.0 434.98385429382324 107.65999999999985 229.08000000000038 187.30000000000018
2.0 35.0 442.0168731212616 111.18000000000029 208.35000000000036 184.74499999999898
2.0 36.0 449.41144013404846 502.3150000000005 308.4799999999991 307.0149999999985
2.0 37.0 457.1688389778137 369.1299999999983 308.4799999999991 307.0149999999985
2.0 38.0 463.64534044265747 1113.605 308.4799999999991 307.0149999999985
2.0 39.0 470.4634668827057 368.9799999999991 291.0100000000011 336.4399999999996
2.0 40.0 482.0235571861267 599.7300000000014 291.0100000000011 336.4399999999996
2.0 41.0 488.6208071708679 187.9149999999995 246.82500000000073 203.53499999999894
2.0 42.0 509.8632981777191 1297.245 246.82500000000073 203.53499999999894
2.0 43.0 549.0046162605286 388.15499999999975 246.82500000000073 203.53499999999894
2.0 44.0 592.5149857997894 326.5400000000004 246.82500000000073 203.53499999999894
2.0 45.0 601.6325671672821 674.760000000002 246.82500000000073 203.53499999999894
2.0 46.0 614.7229804992676 298.4999999999982 233.1550000000002 246.83499999999913
2.0 47.0 667.2038071155548 422.0700000000011 233.1550000000002 246.83499999999913
2.0 48.0 695.718471288681 575.5450000000001 233.1550000000002 246.83499999999913
2.0 49.0 762.3668854236603 429.94999999999936 233.1550000000002 246.83499999999913
2.0 50.0 797.6224000453949 362.2499999999991 233.1550000000002 246.83499999999913
2.0 51.0 832.3011329174042 213.1249999999991 233.14499999999953 242.36999999999944
3.0 52.0 849.7504251003265 99.25499999999874 233.14499999999953 242.36999999999944
3.0 53.0 868.3747165203094 177.85499999999956 233.14499999999953 242.36999999999944
3.0 54.0 890.0314385890961 139.07500000000027 229.08000000000038 203.53499999999894
3.0 55.0 953.5685498714447 365.82499999999936 229.08000000000038 203.53499999999894
3.0 56.0 999.0281281471252 353.8649999999993 229.08000000000038 203.53499999999894
3.0 57.0 1021.6245539188385 171.31000000000085 268.4900000000007 193.5649999999987
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7831.83 106.24499999999944 77.71499999999924
0.0 1.0 10.199777603149414 117.65000000000009 106.63500000000067 142.84999999999945
0.0 2.0 20.270468711853027 47.9350000000004 106.63500000000022 64.31500000000051
0.0 3.0 35.76650547981262 217.04500000000053 106.63500000000022 64.31500000000051
0.0 4.0 45.62570238113403 48.32499999999982 165.45499999999993 124.3199999999988
0.0 5.0 56.02246880531311 117.22500000000127 125.05500000000029 76.75
0.0 6.0 66.11071729660034 91.56500000000051 125.05500000000029 76.75
0.0 7.0 104.9266562461853 294.8150000000005 125.05500000000029 76.75
0.0 8.0 115.35311555862427 81.41999999999916 125.05500000000029 76.75
0.0 9.0 130.62767887115479 124.9050000000002 96.51499999999896 123.42499999999836
0.0 10.0 161.35015892982483 103.35000000000036 96.51499999999896 123.42499999999836
0.0 11.0 176.46648812294006 127.51500000000078 96.51499999999896 123.42499999999836
0.0 12.0 188.89394664764404 447.61500000000024 96.51499999999896 123.42499999999836
0.0 13.0 294.3965094089508 165.01000000000022 86.70499999999947 90.19500000000016
0.0 14.0 303.81511521339417 156.9700000000007 95.41499999999951 96.96000000000004
0.0 15.0 317.8305525779724 107.51999999999953 95.41499999999951 96.96000000000004
0.0 16.0 354.67467164993286 284.8649999999989 160.1200000000017 83.70499999999993
0.0 17.0 362.816442489624 231.9600000000005 160.1200000000017 83.70499999999993
1.0 18.0 375.32527685165405 88.79499999999734 127.14000000000033 86.99499999999989
1.0 19.0 420.4386987686157 509.87500000000273 161.36999999999944 71.9699999999998
1.0 20.0 456.4871892929077 359.4050000000002 161.36999999999944 71.9699999999998
1.0 21.0 694.6281991004944 233.52000000000135 161.36999999999944 71.9699999999998
1.0 22.0 899.1394655704498 120.22499999999945 190.79500000000007 72.47999999999956
1.0 23.0 909.0161798000336 162.12999999999965 190.79500000000007 72.47999999999956
1.0 24.0 936.5720882415771 71.75500000000011 163.48500000000013 87.19999999999982
1.0 25.0 1346.659951210022 90.70500000000038 163.48500000000013 87.19999999999982
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7831.83 134.7999999999979 84.88500000000022
0.0 1.0 8.856561183929443 111.98000000000002 97.4099999999994 143.30000000000018
0.0 2.0 18.817001342773438 65.36999999999989 85.5949999999998 106.63999999999987
0.0 3.0 35.3966543674469 236.22000000000116 85.5949999999998 106.63999999999987
0.0 4.0 47.87783741950989 37.434999999999945 85.5949999999998 149.05000000000018
0.0 5.0 58.39639925956726 102.34000000000196 157.64000000000124 102.46499999999924
0.0 6.0 68.64732146263123 113.67499999999973 157.64000000000124 102.46499999999924
0.0 7.0 82.38312363624573 305.4849999999997 157.64000000000124 102.46499999999924
0.0 8.0 91.29212427139282 67.22000000000071 157.64000000000124 102.46499999999924
0.0 9.0 108.66304159164429 144.1600000000003 148.31500000000005 101.25500000000011
0.0 10.0 127.2891411781311 101.3400000000006 148.31500000000005 101.25500000000011
0.0 11.0 149.24236512184143 127.11500000000024 148.31500000000005 101.25500000000011
0.0 12.0 171.86930441856384 365.3900000000008 148.31500000000005 101.25500000000011
0.0 13.0 220.24246501922607 150.6800000000003 90.1599999999994 165.53999999999996
0.0 14.0 228.21923398971558 270.36999999999944 266.7749999999992 104.14999999999964
0.0 15.0 294.70155000686646 116.25500000000056 181.87000000000035 138.27000000000044
0.0 16.0 324.5586779117584 272.3349999999982 406.7599999999993 443.6050000000009
0.0 17.0 331.3690345287323 402.1550000000011 406.7599999999993 443.6050000000009
1.0 18.0 372.153847694397 453.0749999999998 406.7599999999993 443.6050000000009
1.0 19.0 862.6737847328186 368.7600000000002 565.4900000000007 592.1299999999992
1.0 20.0 870.9067525863647 646.539999999999 565.4900000000007 592.1299999999992
1.0 21.0 1175.953739643097 401.87000000000126 565.4900000000007 592.1299999999992
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7846.780000000001 102.13499999999976 85.14500000000044
0.0 1.0 17.215954780578613 137.77999999999884 229.26999999999998 170.22500000000036
0.0 2.0 32.53469133377075 58.30000000000018 252.12999999999965 329.1399999999985
0.0 3.0 80.23150658607483 298.5700000000006 252.12999999999965 329.1399999999985
0.0 4.0 104.85233688354492 55.72499999999991 186.5949999999998 142.23000000000002
0.0 5.0 114.88912653923035 169.22000000000025 259.84500000000116 185.55499999999938
0.0 6.0 130.83375811576843 109.33500000000004 259.84500000000116 185.55499999999938
0.0 7.0 141.3167803287506 475.92500000000064 259.84500000000116 185.55499999999938
0.0 8.0 153.73424625396729 94.15500000000065 259.84500000000116 185.55499999999938
0.0 9.0 170.2411892414093 116.13999999999942 405.5199999999977 472.9649999999997
0.0 10.0 181.60397458076477 460.7699999999995 405.5199999999977 472.9649999999997
0.0 11.0 214.0386950969696 247.69999999999982 405.5199999999977 472.9649999999997
0.0 12.0 227.30228924751282 538.3149999999996 405.5199999999977 472.9649999999997
0.0 13.0 239.03259897232056 281.9399999999987 305.6650000000009 388.74499999999944
0.0 14.0 250.8118863105774 299.83999999999924 228.4449999999997 96.24499999999989
0.0 15.0 261.8038091659546 154.35500000000093 228.4449999999997 96.24499999999989
0.0 16.0 409.77745628356934 413.5700000000015 331.7250000000008 542.9899999999998
0.0 17.0 428.0912277698517 312.0050000000001 331.7250000000008 542.9899999999998
1.0 18.0 438.14933466911316 651.5649999999991 331.7250000000008 542.9899999999998
1.0 19.0 452.3304715156555 413.5700000000015 327.0500000000002 542.9899999999998
1.0 20.0 466.93488001823425 418.3099999999995 327.0500000000002 542.9899999999998
1.0 21.0 499.6660957336426 343.320000000002 327.0500000000002 542.9899999999998
1.0 22.0 523.9258341789246 130.5300000000002 376.9850000000006 569.5550000000007
1.0 23.0 539.3696196079254 625.5299999999997 376.9850000000006 569.5550000000007
1.0 24.0 554.916957616806 106.45999999999867 234.1800000000003 329.1399999999985
1.0 25.0 581.2616548538208 91.34500000000025 234.1800000000003 329.1399999999985
1.0 26.0 592.8654112815857 277.5599999999995 194.7799999999993 158.03499999999894
1.0 27.0 605.457389831543 120.15500000000065 98.33499999999913 122.01000000000022
1.0 28.0 636.7038691043854 234.47500000000218 98.33499999999913 122.01000000000022
1.0 29.0 747.3528673648834 178.96499999999878 98.33499999999913 122.01000000000022
1.0 30.0 785.6027584075928 104.45000000000073 98.33499999999913 122.01000000000022
1.0 31.0 932.3021001815796 199.85499999999956 128.9650000000006 119.63000000000011
1.0 32.0 1880.5752818584442 565.8499999999999 128.9650000000006 119.63000000000011
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7843.089999999999 103.83499999999958 62.590000000000146
0.0 1.0 11.895342826843262 120.82499999999936 208.5949999999989 157.26500000000033
0.0 2.0 22.973707914352417 50.3100000000004 146.38499999999976 162.3499999999999
0.0 3.0 37.17419981956482 250.6450000000009 146.38499999999976 162.3499999999999
0.0 4.0 48.68033981323242 129.42500000000018 147.71499999999878 87.52999999999975
0.0 5.0 58.88959193229675 163.48500000000013 147.71499999999878 106.34999999999854
0.0 6.0 69.10538244247437 109.38999999999942 147.71499999999878 106.34999999999854
0.0 7.0 79.27994871139526 292.4500000000003 147.71499999999878 106.34999999999854
0.0 8.0 88.85011434555054 86.45499999999993 147.71499999999878 106.34999999999854
0.0 9.0 100.31263947486877 132.0850000000005 128.26999999999998 242.32999999999947
0.0 10.0 124.65439558029175 155.17999999999984 128.26999999999998 242.32999999999947
0.0 11.0 145.3957200050354 88.82999999999993 128.26999999999998 242.32999999999947
0.0 12.0 157.35493302345276 401.87499999999955 128.26999999999998 242.32999999999947
0.0 13.0 196.85014081001282 235.9100000000003 197.24999999999955 356.4500000000003
0.0 14.0 220.7751395702362 167.34000000000015 111.41000000000031 197.0599999999995
0.0 15.0 239.1813564300537 110.64499999999998 111.41000000000031 197.0599999999995
0.0 16.0 251.87812161445618 325.7600000000011 158.4300000000003 387.42999999999984
0.0 17.0 394.9810948371887 261.7049999999995 158.4300000000003 387.42999999999984
1.0 18.0 495.28852462768555 190.45499999999947 158.4300000000003 387.42999999999984
1.0 19.0 595.2016627788544 444.63500000000295 180.83499999999867 530.460000000001
1.0 20.0 692.6238794326782 446.18999999999824 180.83499999999867 530.460000000001
1.0 21.0 808.5155460834503 248.98999999999978 180.83499999999867 530.460000000001
1.0 22.0 894.6944658756256 131.0300000000002 147.4350000000004 241.25
1.0 23.0 1027.4864308834076 146.83499999999913 147.4350000000004 241.25
