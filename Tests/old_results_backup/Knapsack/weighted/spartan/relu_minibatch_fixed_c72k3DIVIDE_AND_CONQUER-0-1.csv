Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6322.6 168.474999999999 66.90499999999884
0.0 1.0 12.182839632034302 87.67499999999882 297.25500000000056 95.48499999999967
0.0 2.0 23.936611890792847 49.24000000000024 400.43499999999995 425.34999999999945
0.0 3.0 48.84908604621887 363.605 400.43499999999995 425.34999999999945
0.0 4.0 61.613041639328 88.34000000000015 394.0399999999995 500.5149999999999
0.0 5.0 292.5530033111572 70.84999999999991 378.80499999999984 184.92999999999893
0.0 6.0 306.7394938468933 612.3199999999997 378.80499999999984 184.92999999999893
0.0 7.0 598.3810927867889 333.42999999999984 378.80499999999984 184.92999999999893
0.0 8.0 638.9982154369354 59.150000000001 399.9499999999998 137.80500000000075
0.0 9.0 675.6102647781372 197.59499999999935 357.4000000000001 273.00000000000045
0.0 10.0 689.9762532711029 361.5050000000001 357.4000000000001 273.00000000000045
0.0 11.0 704.3782067298889 245.29500000000053 357.4000000000001 273.00000000000045
0.0 12.0 730.1833293437958 717.53 357.4000000000001 273.00000000000045
0.0 13.0 741.5059566497803 358.3750000000009 357.4000000000001 273.00000000000045
0.0 14.0 753.1237432956696 358.5700000000011 184.0099999999993 142.9699999999998
0.0 15.0 762.8299739360809 204.50000000000045 196.72499999999945 122.26999999999998
0.0 16.0 780.7463757991791 523.460000000001 277.13999999999896 236.19500000000107
0.0 17.0 797.9958069324493 247.78499999999985 277.13999999999896 236.19500000000107
1.0 18.0 809.0987372398376 122.17999999999984 245.6250000000009 129.61000000000013
1.0 19.0 828.9205753803253 518.8999999999996 303.32500000000164 289.34000000000015
1.0 20.0 847.6326730251312 389.8750000000009 303.32500000000164 289.34000000000015
1.0 21.0 968.6057598590851 346.9150000000009 303.32500000000164 289.34000000000015
1.0 22.0 1026.7439405918121 199.84000000000015 319.170000000001 308.5250000000001
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6336.970000000001 173.64000000000033 61.945000000000164
0.0 1.0 14.16122031211853 157.875 431.96500000000106 275.7149999999997
0.0 2.0 22.868067741394043 48.48000000000047 236.57999999999856 122.86000000000058
0.0 3.0 71.18155646324158 266.4700000000007 236.57999999999856 122.86000000000058
0.0 4.0 79.13277816772461 63.07500000000027 222.88999999999896 122.86000000000058
0.0 5.0 88.52018737792969 145.00999999999976 241.19999999999936 123.94999999999982
0.0 6.0 96.68616890907288 59.975000000000364 241.19999999999936 123.94999999999982
0.0 7.0 122.02344703674316 316.8250000000007 241.19999999999936 123.94999999999982
0.0 8.0 133.4205391407013 62.470000000001164 249.1500000000001 133.74500000000035
0.0 9.0 142.21290469169617 125.74000000000115 252.34500000000025 81.98500000000013
0.0 10.0 162.56389498710632 174.10500000000002 252.34500000000025 81.98500000000013
0.0 11.0 174.04068779945374 81.92500000000018 252.34500000000025 81.98500000000013
0.0 12.0 256.76341557502747 487.10000000000036 252.34500000000025 81.98500000000013
0.0 13.0 288.649338722229 261.2350000000001 252.34500000000025 81.98500000000013
0.0 14.0 297.99386072158813 183.12499999999955 165.45999999999958 88.91000000000031
0.0 15.0 306.65069460868835 232.95999999999913 267.02500000000055 207.51999999999953
0.0 16.0 404.9745376110077 507.7299999999991 158.27000000000044 258.6449999999995
0.0 17.0 464.5643262863159 181.86000000000013 158.27000000000044 258.6449999999995
1.0 18.0 490.7285430431366 194.13000000000056 174.80000000000018 171.36000000000013
1.0 19.0 552.8931875228882 312.75999999999976 195.45000000000027 144.52499999999964
1.0 20.0 566.4686117172241 410.52999999999975 195.45000000000027 144.52499999999964
1.0 21.0 610.4207491874695 338.6600000000003 195.45000000000027 144.52499999999964
1.0 22.0 654.1805503368378 135.48999999999978 183.29000000000087 158.91499999999996
1.0 23.0 702.1471755504608 261.6850000000004 183.29000000000087 158.91499999999996
1.0 24.0 754.4038922786713 76.63500000000022 184.44999999999936 140.1299999999992
1.0 25.0 802.7102632522583 88.27000000000044 184.44999999999936 140.1299999999992
1.0 26.0 851.1661353111267 178.78499999999985 184.44999999999936 140.1299999999992
1.0 27.0 869.4129025936127 101.79500000000053 186.2150000000006 89.07999999999947
1.0 28.0 884.0703785419464 68.67499999999927 175.9900000000007 106.28999999999951
1.0 29.0 914.8917326927185 185.73000000000093 175.9900000000007 106.28999999999951
1.0 30.0 930.6679251194 124.35999999999922 175.9900000000007 106.28999999999951
1.0 31.0 946.8741817474365 150.98500000000013 173.0300000000002 115.43000000000029
1.0 32.0 982.9937238693237 444.0400000000004 173.0300000000002 115.43000000000029
1.0 33.0 1037.7570581436157 69.42999999999847 240.17000000000007 64.28999999999996
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6321.240000000001 169.9600000000005 62.98999999999978
0.0 1.0 17.550654888153076 113.17000000000053 295.5700000000006 257.50500000000056
0.0 2.0 29.22319769859314 58.585000000000036 395.9249999999995 349.5100000000002
0.0 3.0 46.39092969894409 370.5499999999993 395.9249999999995 349.5100000000002
0.0 4.0 64.12445187568665 88.3400000000006 294.84499999999935 236.82500000000118
0.0 5.0 74.71818542480469 201.74999999999955 414.0149999999999 193.61000000000013
0.0 6.0 84.71176266670227 667.0350000000008 414.0149999999999 193.61000000000013
0.0 7.0 93.30154657363892 633.7249999999995 414.0149999999999 193.61000000000013
0.0 8.0 102.8997209072113 105.79499999999962 414.0149999999999 193.61000000000013
0.0 9.0 118.12021684646606 213.30499999999984 337.7950000000001 289.34000000000015
0.0 10.0 131.21364974975586 348.6250000000009 337.7950000000001 289.34000000000015
0.0 11.0 150.33981323242188 223.36499999999978 337.7950000000001 289.34000000000015
0.0 12.0 187.751770734787 736.2950000000005 337.7950000000001 289.34000000000015
0.0 13.0 198.64477372169495 356.1700000000005 337.7950000000001 289.34000000000015
0.0 14.0 209.81774735450745 293.4349999999995 219.5999999999999 118.09500000000025
0.0 15.0 220.15721988677979 147.13999999999987 218.65499999999975 120.99499999999944
0.0 16.0 256.2871539592743 418.380000000001 400.5199999999995 311.71000000000004
0.0 17.0 280.4377136230469 359.09500000000025 400.5199999999995 311.71000000000004
1.0 18.0 299.5241837501526 250.63499999999976 383.7850000000003 198.18000000000075
1.0 19.0 323.0198709964752 418.380000000001 383.7850000000003 198.18000000000075
1.0 20.0 347.9304962158203 459.2900000000004 383.7850000000003 198.18000000000075
1.0 21.0 374.380167722702 488.8050000000003 383.7850000000003 198.18000000000075
1.0 22.0 388.67244267463684 116.55999999999949 247.88999999999965 131.30499999999984
1.0 23.0 509.5331633090973 102.61500000000024 247.88999999999965 131.30499999999984
1.0 24.0 1033.4059567451477 76.96000000000049 277.7399999999998 117.05000000000064
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6336.970000000001 146.35999999999967 84.91500000000042
0.0 1.0 8.877192258834839 206.7550000000001 226.95999999999913 301.8550000000005
0.0 2.0 16.910044193267822 123.60500000000047 230.20499999999902 176.849999999999
0.0 3.0 24.166738510131836 356.14999999999964 230.20499999999902 176.849999999999
0.0 4.0 30.80980682373047 63.68499999999949 258.645 128.06500000000005
0.0 5.0 37.92870569229126 129.1199999999999 310.7049999999999 110.05500000000029
0.0 6.0 44.976357221603394 485.0049999999992 310.7049999999999 110.05500000000029
0.0 7.0 178.51970887184143 336.7199999999998 310.7049999999999 110.05500000000029
0.0 8.0 186.4686884880066 62.29499999999962 322.724999999999 64.41499999999951
0.0 9.0 192.81292033195496 130.8700000000008 248.52999999999975 60.48000000000002
0.0 10.0 222.60614681243896 101.01000000000022 248.52999999999975 60.48000000000002
0.0 11.0 229.56632351875305 197.25 248.52999999999975 60.48000000000002
0.0 12.0 236.10824704170227 612.5850000000005 248.52999999999975 60.48000000000002
0.0 13.0 252.7229127883911 272.6399999999999 248.52999999999975 60.48000000000002
0.0 14.0 258.5689630508423 204.14000000000033 248.52999999999975 60.48000000000002
0.0 15.0 264.9107873439789 117.05000000000018 165.8499999999999 89.91000000000076
0.0 16.0 270.9622986316681 469.08500000000004 170.69500000000062 108.95499999999993
0.0 17.0 276.67449021339417 183.94500000000016 170.69500000000062 108.95499999999993
1.0 18.0 282.65963912010193 204.07499999999936 236.64999999999873 180.04000000000133
1.0 19.0 288.55623388290405 451.02499999999964 179.72500000000036 157.02499999999964
1.0 20.0 296.65261697769165 159.10999999999967 179.72500000000036 157.02499999999964
1.0 21.0 310.0316767692566 222.16000000000076 179.72500000000036 157.02499999999964
1.0 22.0 316.5140812397003 122.38499999999931 186.35500000000047 112.34500000000025
1.0 23.0 349.87045788764954 160.66999999999916 186.35500000000047 112.34500000000025
1.0 24.0 356.43323707580566 82.27999999999975 209.70500000000038 153.37000000000035
1.0 25.0 362.89121174812317 119.80499999999984 209.70500000000038 153.37000000000035
1.0 26.0 369.4349503517151 169.5999999999999 167.79000000000087 89.91000000000076
1.0 27.0 375.72766184806824 138.98500000000013 207.57999999999993 129.11499999999978
1.0 28.0 382.34956216812134 156.3650000000007 185.60999999999967 104.60000000000036
1.0 29.0 388.46399784088135 189.45499999999947 185.60999999999967 104.60000000000036
1.0 30.0 394.87663888931274 113.25000000000045 185.60999999999967 104.60000000000036
1.0 31.0 401.5442416667938 184.39499999999998 176.63999999999942 106.23999999999978
1.0 32.0 407.97097420692444 457.145 176.63999999999942 106.23999999999978
1.0 33.0 414.06770181655884 78.37000000000035 238.46499999999924 173.9749999999999
1.0 34.0 422.2095527648926 109.01999999999953 263.56500000000005 137.39499999999998
2.0 35.0 431.9446392059326 109.01999999999953 263.56500000000005 137.39499999999998
2.0 36.0 440.07990622520447 430.52999999999975 202.67499999999973 89.91000000000076
2.0 37.0 466.4925513267517 114.9699999999998 202.67499999999973 89.91000000000076
2.0 38.0 474.7111625671387 111.71999999999935 185.60999999999967 89.91000000000076
2.0 39.0 483.0200026035309 84.97999999999956 270.03499999999894 103.88499999999976
2.0 40.0 1302.138160943985 98.42499999999973 270.03499999999894 103.88499999999976
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6339.04 174.50500000000056 66.1899999999996
0.0 1.0 9.407198905944824 163.66499999999996 179.97499999999945 124.48999999999978
0.0 2.0 16.439393043518066 55.90000000000009 159.08500000000004 227.92500000000064
0.0 3.0 26.4846613407135 207.5399999999995 159.08500000000004 227.92500000000064
0.0 4.0 33.57698845863342 41.11999999999989 158.88499999999976 169.19500000000016
0.0 5.0 41.91329598426819 160.21000000000095 153.7500000000009 96.22000000000025
0.0 6.0 49.572020292282104 196.7299999999991 153.7500000000009 96.22000000000025
0.0 7.0 57.834057569503784 280.619999999999 153.7500000000009 96.22000000000025
0.0 8.0 65.1877236366272 61.67499999999836 166.79500000000053 118.63000000000056
0.0 9.0 73.11318063735962 137.66500000000042 162.47000000000025 106.6550000000002
0.0 10.0 82.83766984939575 86.90999999999894 162.47000000000025 106.6550000000002
0.0 11.0 91.29459929466248 116.20499999999947 162.47000000000025 106.6550000000002
0.0 12.0 101.2304036617279 387.3649999999989 162.47000000000025 106.6550000000002
0.0 13.0 111.91999936103821 150.22500000000036 194.54500000000007 182.5550000000003
0.0 14.0 119.85959577560425 132.54000000000042 222.9300000000003 114.99000000000024
0.0 15.0 128.96412658691406 134.79499999999962 192.3800000000001 106.79000000000042
0.0 16.0 137.14674282073975 404.7149999999983 190.48500000000058 57.465000000000146
0.0 17.0 155.74776220321655 218.44500000000016 190.48500000000058 57.465000000000146
1.0 18.0 163.6616439819336 89.66000000000031 160.625 94.14000000000033
1.0 19.0 176.0061070919037 560.5450000000001 486.3649999999993 710.7549999999997
1.0 20.0 209.33931279182434 656.6350000000002 486.3649999999993 710.7549999999997
1.0 21.0 233.2189552783966 272.9549999999999 486.3649999999993 710.7549999999997
1.0 22.0 750.5042498111725 114.99500000000035 719.9099999999994 908.8600000000006
1.0 23.0 5909.008903026581 843.2049999999999 719.9099999999994 908.8600000000006
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6274.630000000001 165.45999999999958 89.21000000000095
0.0 1.0 9.796732187271118 203.37000000000035 216.75 140.24000000000024
0.0 2.0 17.916826963424683 76.32500000000027 234.36999999999944 332.97000000000025
0.0 3.0 29.227916955947876 292.2950000000005 234.36999999999944 332.97000000000025
0.0 4.0 38.477102518081665 91.83500000000095 222.44999999999936 212.02499999999918
0.0 5.0 50.722801208496094 117.26500000000033 265.9899999999998 90.2150000000006
0.0 6.0 60.79061031341553 70.85000000000082 185.35499999999956 148.86499999999978
0.0 7.0 70.04836773872375 292.0049999999992 185.35499999999956 148.86499999999978
0.0 8.0 77.90101480484009 57.59500000000071 325.35499999999956 104.70499999999993
0.0 9.0 161.8046588897705 200.17499999999973 308.619999999999 176.54999999999927
0.0 10.0 168.40774130821228 245.31000000000085 308.619999999999 176.54999999999927
0.0 11.0 272.43312191963196 267.8050000000003 308.619999999999 176.54999999999927
0.0 12.0 306.8408920764923 608.4000000000005 308.619999999999 176.54999999999927
0.0 13.0 341.80537605285645 232.3099999999995 280.7699999999995 179.20999999999958
0.0 14.0 347.496773481369 185.51000000000067 316.5950000000007 174.13499999999976
0.0 15.0 597.0201449394226 125.35499999999911 445.56500000000096 102.56500000000005
0.0 16.0 1869.7691576480865 346.6449999999995 305.6349999999993 179.58500000000004
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6284.28 165.5599999999995 64.62499999999955
0.0 1.0 11.614002466201782 121.1899999999996 181.36500000000024 81.02999999999975
0.0 2.0 20.312947273254395 55.90000000000009 178.82999999999947 93.60999999999967
0.0 3.0 30.004343032836914 278.6350000000002 178.82999999999947 93.60999999999967
0.0 4.0 38.10659098625183 45.5649999999996 170.97000000000025 89.38000000000011
0.0 5.0 47.6404595375061 106.17000000000053 124.46999999999889 84.75500000000011
0.0 6.0 56.51705241203308 201.70499999999902 124.46999999999889 84.75500000000011
0.0 7.0 73.94527459144592 337.40499999999884 124.46999999999889 84.75500000000011
0.0 8.0 84.2958824634552 72.40999999999985 322.3200000000006 97.32000000000062
0.0 9.0 93.74221801757812 192.35000000000036 649.7799999999997 808.2449999999994
0.0 10.0 102.16965842247009 1083.02 649.7799999999997 808.2449999999994
0.0 11.0 111.00634407997131 220.17500000000018 649.7799999999997 808.2449999999994
0.0 12.0 119.86989259719849 697.2650000000003 649.7799999999997 808.2449999999994
0.0 13.0 127.21604943275452 785.7899999999995 649.7799999999997 808.2449999999994
0.0 14.0 140.84239602088928 279.7049999999995 186.22500000000127 117.05000000000064
0.0 15.0 155.92121243476868 250.63499999999976 259.1849999999995 167.00000000000045
0.0 16.0 190.04359531402588 446.0900000000006 450.80000000000064 344.91000000000076
0.0 17.0 228.62908124923706 359.09500000000025 450.80000000000064 344.91000000000076
1.0 18.0 248.31496453285217 164.90499999999884 303.2999999999997 139.0349999999994
1.0 19.0 579.3868527412415 373.6200000000008 322.625 164.03999999999905
1.0 20.0 697.7896959781647 530.4300000000003 322.625 164.03999999999905
1.0 21.0 848.8060252666473 368.47499999999945 322.625 164.03999999999905
1.0 22.0 1593.1373567581177 114.99500000000035 314.5150000000008 158.3100000000004
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6318.39 149.37000000000035 82.10000000000036
0.0 1.0 12.640272378921509 54.905000000000655 181.61500000000024 69.19499999999971
0.0 2.0 24.167659044265747 56.70499999999902 166.08999999999924 84.62500000000045
0.0 3.0 46.458367586135864 273.39999999999964 166.08999999999924 84.62500000000045
0.0 4.0 56.5910747051239 44.49499999999989 161.51999999999907 97.53000000000065
0.0 5.0 68.60609912872314 135.1600000000003 259.3599999999992 78.74499999999989
0.0 6.0 80.5442566871643 434.9849999999992 259.3599999999992 78.74499999999989
0.0 7.0 104.84909987449646 268.4600000000005 259.3599999999992 78.74499999999989
0.0 8.0 121.77274942398071 57.59500000000071 329.179999999998 89.32999999999993
0.0 9.0 130.83130264282227 138.36499999999978 225.55000000000018 145.72000000000025
0.0 10.0 163.06494736671448 102.94500000000062 225.55000000000018 145.72000000000025
0.0 11.0 172.27700781822205 259.3750000000009 225.55000000000018 145.72000000000025
0.0 12.0 183.75748682022095 736.3249999999994 225.55000000000018 145.72000000000025
0.0 13.0 195.1933114528656 245.04000000000087 225.55000000000018 145.72000000000025
0.0 14.0 217.299001455307 302.4399999999996 327.8549999999991 117.57000000000062
0.0 15.0 362.7844853401184 248.7400000000007 382.74999999999955 183.1299999999992
0.0 16.0 385.815146446228 382.28499999999985 179.7150000000006 89.21000000000095
0.0 17.0 456.52410221099854 201.6999999999996 179.7150000000006 89.21000000000095
1.0 18.0 469.384756565094 116.81500000000005 375.9499999999998 226.1600000000003
1.0 19.0 481.114403963089 794.9549999999999 772.6499999999999 702.8100000000009
1.0 20.0 571.5339477062225 854.4999999999995 772.6499999999999 702.8100000000009
1.0 21.0 620.3513479232788 615.0999999999997 772.6499999999999 702.8100000000009
1.0 22.0 732.4994361400604 186.6550000000002 210.71999999999844 101.13500000000022
1.0 23.0 1064.35426902771 160.61500000000024 210.71999999999844 101.13500000000022
