Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6345.310000000001 267.4000000000001 280.71999999999935
0.0 1.0 14.9605393409729 118.69499999999971 278.07000000000016 280.71999999999935
0.0 2.0 27.61097526550293 97.27000000000044 278.6350000000002 291.97999999999956
0.0 3.0 40.75901126861572 114.17500000000064 287.02000000000044 249.05499999999938
0.0 4.0 75.39517951011658 182.20000000000027 442.30000000000064 271.69000000000005
0.0 5.0 96.21480298042297 299.59999999999945 442.30000000000064 271.69000000000005
0.0 6.0 117.69894790649414 141.3650000000007 325.2449999999981 264.8300000000004
0.0 7.0 166.86598920822144 341.24499999999944 325.2449999999981 264.8300000000004
0.0 8.0 178.54289269447327 78.33000000000084 287.02000000000044 267.3000000000002
0.0 9.0 187.48703169822693 151.77000000000044 370.4250000000002 280.32000000000016
0.0 10.0 196.71101260185242 279.875 370.4250000000002 280.32000000000016
0.0 11.0 214.31270456314087 57.46499999999969 268.4600000000005 285.81000000000085
0.0 12.0 228.68833446502686 69.63999999999987 268.4600000000005 285.81000000000085
0.0 13.0 257.89720034599304 143.7100000000005 268.4600000000005 285.81000000000085
0.0 14.0 281.0381615161896 142.97500000000036 268.4600000000005 285.81000000000085
0.0 15.0 385.9675085544586 225.54999999999973 268.4600000000005 285.81000000000085
0.0 16.0 409.3536751270294 51.805000000000746 316.8599999999997 271.6100000000001
0.0 17.0 435.91024470329285 63.51999999999998 316.8599999999997 271.6100000000001
1.0 18.0 723.3882296085358 257.3000000000002 316.8599999999997 271.6100000000001
1.0 19.0 751.7779564857483 51.805000000000746 316.8599999999997 271.6100000000001
1.0 20.0 867.4912850856781 340.3600000000006 316.8599999999997 271.6100000000001
1.0 21.0 884.7323939800262 110.78500000000076 317.1400000000008 271.6100000000001
1.0 22.0 905.1750950813293 72.71999999999935 253.48000000000002 268.1350000000002
1.0 23.0 955.2770230770111 247.24000000000024 253.48000000000002 268.1350000000002
1.0 24.0 996.0461792945862 135.6349999999993 316.0349999999994 339.3199999999988
1.0 25.0 1017.7742228507996 79.9099999999994 256.0899999999997 293.1349999999993
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6337.45 264.7249999999999 258.30499999999984
0.0 1.0 11.779945611953735 140.44000000000005 279.0550000000003 311.4449999999997
0.0 2.0 21.131197452545166 97.27000000000044 285.95500000000084 234.78500000000076
0.0 3.0 29.4544734954834 102.92500000000109 411.5550000000005 371.9350000000013
0.0 4.0 39.25061821937561 80.88499999999976 479.6850000000013 249.01999999999907
0.0 5.0 48.118629932403564 254.1300000000001 479.6850000000013 249.01999999999907
0.0 6.0 61.16014862060547 88.0300000000002 474.6700000000001 291.85000000000036
0.0 7.0 72.03108024597168 573.6800000000003 474.6700000000001 291.85000000000036
0.0 8.0 82.24052357673645 77.10999999999967 367.99000000000024 263.5649999999996
0.0 9.0 88.52468371391296 138.98999999999978 362.5849999999996 190.71499999999924
0.0 10.0 99.87164211273193 193.2549999999992 362.5849999999996 190.71499999999924
0.0 11.0 114.61196208000183 78.11000000000013 602.335 492.2949999999996
0.0 12.0 202.99153351783752 383.5050000000001 602.335 492.2949999999996
0.0 13.0 328.81007051467896 416.1150000000007 602.335 492.2949999999996
0.0 14.0 434.5149338245392 528.585 602.335 492.2949999999996
0.0 15.0 604.3666081428528 540.1249999999991 602.335 492.2949999999996
0.0 16.0 666.4359080791473 155.09000000000015 711.9600000000005 535.94
0.0 17.0 771.8846199512482 85.27999999999929 711.9600000000005 535.94
1.0 18.0 908.3364024162292 709.9500000000003 711.9600000000005 535.94
1.0 19.0 1017.2090790271759 207.72999999999956 731.0550000000007 567.5450000000001
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6321.449999999999 299.33500000000004 279.4100000000003
0.0 1.0 14.87015175819397 73.71000000000049 240.8900000000017 323.25499999999874
0.0 2.0 24.895394802093506 85.61999999999989 360.4900000000007 267.66499999999996
0.0 3.0 33.649189949035645 246.33999999999924 534.2449999999999 616.9800000000005
0.0 4.0 45.55646204948425 100.60000000000036 609.2549999999997 533.3449999999998
0.0 5.0 224.3637409210205 242.23499999999967 609.2549999999997 533.3449999999998
0.0 6.0 246.00765824317932 324.59000000000015 596.449999999998 492.02000000000044
0.0 7.0 298.8484890460968 595.3300000000013 596.449999999998 492.02000000000044
0.0 8.0 333.19216442108154 282.8349999999996 596.449999999998 492.02000000000044
0.0 9.0 350.1091344356537 176.83500000000004 306.8949999999995 288.5699999999988
0.0 10.0 431.7023537158966 178.10999999999967 306.8949999999995 288.5699999999988
0.0 11.0 504.35032653808594 90.12999999999965 307.28999999999905 334.38000000000056
0.0 12.0 627.7345740795135 71.41999999999916 307.28999999999905 334.38000000000056
0.0 13.0 776.7203669548035 114.75499999999965 307.28999999999905 334.38000000000056
0.0 14.0 918.5559780597687 191.14000000000033 307.28999999999905 334.38000000000056
0.0 15.0 1064.8993344306946 265.8399999999997 307.28999999999905 334.38000000000056
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6326.35 270.6399999999999 279.4100000000003
0.0 1.0 27.05074691772461 109.98000000000002 270.6399999999999 279.4100000000003
0.0 2.0 44.59652614593506 246.3400000000006 328.81500000000096 313.1249999999991
0.0 3.0 54.53583002090454 93.76000000000113 314.6700000000005 313.1249999999991
0.0 4.0 122.07734036445618 47.2199999999998 338.76499999999896 267.8049999999985
0.0 5.0 158.24630069732666 152.58000000000038 338.76499999999896 267.8049999999985
0.0 6.0 178.01665902137756 112.07000000000062 319.5450000000005 249.9999999999991
0.0 7.0 194.15849614143372 363.4600000000005 319.5450000000005 249.9999999999991
0.0 8.0 230.00935244560242 71.27000000000044 376.6449999999991 275.28499999999894
0.0 9.0 248.60706996917725 158.65000000000055 379.96000000000004 250.91499999999996
0.0 10.0 263.8382430076599 279.28000000000156 379.96000000000004 250.91499999999996
0.0 11.0 274.3271336555481 116.14000000000078 321.4200000000005 274.3850000000002
0.0 12.0 283.23599123954773 103.74000000000024 321.4200000000005 274.3850000000002
0.0 13.0 293.4352214336395 206.81999999999925 321.4200000000005 274.3850000000002
0.0 14.0 310.4403705596924 124.93499999999995 321.4200000000005 274.3850000000002
0.0 15.0 322.02114701271057 308.0049999999992 321.4200000000005 274.3850000000002
0.0 16.0 331.377347946167 61.0300000000002 316.8599999999997 244.0050000000001
0.0 17.0 341.19878816604614 37.04499999999962 316.8599999999997 244.0050000000001
1.0 18.0 350.52046251296997 239.7549999999983 316.8599999999997 244.0050000000001
1.0 19.0 359.65744733810425 61.0300000000002 316.8599999999997 244.0050000000001
1.0 20.0 369.35762429237366 326.40499999999975 316.8599999999997 244.0050000000001
1.0 21.0 380.0379421710968 138.82500000000027 316.8599999999997 244.0050000000001
1.0 22.0 389.51892042160034 131.04999999999927 284.9699999999998 267.8499999999999
1.0 23.0 398.0728704929352 289.3050000000012 284.9699999999998 267.8499999999999
1.0 24.0 407.58966732025146 97.76000000000022 410.2849999999994 363.8299999999999
1.0 25.0 418.6679060459137 155.14499999999953 396.3699999999985 363.8299999999999
1.0 26.0 431.27594661712646 174.8800000000001 396.3699999999985 363.8299999999999
1.0 27.0 441.023561000824 249.36499999999933 396.3699999999985 363.8299999999999
1.0 28.0 449.2306890487671 245.13999999999987 396.3699999999985 363.8299999999999
1.0 29.0 461.37103629112244 83.00999999999976 396.3699999999985 363.8299999999999
1.0 30.0 469.5127012729645 144.78499999999985 375.5949999999998 329.69499999999925
1.0 31.0 477.7786810398102 135.67000000000007 375.5949999999998 329.69499999999925
1.0 32.0 490.9502763748169 94.52500000000055 375.5949999999998 329.69499999999925
1.0 33.0 499.0894911289215 95.30500000000029 411.5500000000002 376.08500000000004
1.0 34.0 636.8792715072632 109.65499999999975 424.31500000000005 401.7850000000012
2.0 35.0 757.2719719409943 109.65499999999975 424.31500000000005 401.7850000000012
2.0 36.0 885.4835045337677 105.90500000000065 500.43500000000085 491.14500000000044
2.0 37.0 2569.6591651439667 338.4549999999995 500.43500000000085 491.14500000000044
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6336.970000000001 280.49500000000035 280.71999999999935
0.0 1.0 11.662470579147339 104.51500000000033 272.80000000000064 259.1749999999997
0.0 2.0 18.828190326690674 96.07500000000073 344.71499999999924 244.10500000000002
0.0 3.0 28.151428937911987 147.47999999999956 476.275000000001 436.54499999999916
0.0 4.0 40.121896743774414 71.43999999999915 412.00999999999976 323.1600000000003
0.0 5.0 186.69051456451416 127.65499999999975 412.00999999999976 323.1600000000003
0.0 6.0 192.42151927947998 318.3599999999997 508.88999999999896 400.4050000000002
0.0 7.0 217.28920817375183 471.1350000000002 508.88999999999896 400.4050000000002
0.0 8.0 231.69109344482422 183.525000000001 508.88999999999896 400.4050000000002
0.0 9.0 243.73764491081238 141.38500000000067 479.0100000000016 351.0999999999999
0.0 10.0 252.0126235485077 289.23 479.0100000000016 351.0999999999999
0.0 11.0 261.51372170448303 105.21499999999969 328.8250000000003 277.2300000000005
0.0 12.0 276.4202582836151 71.41999999999916 328.8250000000003 277.2300000000005
0.0 13.0 289.0073416233063 229.95500000000038 328.8250000000003 277.2300000000005
0.0 14.0 295.57459330558777 142.27999999999975 328.8250000000003 277.2300000000005
0.0 15.0 312.2032079696655 241.37999999999965 328.8250000000003 277.2300000000005
0.0 16.0 360.4795367717743 91.41499999999996 445.8000000000011 299.0650000000005
0.0 17.0 368.982666015625 57.98499999999967 445.8000000000011 299.0650000000005
1.0 18.0 380.11670684814453 225.14999999999964 445.8000000000011 299.0650000000005
1.0 19.0 442.69123792648315 106.75500000000011 533.7399999999996 351.94999999999936
1.0 20.0 450.3842911720276 534.1499999999996 533.7399999999996 351.94999999999936
1.0 21.0 464.15981936454773 99.92000000000098 398.4499999999998 357.97000000000025
1.0 22.0 548.9352262020111 231.60499999999956 571.8699999999985 277.40000000000055
1.0 23.0 556.5659143924713 420.90499999999975 571.8699999999985 277.40000000000055
1.0 24.0 653.3242332935333 183.4050000000002 566.8399999999992 372.8549999999991
1.0 25.0 745.4300661087036 62.940000000000055 533.875 359.7250000000008
1.0 26.0 757.5573320388794 387.9850000000001 533.875 359.7250000000008
1.0 27.0 770.6514616012573 145.7500000000009 614.3199999999983 342.66499999999996
1.0 28.0 791.4658091068268 402.7099999999989 614.3199999999983 342.66499999999996
1.0 29.0 800.0292406082153 264.8049999999994 614.3199999999983 342.66499999999996
1.0 30.0 810.4367246627808 116.48499999999967 392.3850000000002 367.355
1.0 31.0 862.9034764766693 249.15499999999975 392.3850000000002 367.355
1.0 32.0 931.8060693740845 140.95499999999993 392.3850000000002 367.355
1.0 33.0 959.7693562507629 115.06000000000085 392.3850000000002 367.355
1.0 34.0 972.6717567443848 128.875 443.1099999999997 363.59000000000106
2.0 35.0 984.8062832355499 128.875 443.1099999999997 363.59000000000106
2.0 36.0 994.0874600410461 65.92000000000007 511.3699999999999 421.4599999999996
2.0 37.0 1006.5412545204163 557.0050000000001 511.3699999999999 421.4599999999996
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6321.9 280.49500000000035 280.71999999999935
0.0 1.0 13.347076654434204 107.07999999999947 252.80999999999995 276.88499999999976
0.0 2.0 22.297528505325317 113.53500000000122 383.1399999999994 298.1100000000006
0.0 3.0 91.21886014938354 130.02500000000055 451.1950000000015 315.5249999999992
0.0 4.0 104.26384782791138 176.7100000000005 591.2200000000003 559.0249999999996
0.0 5.0 120.96253490447998 421.8450000000007 591.2200000000003 559.0249999999996
0.0 6.0 150.9232783317566 126.90999999999985 335.6750000000002 309.27999999999975
0.0 7.0 219.7430658340454 319.0450000000005 335.6750000000002 309.27999999999975
0.0 8.0 228.94409561157227 71.27000000000044 395.6150000000007 331.82000000000016
0.0 9.0 242.9434323310852 129.97500000000036 248.77499999999918 280.71999999999935
0.0 10.0 262.5731086730957 196.16000000000076 248.77499999999918 280.71999999999935
0.0 11.0 277.4043288230896 106.52500000000009 314.6700000000001 309.0699999999988
0.0 12.0 292.01071786880493 115.89500000000135 314.6700000000001 309.0699999999988
0.0 13.0 377.4366343021393 310.2800000000002 314.6700000000001 309.0699999999988
0.0 14.0 494.3227825164795 316.7999999999993 314.6700000000001 309.0699999999988
0.0 15.0 517.9137799739838 238.85999999999967 314.6700000000001 309.0699999999988
0.0 16.0 527.1514418125153 93.650000000001 528.3400000000001 428.8650000000007
0.0 17.0 537.52916264534 96.74499999999944 528.3400000000001 428.8650000000007
1.0 18.0 550.8240387439728 461.7249999999999 528.3400000000001 428.8650000000007
1.0 19.0 561.3143231868744 93.650000000001 528.3400000000001 428.8650000000007
1.0 20.0 579.358570098877 462.4850000000001 528.3400000000001 428.8650000000007
1.0 21.0 758.1027579307556 158.9399999999996 380.8899999999985 314.0149999999994
1.0 22.0 804.8896701335907 199.4649999999997 332.5900000000006 247.38999999999942
1.0 23.0 998.4420232772827 121.36999999999989 332.5900000000006 247.38999999999942
1.0 24.0 1477.9483892917633 71.16499999999951 333.81000000000085 346.8449999999989
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6321.240000000001 272.08500000000004 255.9300000000003
0.0 1.0 10.59342908859253 123.25999999999976 281.22000000000025 280.71999999999935
0.0 2.0 17.009169101715088 96.07500000000073 364.50500000000056 278.44000000000005
0.0 3.0 23.23022174835205 107.77500000000055 401.974999999999 291.5800000000004
0.0 4.0 30.486324548721313 212.87500000000045 843.7149999999992 789.0400000000004
0.0 5.0 44.815850257873535 757.7200000000007 843.7149999999992 789.0400000000004
0.0 6.0 54.175050258636475 190.07999999999947 461.6850000000004 335.69000000000005
0.0 7.0 98.99720501899719 512.7850000000003 461.6850000000004 335.69000000000005
0.0 8.0 111.83565402030945 102.57999999999993 252.4900000000007 266.3899999999994
0.0 9.0 121.88742446899414 118.33500000000004 322.8900000000008 255.9349999999995
0.0 10.0 147.24598217010498 357.8249999999998 322.8900000000008 255.9349999999995
0.0 11.0 185.4974594116211 65.26999999999998 262.75 290.579999999999
0.0 12.0 213.75388526916504 83.52500000000009 262.75 290.579999999999
0.0 13.0 278.4282605648041 180.6850000000004 262.75 290.579999999999
0.0 14.0 328.52470326423645 186.03000000000065 262.75 290.579999999999
0.0 15.0 358.2190294265747 177.11999999999898 262.75 290.579999999999
0.0 16.0 389.5555589199066 49.225000000000364 398.8500000000008 244.0050000000001
0.0 17.0 436.4538996219635 111.28500000000031 398.8500000000008 244.0050000000001
1.0 18.0 1583.1547725200653 305.99500000000035 398.8500000000008 244.0050000000001
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6322.48 272.08500000000004 280.71999999999935
0.0 1.0 22.684915781021118 86.25499999999965 272.6550000000002 244.92500000000018
0.0 2.0 31.279957056045532 72.50999999999976 319.5450000000005 272.11999999999944
0.0 3.0 9343.942450284958 147.47999999999956 491.59500000000116 398.1449999999995
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 6345.310000000001 280.49500000000035 280.71999999999935
0.0 1.0 14.211286544799805 122.90000000000009 271.37000000000035 259.90999999999985
0.0 2.0 24.305628299713135 203.83499999999958 386.52499999999964 341.0599999999995
0.0 3.0 35.33619451522827 142.9349999999995 405.23499999999876 327.56000000000085
0.0 4.0 47.525824546813965 113.12500000000045 467.0499999999993 369.08000000000084
0.0 5.0 69.75708508491516 249.88999999999987 467.0499999999993 369.08000000000084
0.0 6.0 79.86141395568848 174.8199999999988 451.4899999999998 344.5400000000004
0.0 7.0 105.79903960227966 377.1100000000001 451.4899999999998 344.5400000000004
0.0 8.0 123.29888153076172 98.08500000000049 451.4899999999998 344.5400000000004
0.0 9.0 139.8357162475586 121.35499999999911 297.5600000000004 236.25000000000045
0.0 10.0 151.93615102767944 152.650000000001 297.5600000000004 236.25000000000045
0.0 11.0 165.21381759643555 96.16999999999962 328.8250000000003 340.03500000000076
0.0 12.0 174.89048194885254 103.60500000000002 328.8250000000003 340.03500000000076
0.0 13.0 198.13299894332886 221.3499999999999 328.8250000000003 340.03500000000076
0.0 14.0 213.4741015434265 123.91000000000031 328.8250000000003 340.03500000000076
0.0 15.0 235.24548316001892 239.47999999999865 328.8250000000003 340.03500000000076
0.0 16.0 243.97826743125916 78.75500000000056 359.6899999999996 346.1149999999989
0.0 17.0 253.83992266654968 72.78999999999951 359.6899999999996 346.1149999999989
1.0 18.0 263.4339141845703 254.04499999999962 359.6899999999996 346.1149999999989
1.0 19.0 272.9208083152771 78.75500000000056 359.6899999999996 346.1149999999989
1.0 20.0 281.66157746315 251.70000000000027 359.6899999999996 346.1149999999989
1.0 21.0 291.1699216365814 81.72500000000036 380.8899999999985 353.6600000000003
1.0 22.0 334.2344334125519 209.26999999999998 413.91499999999996 357.57000000000016
1.0 23.0 352.46043968200684 370.99999999999864 413.91499999999996 357.57000000000016
1.0 24.0 399.5246889591217 56.7199999999998 413.91499999999996 357.57000000000016
1.0 25.0 431.65408730506897 116.98499999999967 365.86500000000024 353.6600000000003
1.0 26.0 451.44858288764954 180.23500000000013 365.86500000000024 353.6600000000003
1.0 27.0 574.6892330646515 229.45499999999902 365.86500000000024 353.6600000000003
1.0 28.0 634.028146982193 223.3299999999981 365.86500000000024 353.6600000000003
1.0 29.0 649.2138984203339 73.96499999999924 365.86500000000024 353.6600000000003
1.0 30.0 736.3775918483734 144.78499999999985 365.86500000000024 353.6600000000003
1.0 31.0 773.2329540252686 135.67000000000007 365.86500000000024 353.6600000000003
1.0 32.0 838.8496279716492 94.52500000000055 365.86500000000024 353.6600000000003
1.0 33.0 945.2222797870636 91.50000000000091 365.86500000000024 353.6600000000003
1.0 34.0 1128.0211629867554 66.31999999999971 474.3200000000006 357.57000000000016
