Method "Max Step Size Order" "Min Step Size Order" "Layer params" params_per_epoch leaky_slope "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER_GREEDY 0 -1 "[9, 5, 1]" 11 0.2 3000 10 571 1 True False 0.001
epochs "sub epochs" "run time" "val obj" "val regret" "test obj" "test regret" test_MSE pred_Ys
0 0 1 2 3 4 5 6 7 8 9
0 1 2 3 4 5 6 7 8 9 10
0 30.047927141189575 60.178062200546265 88.95313024520874 116.46099305152893 143.3370668888092 166.03566431999207 191.93784928321838 217.7263376712799 244.19819474220276 270.8625783920288
13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999
21.8650000000016 7.344999999999345 13.654999999999745 21.8650000000016 21.8650000000016 13.654999999999745 14.24499999999989 14.24499999999989 14.24499999999989 14.535000000000764 14.535000000000764
14293.72
60.55999999999949 38.474999999999454 40.3199999999988 40.3199999999988 40.3199999999988 41.10999999999967 63.524999999999636 63.524999999999636 63.524999999999636 46.99499999999989 46.99499999999989
22132.297959741314 22349.722348573723 22756.379026683622 22595.088197394824 22671.428026405916 22665.78022312874 22980.198917029513 22980.198917029513 22980.198917029513 22639.47835901084 22630.64321157289
Method "Max Step Size Order" "Min Step Size Order" "Layer params" params_per_epoch leaky_slope "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER_GREEDY 0 -1 "[9, 5, 1]" 11 0.2 3000 10 571 1 True False 0.001
epochs "sub epochs" "run time" "val obj" "val regret" "test obj" "test regret" test_MSE pred_Ys
0 0 1 2 3 4 5 6 7 8 9
0 1 2 3 4 5 6 7 8 9 10
0 24.6455237865448 44.34835600852966 63.94265961647034 84.00975847244263 103.98312211036682 124.15682578086853 143.77661108970642 161.75676012039185 179.38469457626343 197.40213251113892
13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999 13545.029999999999
69.06999999999971 118.11999999999989 118.11999999999989 118.11999999999989 118.11999999999989 118.11999999999989 118.11999999999989 118.11999999999989 118.11999999999989 118.11999999999989 118.11999999999989
14271.319999999998
78.14499999999771 89.86999999999898 89.86999999999898 89.86999999999898 89.86999999999898 89.86999999999898 89.86999999999898 89.86999999999898 89.86999999999898 89.86999999999898 89.86999999999898
22283.0829821836 22438.285760189923 22438.285760189923 22438.285760189923 22438.285760189923 22438.285760189923 22438.285760189923 22438.285760189923 22438.285760189923 22438.285760189923 22438.285760189923
Method "Max Step Size Order" "Min Step Size Order" "Layer params" params_per_epoch leaky_slope "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER_GREEDY 0 -1 "[9, 1, 1]" 12 0.2 3000 10 571 1 True False 0.001
epochs "sub epochs" "run time" "val obj" "val regret" "test obj" "test regret" test_MSE pred_Ys
0.0 0.0 0.0 13545.029999999999 83.95499999999993 14485.835000000001 87.699999999998 23335.99202995354
0.0 1.0 35.75384879112244 13545.029999999999 11.8799999999992 14485.835000000001 39.6299999999992 29023.583708602004
1.0 2.0 76.97590517997742 13545.029999999999 4.145000000000437 14485.835000000001 38.4399999999996 29022.744788365282
2.0 3.0 119.05948114395142 13545.029999999999 7.799999999999272 14485.835000000001 38.4399999999996 29023.041432519134
3.0 4.0 160.41431546211243 13545.029999999999 7.799999999999272 14485.835000000001 38.4399999999996 29022.862338568662
4.0 5.0 204.80115365982056 13545.029999999999 3.3150000000005093 14485.835000000001 38.4399999999996 29635.612249903825
5.0 6.0 247.3901698589325 13545.029999999999 3.3150000000005093 14485.835000000001 39.104999999998654 29325.02540809199
6.0 7.0 289.7810261249542 13545.029999999999 3.3150000000005093 14485.835000000001 38.4399999999996 29812.501514997795
7.0 8.0 332.313782453537 13545.029999999999 3.3150000000005093 14485.835000000001 38.4399999999996 29790.907119432846
8.0 9.0 372.9898679256439 13545.029999999999 3.3150000000005093 14485.835000000001 38.4399999999996 29790.907119432846
9.0 10.0 414.5218381881714 13545.029999999999 3.3150000000005093 14485.835000000001 38.4399999999996 29797.29504601123
