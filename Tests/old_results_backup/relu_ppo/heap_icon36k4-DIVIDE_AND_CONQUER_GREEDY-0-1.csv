Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER_GREEDY 0 -1 30000 10 571 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0 0 1 2 3 4 5 6 7 8 9
0 1 2 3 4 5 6 7 8 9 10
0 245.424907207489 455.898056268692 672.9285745620728 897.733226776123 1112.5577373504639 1330.5570147037506 1538.5195558071136 1760.2801938056946 1985.576206445694 2212.113904953003
-5974750.0
53650.0 41375.0 41375.0 41375.0 38525.0 41375.0 41375.0 41375.0 41375.0 41375.0 41375.0
21275.0 22250.0 21925.0 21925.0 22875.0 32950.0 32950.0 32950.0 32950.0 32950.0 32950.0
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER_GREEDY 0 -1 30000 10 571 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0 0 1 2 3 4 5 6 7 8 9
0 1 2 3 4 5 6 7 8 9 10
0 236.0576455593109 476.50646018981934 723.3320274353027 952.9132950305939 1179.6263909339905 1424.1551713943481 1651.3736262321472 1877.7078063488007 2115.317171573639 2355.3422813415527
-5976000.0
44450.0 50200.0 50200.0 47425.0 47425.0 47425.0 47425.0 47425.0 47425.0 47425.0 47425.0
25825.0 28925.0 28925.0 21275.0 21275.0 21275.0 21275.0 21275.0 21275.0 21275.0 21275.0
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER_GREEDY 0 -1 30000 10 571 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0 0 1 2 3 4 5 6 7 8 9
0 1 2 3 4 5 6 7 8 9 10
0 259.83382964134216 479.88372468948364 699.7100346088409 933.1475665569305 1145.4408874511719 1367.83594083786 1600.4600584506989 1816.289922952652 2045.878818511963 2270.474886417389
-5984950.0
59450.0 59450.0 59450.0 56150.0 56150.0 55700.0 55700.0 55700.0 53850.0 53850.0 57475.0
23275.0 27125.0 27125.0 29225.0 28150.0 27125.0 27125.0 27125.0 27125.0 27125.0 27125.0
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER_GREEDY 0 -1 30000 10 571 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0 0 1 2 3 4 5 6 7 8 9
0 1 2 3 4 5 6 7 8 9 10
0 246.43464922904968 468.78112602233887 685.3960518836975 900.4706721305847 1117.4112906455994 1331.6994471549988 1550.7431104183197 1782.7310328483582 2026.5084149837494 2246.2248249053955
-5976000.0
54625.0 47425.0 44300.0 59025.0 60175.0 50200.0 50200.0 50000.0 47425.0 47425.0 47425.0
27050.0 28150.0 32950.0 32950.0 32950.0 27125.0 27125.0 28125.0 28125.0 27125.0 27125.0
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER_GREEDY 0 -1 30000 10 571 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0 0 1 2 3 4 5 6 7 8 9
0 1 2 3 4 5 6 7 8 9 10
0 196.63304328918457 391.9979729652405 576.9489295482635 778.6809918880463 980.4474077224731 1183.5977549552917 1385.4641246795654 1588.5791108608246 1789.5293247699738 2002.7552301883698
-5980250.0
66350.0 68325.0 69525.0 69525.0 69525.0 69525.0 69525.0 69525.0 69525.0 57475.0 57475.0
22875.0 25500.0 25500.0 25500.0 25500.0 25500.0 25500.0 25500.0 25500.0 22875.0 22875.0
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER_GREEDY 0 -1 30000 10 571 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0 0 1 2 3 4 5 6 7 8 9
0 1 2 3 4 5 6 7 8 9 10
0 292.24557852745056 570.682451248169 848.6367542743683 1128.123916387558 1408.013934135437 1680.9282953739166 1961.7968232631683 2238.804030418396 2512.066605567932 2785.3721067905426
-5973150.0
55425.0 55425.0 57475.0 57475.0 57475.0 57475.0 57475.0 57475.0 57475.0 57475.0 57475.0
21925.0 21925.0 29225.0 29225.0 29225.0 29225.0 29225.0 29225.0 29225.0 29225.0 29225.0
