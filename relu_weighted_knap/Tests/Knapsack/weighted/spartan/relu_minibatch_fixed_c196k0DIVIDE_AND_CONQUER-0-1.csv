Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 13230.480000000003 90.9950000000008 91.60999999999967
0.0 1.0 13.578837156295776 44.70499999999993 90.9950000000008 91.60999999999967
0.0 2.0 25.34019923210144 36.54500000000098 90.9950000000008 91.60999999999967
0.0 3.0 36.82529306411743 40.43999999999778 90.9950000000008 91.60999999999967
0.0 4.0 55.52851462364197 173.6850000000004 125.40000000000055 192.92499999999927
0.0 5.0 87.89207530021667 107.27499999999964 174.52500000000055 155.69999999999982
0.0 6.0 117.7848732471466 127.11000000000149 523.2850000000008 4082.670000000002
0.0 7.0 130.195326089859 47.1299999999992 348.8700000000008 3520.0700000000006
0.0 8.0 1186.703830242157 183.64499999999953 1418.5349999999999 10667.564999999999
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 13243.859999999997 83.73500000000058 47.57999999999993
0.0 1.0 14.359086751937866 98.57500000000073 83.73500000000058 47.57999999999993
0.0 2.0 29.182889938354492 26.79500000000189 83.73500000000058 47.57999999999993
0.0 3.0 41.22303819656372 53.91999999999916 83.73500000000058 47.57999999999993
0.0 4.0 75.62745213508606 200.20000000000073 161.1249999999991 124.29999999999927
0.0 5.0 91.12282013893127 55.63500000000113 77.04500000000007 45.63499999999931
0.0 6.0 113.88321423530579 102.23500000000058 99.24499999999989 62.43000000000029
0.0 7.0 123.26052260398865 37.1800000000012 93.69999999999982 68.67000000000007
0.0 8.0 133.96120929718018 52.520000000002256 77.26999999999953 52.20000000000073
0.0 9.0 150.9030077457428 54.18499999999949 77.26999999999953 52.20000000000073
0.0 10.0 160.57325744628906 46.19999999999891 53.909999999998945 56.57000000000062
0.0 11.0 170.42762970924377 62.154999999999745 53.909999999998945 56.57000000000062
0.0 12.0 181.49908208847046 60.914999999999964 53.909999999998945 56.57000000000062
0.0 13.0 191.92408394813538 46.534999999999854 52.225000000000364 51.164999999999054
0.0 14.0 202.50521540641785 50.05000000000109 53.125 51.164999999999054
0.0 15.0 212.62711119651794 60.72500000000127 99.77499999999964 59.26000000000113
0.0 16.0 224.47419500350952 102.89499999999953 99.77499999999964 59.26000000000113
0.0 17.0 235.76142048835754 91.48500000000058 99.77499999999964 59.26000000000113
1.0 18.0 245.94083738327026 60.72500000000127 99.77499999999964 59.26000000000113
1.0 19.0 258.5926191806793 102.89499999999953 99.77499999999964 59.26000000000113
1.0 20.0 268.51672077178955 23.640000000000327 50.73500000000058 46.715000000000146
1.0 21.0 278.7331953048706 42.79499999999916 50.73500000000058 46.715000000000146
1.0 22.0 289.4359676837921 88.43499999999949 50.73500000000058 46.715000000000146
1.0 23.0 300.0781316757202 43.75999999999931 66.77999999999884 50.30999999999949
1.0 24.0 310.76686334609985 143.40499999999884 57.51000000000022 57.275000000000546
1.0 25.0 321.3582170009613 56.26499999999942 57.51000000000022 57.275000000000546
1.0 26.0 332.1264762878418 92.92499999999927 57.51000000000022 54.92500000000109
1.0 27.0 343.4879062175751 340.83500000000095 57.51000000000022 54.92500000000109
1.0 28.0 355.4360136985779 102.0550000000012 66.04000000000087 50.340000000000146
1.0 29.0 377.16375041007996 91.31500000000051 66.04000000000087 50.340000000000146
1.0 30.0 391.34228014945984 189.67499999999927 85.77499999999964 44.025000000000546
1.0 31.0 475.85996651649475 44.534999999999854 86.23999999999887 42.85500000000138
1.0 32.0 491.16194796562195 84.41499999999996 86.23999999999887 42.85500000000138
1.0 33.0 504.1015157699585 84.38499999999931 195.76000000000022 128.5
1.0 34.0 517.3048903942108 71.08500000000004 195.76000000000022 128.5
2.0 35.0 531.5764939785004 71.08500000000004 195.76000000000022 128.5
2.0 36.0 544.9604966640472 151.5 195.76000000000022 128.5
2.0 37.0 558.1611657142639 43.92999999999938 93.44499999999971 43.210000000001855
2.0 38.0 572.492702960968 65.25000000000091 94.71500000000015 44.025000000000546
2.0 39.0 603.41064620018 59.60000000000218 98.73999999999978 44.845000000000255
2.0 40.0 626.3224997520447 128.79500000000007 98.73999999999978 44.845000000000255
2.0 41.0 646.6917691230774 96.91500000000087 98.73999999999978 44.845000000000255
2.0 42.0 662.4183769226074 96.84999999999854 87.94999999999982 52.20000000000073
2.0 43.0 678.6573433876038 104.38499999999931 75.92000000000098 48.350000000000364
2.0 44.0 695.3771095275879 51.525000000000546 75.92000000000098 48.350000000000364
2.0 45.0 710.2177789211273 165.28000000000065 127.51999999999953 114.78500000000076
2.0 46.0 725.1257381439209 52.86500000000069 163.6849999999995 97.19499999999971
2.0 47.0 739.794774055481 43.910000000000764 131.65499999999884 116.67000000000007
2.0 48.0 752.9491510391235 57.68499999999949 131.65499999999884 116.67000000000007
2.0 49.0 766.0232362747192 75.63500000000022 131.65499999999884 116.67000000000007
2.0 50.0 781.4084296226501 106.42500000000018 109.38000000000284 114.78500000000076
2.0 51.0 796.1712336540222 30.9399999999996 109.38000000000284 114.78500000000076
3.0 52.0 811.8190689086914 167.21500000000015 111.51500000000215 116.67000000000007
3.0 53.0 827.4522414207458 320.6700000000037 309.53000000000156 165.83500000000095
3.0 54.0 843.6893577575684 147.1250000000009 309.53000000000156 165.83500000000095
3.0 55.0 859.4389626979828 52.17999999999847 111.2400000000016 113.0049999999992
3.0 56.0 875.1738474369049 63.974999999999454 111.2400000000016 113.0049999999992
3.0 57.0 892.1550350189209 98.47500000000036 111.2400000000016 113.0049999999992
3.0 58.0 909.260276556015 102.02999999999975 111.2400000000016 113.0049999999992
3.0 59.0 925.9570159912109 47.970000000000255 139.85000000000036 110.93499999999949
3.0 60.0 947.1165528297424 59.22999999999956 75.5649999999996 46.13500000000022
3.0 61.0 968.5892243385315 45.77499999999873 75.5649999999996 46.13500000000022
3.0 62.0 996.4546797275543 103.23500000000331 78.61499999999978 49.280000000000655
3.0 63.0 1018.7618851661682 35.49499999999898 78.61499999999978 49.280000000000655
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 13252.19 86.70499999999993 44.085000000000036
0.0 1.0 15.836228847503662 54.39999999999873 86.70499999999993 44.085000000000036
0.0 2.0 29.574301958084106 50.42999999999938 86.70499999999993 44.085000000000036
0.0 3.0 42.07063436508179 39.20000000000073 86.70499999999993 44.085000000000036
0.0 4.0 72.44364070892334 131.57999999999902 98.91500000000087 100.51999999999862
0.0 5.0 88.55028033256531 74.98000000000138 130.27500000000055 123.79500000000189
0.0 6.0 105.3717622756958 116.88499999999931 97.64000000000033 55.48500000000058
0.0 7.0 124.37543487548828 43.910000000000764 128.23000000000047 93.32499999999891
0.0 8.0 151.61943817138672 61.6700000000028 201.23499999999967 142.77500000000055
0.0 9.0 228.95865774154663 65.47499999999945 201.23499999999967 142.77500000000055
0.0 10.0 238.3123219013214 30.69499999999971 45.405000000000655 43.75000000000091
0.0 11.0 279.73315048217773 51.16500000000087 45.405000000000655 43.75000000000091
0.0 12.0 318.80109786987305 50.664999999999964 45.405000000000655 43.75000000000091
0.0 13.0 353.1629536151886 79.47500000000127 45.405000000000655 43.75000000000091
0.0 14.0 371.4758412837982 16.394999999999527 57.51000000000022 43.75000000000091
0.0 15.0 405.9112739562988 58.30500000000029 57.98999999999978 44.75999999999931
0.0 16.0 725.0014231204987 140.6900000000005 57.98999999999978 44.75999999999931
0.0 17.0 771.200168132782 13.409999999999854 57.98999999999978 44.75999999999931
1.0 18.0 807.7728266716003 67.27500000000236 58.20000000000073 45.404999999999745
1.0 19.0 1239.0078134536743 140.6900000000005 58.20000000000073 45.404999999999745
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 13244.790000000003 98.17500000000109 55.720000000000255
0.0 1.0 32.42121171951294 68.52000000000044 98.17500000000109 55.720000000000255
0.0 2.0 54.84614419937134 67.51999999999862 98.17500000000109 55.720000000000255
0.0 3.0 76.39335536956787 60.289999999999964 98.17500000000109 55.720000000000255
0.0 4.0 818.1269423961639 124.86499999999887 103.50000000000091 75.65999999999985
0.0 5.0 835.8642942905426 65.7549999999992 135.09500000000116 52.844999999998436
0.0 6.0 855.9479212760925 115.12500000000091 123.24999999999909 86.5649999999996
0.0 7.0 889.0628678798676 92.07999999999993 122.8199999999988 76.07500000000255
0.0 8.0 917.8332266807556 84.09999999999945 121.66999999999916 81.70500000000175
0.0 9.0 933.8972401618958 61.16999999999916 121.66999999999916 81.70500000000175
0.0 10.0 982.8898599147797 48.74499999999807 106.26500000000215 61.50999999999931
0.0 11.0 1033.7666971683502 110.83500000000004 106.26500000000215 61.50999999999931
