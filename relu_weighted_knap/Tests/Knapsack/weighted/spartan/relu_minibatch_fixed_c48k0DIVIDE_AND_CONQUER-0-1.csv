Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4417.88 184.7950000000003 57.95999999999958
0.0 1.0 13.779343128204346 85.23499999999967 173.07499999999982 57.95999999999958
0.0 2.0 25.093993425369263 86.64000000000078 303.61500000000024 209.39499999999975
0.0 3.0 38.318355560302734 136.70000000000027 303.61500000000024 209.39499999999975
0.0 4.0 54.014307498931885 284.0900000000006 303.61500000000024 209.39499999999975
0.0 5.0 64.95737648010254 56.9399999999996 285.9449999999997 217.73499999999922
0.0 6.0 76.60112309455872 363.40999999999985 346.34500000000025 349.645
0.0 7.0 86.036780834198 253.1700000000003 346.34500000000025 349.645
0.0 8.0 95.9185779094696 301.66999999999985 254.08500000000004 179.63499999999976
0.0 9.0 105.97479748725891 214.92000000000007 254.08500000000004 179.63499999999976
0.0 10.0 115.78079628944397 82.625 255.88999999999987 111.66999999999962
0.0 11.0 128.61630988121033 169.9000000000001 255.88999999999987 111.66999999999962
0.0 12.0 139.00522089004517 252.47000000000025 255.88999999999987 111.66999999999962
0.0 13.0 149.6492063999176 188.51499999999987 255.88999999999987 111.66999999999962
0.0 14.0 159.2357771396637 16.410000000000764 187.66000000000008 38.61499999999978
0.0 15.0 169.60840034484863 182.22499999999968 278.77 96.94999999999982
0.0 16.0 192.54355216026306 421.7549999999994 278.77 96.94999999999982
0.0 17.0 222.29871892929077 249.63500000000022 278.77 96.94999999999982
1.0 18.0 234.08494925498962 128.70000000000073 255.1500000000001 58.46999999999912
1.0 19.0 258.30165123939514 421.7549999999994 255.1500000000001 58.46999999999912
1.0 20.0 305.22103929519653 296.8149999999996 255.1500000000001 58.46999999999912
1.0 21.0 327.6483736038208 295.3049999999996 255.1500000000001 58.46999999999912
1.0 22.0 342.3566884994507 214.35000000000014 255.1500000000001 58.46999999999912
1.0 23.0 360.4339714050293 94.24499999999944 157.5749999999996 84.80999999999949
1.0 24.0 385.25127387046814 507.7250000000008 157.5749999999996 84.80999999999949
1.0 25.0 425.40231370925903 314.1999999999998 157.5749999999996 84.80999999999949
1.0 26.0 458.84011125564575 188.80999999999995 157.5749999999996 84.80999999999949
1.0 27.0 471.5779106616974 78.92999999999938 247.37999999999988 64.80999999999949
1.0 28.0 489.0935866832733 25.860000000000127 247.37999999999988 64.80999999999949
1.0 29.0 522.5713310241699 248.10000000000036 247.37999999999988 64.80999999999949
1.0 30.0 555.0932447910309 470.69000000000005 458.1949999999995 358.83500000000004
1.0 31.0 568.6435685157776 19.56999999999971 252.17499999999995 58.26999999999953
1.0 32.0 608.0295329093933 329.6800000000003 252.17499999999995 58.26999999999953
1.0 33.0 621.7707912921906 388.7399999999989 252.6949999999997 104.98499999999945
1.0 34.0 636.1866054534912 237.55500000000006 296.8199999999997 211.73999999999955
2.0 35.0 649.8222270011902 87.73999999999978 381.8850000000007 226.97000000000025
2.0 36.0 684.5432095527649 314.1450000000002 381.8850000000007 226.97000000000025
2.0 37.0 701.7076823711395 64.27499999999964 225.1800000000003 40.63499999999931
2.0 38.0 716.8694608211517 97.33500000000026 288.18000000000006 204.6299999999992
2.0 39.0 730.4255509376526 69.03999999999951 275.13999999999965 126.15999999999985
2.0 40.0 745.5228793621063 194.85000000000014 275.13999999999965 126.15999999999985
2.0 41.0 758.6533663272858 233.00999999999976 275.13999999999965 126.15999999999985
2.0 42.0 822.8359298706055 484.8150000000005 512.935 573.4200000000001
2.0 43.0 850.0858824253082 304.11500000000024 512.935 573.4200000000001
2.0 44.0 873.6352097988129 275.7199999999998 512.935 573.4200000000001
2.0 45.0 915.8202540874481 535.8150000000003 512.935 573.4200000000001
2.0 46.0 930.5026392936707 51.63499999999976 295.96500000000015 132.03999999999974
2.0 47.0 949.7929718494415 140.5550000000003 295.96500000000015 132.03999999999974
2.0 48.0 964.9132494926453 244.77999999999975 295.96500000000015 132.03999999999974
2.0 49.0 977.981920003891 115.14000000000033 295.96500000000015 132.03999999999974
2.0 50.0 995.948840379715 481.3799999999999 413.2550000000001 384.6100000000001
2.0 51.0 1083.5852518081665 139.51499999999987 371.9399999999996 249.87999999999965
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4402.400000000001 173.23500000000058 43.210000000000946
0.0 1.0 9.612783908843994 106.92499999999927 147.13999999999987 40.85500000000047
0.0 2.0 18.340514421463013 78.45000000000027 185.84499999999957 65.39500000000044
0.0 3.0 34.53140830993652 127.15499999999997 185.84499999999957 65.39500000000044
0.0 4.0 55.802592039108276 331.0900000000004 185.84499999999957 65.39500000000044
0.0 5.0 64.9831190109253 22.149999999999636 182.9450000000004 38.29500000000007
0.0 6.0 78.6251266002655 469.4299999999996 186.1450000000002 154.81999999999925
0.0 7.0 92.31100249290466 253.66000000000008 186.1450000000002 154.81999999999925
0.0 8.0 100.46938920021057 212.44999999999982 144.58500000000026 40.85500000000047
0.0 9.0 109.11847925186157 178.30499999999938 144.58500000000026 40.85500000000047
0.0 10.0 117.36097145080566 45.874999999999545 271.36999999999944 107.66499999999951
0.0 11.0 131.36180806159973 194.4350000000004 271.36999999999944 107.66499999999951
0.0 12.0 140.4145872592926 277.99999999999886 271.36999999999944 107.66499999999951
0.0 13.0 151.41607546806335 219.4449999999997 271.36999999999944 107.66499999999951
0.0 14.0 160.11080741882324 113.19499999999925 320.46000000000004 143.60500000000002
0.0 15.0 172.47691535949707 136.34500000000025 320.46000000000004 167.5899999999997
0.0 16.0 183.0105254650116 338.2849999999994 320.46000000000004 167.5899999999997
0.0 17.0 193.62803316116333 236.50000000000045 320.46000000000004 167.5899999999997
1.0 18.0 210.87807273864746 101.83500000000049 197.38999999999965 151.3050000000003
1.0 19.0 225.21639704704285 316.3749999999991 197.38999999999965 151.3050000000003
1.0 20.0 236.64829516410828 144.7299999999998 197.38999999999965 151.3050000000003
1.0 21.0 246.57485818862915 94.66000000000008 197.38999999999965 151.3050000000003
1.0 22.0 257.5351767539978 176.6499999999994 197.38999999999965 151.3050000000003
1.0 23.0 273.96022605895996 97.30999999999949 202.8499999999999 134.23999999999978
1.0 24.0 330.71559500694275 430.27499999999986 202.8499999999999 134.23999999999978
1.0 25.0 360.471538066864 235.99500000000012 202.8499999999999 134.23999999999978
1.0 26.0 384.517041683197 208.68000000000006 202.8499999999999 134.23999999999978
1.0 27.0 394.49314165115356 130.89499999999953 192.48999999999955 156.9300000000003
1.0 28.0 410.0069224834442 54.190000000000055 157.46000000000004 71.76999999999975
1.0 29.0 425.9985649585724 98.70500000000038 157.46000000000004 71.76999999999975
1.0 30.0 607.9398508071899 238.17500000000018 214.82999999999993 78.29499999999939
1.0 31.0 621.1494326591492 58.33000000000084 214.82999999999993 78.29499999999939
1.0 32.0 793.1889455318451 281.97 214.82999999999993 78.29499999999939
1.0 33.0 816.6761608123779 239.20999999999913 129.21500000000015 146.72499999999945
1.0 34.0 835.4255948066711 63.79500000000007 193.15499999999975 146.19999999999982
2.0 35.0 854.2130224704742 63.79500000000007 193.15499999999975 146.19999999999982
2.0 36.0 883.380312204361 214.04999999999995 193.15499999999975 146.19999999999982
2.0 37.0 949.1478984355927 69.40499999999975 227.99499999999966 123.03999999999996
2.0 38.0 966.1008243560791 76.58500000000004 125.34500000000048 98.79499999999916
2.0 39.0 980.2929999828339 36.6550000000002 221.15499999999975 40.33499999999958
2.0 40.0 1128.4557824134827 188.39500000000044 221.15499999999975 40.33499999999958
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4379.17 181.74 43.210000000000946
0.0 1.0 10.886462211608887 86.86999999999944 260.52 199.92499999999927
0.0 2.0 19.140868663787842 70.03999999999951 381.8850000000007 250.0899999999997
0.0 3.0 33.31150531768799 222.76000000000045 381.8850000000007 250.0899999999997
0.0 4.0 56.985859394073486 486.5999999999999 381.8850000000007 250.0899999999997
0.0 5.0 66.57184147834778 46.815000000000055 212.0599999999995 104.30500000000006
0.0 6.0 105.74244928359985 370.6750000000002 328.7600000000002 214.0649999999996
0.0 7.0 120.71923470497131 248.15000000000032 328.7600000000002 214.0649999999996
0.0 8.0 139.90098690986633 207.4499999999989 321.3900000000003 170.87999999999965
0.0 9.0 169.1005506515503 226.80000000000064 321.3900000000003 170.87999999999965
0.0 10.0 179.1549162864685 61.64499999999998 190.8900000000001 43.210000000000946
0.0 11.0 207.4739053249359 252.7250000000006 190.8900000000001 43.210000000000946
0.0 12.0 220.71530961990356 385.1750000000002 190.8900000000001 43.210000000000946
0.0 13.0 230.78803062438965 219.78000000000043 190.8900000000001 43.210000000000946
0.0 14.0 240.30181074142456 19.420000000000528 190.8900000000001 43.210000000000946
0.0 15.0 251.73217105865479 73.71000000000049 266.5649999999998 107.91500000000042
0.0 16.0 270.30640292167664 271.38499999999976 266.5649999999998 107.91500000000042
0.0 17.0 280.4335730075836 147.41499999999974 266.5649999999998 107.91500000000042
1.0 18.0 291.7112543582916 73.71000000000049 266.5649999999998 107.91500000000042
1.0 19.0 310.6826469898224 271.38499999999976 266.5649999999998 107.91500000000042
1.0 20.0 322.6040906906128 130.87500000000045 266.5649999999998 107.91500000000042
1.0 21.0 335.20166277885437 163.80999999999995 266.5649999999998 107.91500000000042
1.0 22.0 349.24116921424866 117.03499999999985 266.5649999999998 107.91500000000042
1.0 23.0 360.82210302352905 57.44499999999971 190.8900000000001 43.210000000000946
1.0 24.0 385.2763729095459 433.9200000000001 190.8900000000001 43.210000000000946
1.0 25.0 409.22332763671875 252.7250000000006 190.8900000000001 43.210000000000946
1.0 26.0 422.3679075241089 219.78000000000043 190.8900000000001 43.210000000000946
1.0 27.0 434.1336717605591 106.92499999999927 204.19000000000005 98.62999999999965
1.0 28.0 447.4150402545929 25.854999999999563 213.59500000000116 46.725000000000364
1.0 29.0 460.0054979324341 230.00000000000023 213.59500000000116 46.725000000000364
1.0 30.0 567.0428228378296 358.39500000000044 466.2549999999992 234.72999999999956
1.0 31.0 580.4703621864319 84.89000000000033 353.0149999999999 75.59500000000025
1.0 32.0 593.8094182014465 425.1500000000001 353.0149999999999 75.59500000000025
1.0 33.0 605.0931808948517 259.38999999999896 318.1199999999999 190.0099999999993
1.0 34.0 615.9694502353668 80.61000000000013 342.11000000000035 219.60999999999945
2.0 35.0 626.9576861858368 80.61000000000013 342.11000000000035 219.60999999999945
2.0 36.0 639.2941188812256 312.04999999999995 342.11000000000035 219.60999999999945
2.0 37.0 651.0736536979675 57.44499999999971 204.19000000000005 58.00999999999908
2.0 38.0 664.0317041873932 113.66000000000076 204.19000000000005 58.00999999999908
2.0 39.0 677.9255409240723 27.234999999999673 204.19000000000005 58.00999999999908
2.0 40.0 695.925698518753 293.9599999999991 204.19000000000005 58.00999999999908
2.0 41.0 712.4955744743347 211.78500000000008 204.19000000000005 58.00999999999908
2.0 42.0 756.4927105903625 411.1500000000001 497.5150000000003 545.1699999999998
2.0 43.0 785.5113542079926 400.7149999999999 497.5150000000003 545.1699999999998
2.0 44.0 815.3441183567047 295.3049999999996 497.5150000000003 545.1699999999998
2.0 45.0 868.3815894126892 596.3699999999997 497.5150000000003 545.1699999999998
2.0 46.0 880.4488391876221 37.5649999999996 251.8499999999999 52.92999999999893
2.0 47.0 891.6969335079193 282.73999999999955 251.8499999999999 52.92999999999893
2.0 48.0 902.9568123817444 423.9699999999998 251.8499999999999 52.92999999999893
2.0 49.0 913.7345428466797 242.34500000000003 251.8499999999999 52.92999999999893
2.0 50.0 925.4670562744141 282.54499999999916 299.13499999999976 146.19999999999982
2.0 51.0 938.3925812244415 72.93000000000029 345.46000000000004 60.93499999999926
3.0 52.0 1048.9767639636993 581.8799999999994 345.46000000000004 60.93499999999926
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4419.34 172.6049999999998 45.57000000000062
0.0 1.0 12.360949993133545 139.51499999999987 185.06999999999994 55.82500000000027
0.0 2.0 22.15366291999817 88.27000000000044 181.93000000000006 55.82500000000027
0.0 3.0 33.25411343574524 110.70500000000015 181.93000000000006 55.82500000000027
0.0 4.0 52.78881096839905 424.76 181.93000000000006 55.82500000000027
0.0 5.0 63.42662262916565 32.02999999999997 156.2099999999998 54.119999999999436
0.0 6.0 92.58660817146301 535.6749999999997 598.5300000000002 502.5599999999995
0.0 7.0 134.25310730934143 325.30999999999995 598.5300000000002 502.5599999999995
0.0 8.0 274.7909314632416 271.2199999999989 331.4249999999997 366.87499999999955
0.0 9.0 289.72036719322205 168.6500000000001 331.4249999999997 366.87499999999955
0.0 10.0 301.01159262657166 68.64499999999998 239.06000000000017 85.22000000000071
0.0 11.0 314.74420166015625 174.21999999999957 239.06000000000017 85.22000000000071
0.0 12.0 326.9497272968292 353.7449999999999 239.06000000000017 85.22000000000071
0.0 13.0 337.4079382419586 260.8550000000005 239.06000000000017 85.22000000000071
0.0 14.0 346.4547350406647 10.430000000000291 192.7199999999998 42.83500000000049
0.0 15.0 362.71035742759705 101.84000000000015 360.33499999999935 300.85499999999865
0.0 16.0 491.9363384246826 442.96500000000015 360.33499999999935 300.85499999999865
0.0 17.0 739.556478023529 166.79999999999995 360.33499999999935 300.85499999999865
1.0 18.0 1183.2522792816162 113.07000000000062 368.6149999999984 417.44500000000016
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4387.57 223.78499999999963 44.82500000000027
0.0 1.0 8.407412052154541 140.6799999999996 379.4350000000004 347.4699999999998
0.0 2.0 16.02167582511902 89.30499999999984 340.1500000000001 218.89500000000044
0.0 3.0 23.572823524475098 205.19000000000028 340.1500000000001 218.89500000000044
0.0 4.0 32.0915048122406 643.615 340.1500000000001 218.89500000000044
0.0 5.0 39.85083055496216 23.720000000000255 294.31500000000005 222.85499999999934
0.0 6.0 49.44210696220398 479.2800000000002 906.0449999999994 1444.2699999999998
0.0 7.0 59.24249315261841 432.19000000000005 906.0449999999994 1444.2699999999998
0.0 8.0 68.02662348747253 203.4400000000005 128.4600000000005 68.33999999999969
0.0 9.0 81.67020797729492 117.03499999999985 128.4600000000005 68.33999999999969
0.0 10.0 90.76596808433533 94.24499999999944 128.4600000000005 68.33999999999969
0.0 11.0 113.34061288833618 296.35499999999956 128.4600000000005 68.33999999999969
0.0 12.0 129.5164647102356 256.75499999999965 128.4600000000005 68.33999999999969
0.0 13.0 144.69105076789856 188.80999999999995 128.4600000000005 68.33999999999969
0.0 14.0 152.7793972492218 65.95000000000027 384.855 58.00999999999908
0.0 15.0 163.27813029289246 128.70000000000073 303.0999999999999 50.97499999999968
0.0 16.0 214.84002327919006 337.2749999999994 303.0999999999999 50.97499999999968
0.0 17.0 254.696692943573 326.2000000000005 303.0999999999999 50.97499999999968
1.0 18.0 265.51737904548645 128.70000000000073 303.0999999999999 50.97499999999968
1.0 19.0 314.205069065094 337.2749999999994 303.0999999999999 50.97499999999968
1.0 20.0 345.8540127277374 299.135 303.0999999999999 50.97499999999968
1.0 21.0 383.3576376438141 325.30500000000006 303.0999999999999 50.97499999999968
1.0 22.0 411.4236741065979 237.8549999999998 303.0999999999999 50.97499999999968
1.0 23.0 426.52528715133667 79.18999999999915 181.47999999999956 67.94000000000005
1.0 24.0 563.8847277164459 587.5549999999992 181.47999999999956 67.94000000000005
1.0 25.0 683.0956587791443 325.18499999999995 181.47999999999956 67.94000000000005
1.0 26.0 813.2499403953552 279.07000000000085 181.47999999999956 67.94000000000005
1.0 27.0 823.788323879242 64.55000000000018 188.59999999999968 61.57999999999993
1.0 28.0 860.9156160354614 26.704999999999927 188.59999999999968 61.57999999999993
1.0 29.0 906.802515745163 262.50499999999965 188.59999999999968 61.57999999999993
1.0 30.0 958.2228999137878 353.8250000000007 188.59999999999968 61.57999999999993
1.0 31.0 967.8067774772644 84.89000000000033 349.3699999999999 58.00999999999908
1.0 32.0 986.8384864330292 451.4549999999999 349.3699999999999 58.00999999999908
1.0 33.0 1017.5062465667725 222.73500000000058 216.48000000000025 104.90999999999963
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4425.26 195.23999999999978 68.63499999999999
0.0 1.0 13.778841972351074 106.92499999999927 189.09500000000025 49.13999999999987
0.0 2.0 25.9050350189209 97.86000000000013 189.47999999999934 90.48000000000002
0.0 3.0 39.3027708530426 122.22000000000003 189.47999999999934 90.48000000000002
0.0 4.0 61.6590850353241 373.1599999999994 189.47999999999934 90.48000000000002
0.0 5.0 75.53252387046814 31.52500000000009 158.3699999999999 43.210000000000946
0.0 6.0 90.43200349807739 421.930000000001 441.72999999999956 463.78999999999974
0.0 7.0 134.84489488601685 346.8200000000006 441.72999999999956 463.78999999999974
0.0 8.0 146.07838082313538 388.7399999999989 222.86999999999966 118.18499999999995
0.0 9.0 162.162367105484 158.70000000000005 222.86999999999966 118.18499999999995
0.0 10.0 172.02342295646667 112.15000000000009 233.6949999999997 141.1199999999999
0.0 11.0 183.4286322593689 150.80999999999995 233.6949999999997 141.1199999999999
0.0 12.0 194.1666078567505 279.3500000000006 233.6949999999997 141.1199999999999
0.0 13.0 206.04209637641907 190.6300000000001 233.6949999999997 141.1199999999999
0.0 14.0 217.12370347976685 24.514999999999873 219.14499999999953 82.39499999999953
0.0 15.0 230.1639473438263 99.76999999999998 488.7000000000007 380.0899999999997
0.0 16.0 255.90957045555115 319.8100000000002 488.7000000000007 380.0899999999997
0.0 17.0 269.1670243740082 298.9300000000003 488.7000000000007 380.0899999999997
1.0 18.0 282.48607873916626 87.32000000000039 457.4649999999997 385.2750000000001
1.0 19.0 311.5185670852661 326.1800000000003 457.4649999999997 385.2750000000001
1.0 20.0 323.7032663822174 422.36500000000024 457.4649999999997 385.2750000000001
1.0 21.0 335.7456729412079 219.8350000000005 457.4649999999997 385.2750000000001
1.0 22.0 354.7602996826172 117.03499999999985 457.4649999999997 385.2750000000001
1.0 23.0 366.37678503990173 82.36499999999978 236.96500000000037 55.99499999999989
1.0 24.0 378.1729815006256 524.2550000000003 236.96500000000037 55.99499999999989
1.0 25.0 391.00993156433105 267.4400000000005 236.96500000000037 55.99499999999989
1.0 26.0 403.2179801464081 186.10499999999956 236.96500000000037 55.99499999999989
1.0 27.0 415.5085666179657 114.39499999999907 236.96500000000037 55.99499999999989
1.0 28.0 427.9571497440338 23.720000000000255 236.96500000000037 56.70499999999993
1.0 29.0 441.3695435523987 165.60500000000002 236.96500000000037 56.70499999999993
1.0 30.0 456.7943971157074 568.9949999999999 563.8250000000005 451.13000000000056
1.0 31.0 852.6463203430176 81.31500000000005 284.39999999999986 112.23499999999967
1.0 32.0 1006.0805027484894 192.1599999999994 284.39999999999986 112.23499999999967
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4419.34 170.85500000000002 58.07999999999993
0.0 1.0 5.408358573913574 85.23499999999967 174.29500000000007 68.41999999999962
0.0 2.0 10.71493124961853 70.61999999999989 177.90000000000032 38.29500000000007
0.0 3.0 17.125426769256592 119.94000000000028 177.90000000000032 38.29500000000007
0.0 4.0 31.068507432937622 315.6149999999998 177.90000000000032 38.29500000000007
0.0 5.0 36.15431833267212 22.149999999999636 218.7199999999998 71.81500000000028
0.0 6.0 42.56110453605652 485.8399999999999 252.37000000000012 206.11999999999944
0.0 7.0 54.24326944351196 171.38499999999976 252.37000000000012 206.11999999999944
0.0 8.0 73.86914229393005 197.49000000000024 128.83000000000015 110.5949999999998
0.0 9.0 94.3926727771759 107.26000000000022 128.83000000000015 110.5949999999998
0.0 10.0 107.95238971710205 57.44499999999971 163.35000000000014 68.33999999999969
0.0 11.0 163.5368528366089 255.34000000000015 163.35000000000014 68.33999999999969
0.0 12.0 216.91039657592773 206.11999999999966 163.35000000000014 68.33999999999969
0.0 13.0 246.29417371749878 237.44500000000107 163.35000000000014 68.33999999999969
0.0 14.0 252.1975383758545 36.879999999999654 239.37000000000012 38.29500000000007
0.0 15.0 261.94813895225525 113.07000000000062 245.17000000000053 120.20000000000005
0.0 16.0 305.1941969394684 242.92999999999984 245.17000000000053 120.20000000000005
0.0 17.0 335.84860038757324 117.19000000000028 245.17000000000053 120.20000000000005
1.0 18.0 344.49432730674744 113.07000000000062 245.17000000000053 120.20000000000005
1.0 19.0 387.7637469768524 242.92999999999984 245.17000000000053 120.20000000000005
1.0 20.0 461.19943952560425 140.70000000000027 245.17000000000053 120.20000000000005
1.0 21.0 491.247642993927 144.46000000000026 245.17000000000053 120.20000000000005
1.0 22.0 507.52802896499634 176.6499999999994 245.17000000000053 120.20000000000005
1.0 23.0 523.5123825073242 51.22999999999956 237.22000000000003 47.58499999999958
1.0 24.0 533.7635540962219 509.7450000000001 237.22000000000003 47.58499999999958
1.0 25.0 550.8217759132385 172.58999999999946 237.22000000000003 47.58499999999958
1.0 26.0 557.4086945056915 235.78000000000065 237.22000000000003 47.58499999999958
1.0 27.0 562.8523168563843 86.86999999999944 237.22000000000003 47.58499999999958
1.0 28.0 568.1380622386932 28.89500000000021 237.22000000000003 47.58499999999958
1.0 29.0 574.3173434734344 89.92999999999984 237.22000000000003 47.58499999999958
1.0 30.0 911.9024517536163 560.9100000000003 742.2649999999999 776.4749999999999
1.0 31.0 982.728363275528 50.66000000000031 254.82500000000073 94.05999999999972
1.0 32.0 1522.5543282032013 240.50000000000023 254.82500000000073 94.05999999999972
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4402.400000000001 140.16499999999996 40.85500000000047
0.0 1.0 10.808480978012085 106.92499999999927 172.6049999999998 41.92000000000007
0.0 2.0 20.386467456817627 109.01000000000022 171.43499999999972 43.210000000000946
0.0 3.0 29.63480496406555 99.72000000000003 171.43499999999972 43.210000000000946
0.0 4.0 46.2121639251709 456.05500000000006 171.43499999999972 43.210000000000946
0.0 5.0 55.27775287628174 27.61500000000001 181.77500000000032 40.85500000000047
0.0 6.0 65.15382647514343 373.72000000000025 495.7800000000002 314.51000000000045
0.0 7.0 74.9186007976532 369.4799999999998 495.7800000000002 314.51000000000045
0.0 8.0 83.71399259567261 259.38999999999896 337.2549999999992 161.16999999999962
0.0 9.0 94.7169816493988 228.9699999999998 337.2549999999992 161.16999999999962
0.0 10.0 101.72779321670532 120.53500000000031 311.7449999999999 146.1550000000002
0.0 11.0 110.89215874671936 323.0450000000001 311.7449999999999 146.1550000000002
0.0 12.0 132.2706277370453 324.9799999999998 311.7449999999999 146.1550000000002
0.0 13.0 150.90612268447876 243.13500000000022 311.7449999999999 146.1550000000002
0.0 14.0 159.663471698761 81.11499999999978 286.1600000000001 94.47999999999911
0.0 15.0 168.3801634311676 112.46000000000095 277.2049999999999 139.75500000000056
0.0 16.0 245.79503345489502 332.06500000000005 277.2049999999999 139.75500000000056
0.0 17.0 402.1634328365326 243.52500000000032 277.2049999999999 139.75500000000056
1.0 18.0 412.51850271224976 112.46000000000095 277.2049999999999 139.75500000000056
1.0 19.0 491.5389575958252 332.06500000000005 277.2049999999999 139.75500000000056
1.0 20.0 579.0585639476776 128.2900000000002 277.2049999999999 139.75500000000056
1.0 21.0 707.0733532905579 126.30999999999972 277.2049999999999 139.75500000000056
1.0 22.0 724.377153635025 190.64499999999953 277.2049999999999 139.75500000000056
1.0 23.0 875.7593348026276 101.67500000000018 277.31500000000005 130.80000000000018
1.0 24.0 1114.2073919773102 564.5899999999995 277.31500000000005 130.80000000000018
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4404.0599999999995 201.6799999999996 81.92499999999973
0.0 1.0 11.129732847213745 106.92499999999927 363.4099999999994 156.8350000000005
0.0 2.0 21.50451683998108 80.02999999999975 342.9350000000004 190.00999999999976
0.0 3.0 35.72330117225647 145.635 342.9350000000004 190.00999999999976
0.0 4.0 48.099374771118164 383.7500000000002 342.9350000000004 190.00999999999976
0.0 5.0 57.14879083633423 25.50500000000011 277.64999999999964 194.3399999999997
0.0 6.0 66.00695848464966 460.4249999999993 234.27499999999986 256.68999999999915
0.0 7.0 75.65523529052734 238.95500000000038 234.27499999999986 256.68999999999915
0.0 8.0 84.08477854728699 259.38999999999896 262.1800000000003 104.98499999999945
0.0 9.0 93.04031276702881 150.9799999999998 262.1800000000003 104.98499999999945
0.0 10.0 102.15546607971191 40.039999999999964 147.69500000000016 67.94000000000005
0.0 11.0 113.608722448349 271.26 147.69500000000016 67.94000000000005
0.0 12.0 126.18532252311707 279.655 147.69500000000016 67.94000000000005
0.0 13.0 135.54265761375427 206.60000000000036 147.69500000000016 67.94000000000005
0.0 14.0 143.93816876411438 23.549999999999727 224.54500000000007 58.00999999999908
0.0 15.0 163.49991583824158 76.6550000000002 422.1300000000001 548.8099999999997
0.0 16.0 247.10271787643433 308.4850000000001 422.1300000000001 548.8099999999997
0.0 17.0 264.2034294605255 216.81500000000005 422.1300000000001 548.8099999999997
1.0 18.0 283.7317111492157 76.6550000000002 422.1300000000001 548.8099999999997
1.0 19.0 363.02972650527954 308.4850000000001 422.1300000000001 548.8099999999997
1.0 20.0 386.0135269165039 410.4150000000004 422.1300000000001 548.8099999999997
1.0 21.0 406.9339175224304 222.76000000000045 422.1300000000001 548.8099999999997
1.0 22.0 440.7444021701813 194.0399999999995 422.1300000000001 548.8099999999997
1.0 23.0 451.9352910518646 46.30499999999938 189.6300000000001 41.92000000000007
1.0 24.0 468.6844153404236 373.1599999999994 189.6300000000001 41.92000000000007
1.0 25.0 487.70877051353455 192.6450000000002 189.6300000000001 41.92000000000007
1.0 26.0 498.7086935043335 222.55500000000075 189.6300000000001 41.92000000000007
1.0 27.0 511.62726855278015 106.92499999999927 217.52000000000044 75.59500000000025
1.0 28.0 524.2506859302521 59.534999999999854 224.91499999999996 86.34500000000003
1.0 29.0 544.82404088974 119.75500000000079 224.91499999999996 86.34500000000003
1.0 30.0 616.7790179252625 370.6750000000002 423.8250000000012 469.87499999999955
1.0 31.0 627.029923915863 89.58500000000004 291.0999999999997 138.4050000000002
1.0 32.0 641.7974767684937 267.54999999999995 291.0999999999997 138.4050000000002
1.0 33.0 653.6635539531708 226.73499999999922 203.78999999999974 56.70499999999993
1.0 34.0 665.6474823951721 71.36499999999978 203.78999999999974 56.70499999999993
2.0 35.0 677.0522797107697 71.36499999999978 203.78999999999974 56.70499999999993
2.0 36.0 745.4395711421967 337.97 203.78999999999974 56.70499999999993
2.0 37.0 768.794349193573 112.15000000000009 203.78999999999974 56.70499999999993
2.0 38.0 785.976687669754 97.31499999999983 233.8300000000006 56.70499999999993
2.0 39.0 798.0151898860931 38.274999999999864 223.09500000000003 43.9050000000002
2.0 40.0 833.5799906253815 157.84999999999945 223.09500000000003 43.9050000000002
2.0 41.0 854.2498972415924 176.6499999999994 223.09500000000003 43.9050000000002
2.0 42.0 2224.5146474838257 363.40999999999985 432.155 465.6899999999998
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4402.400000000001 162.70499999999947 42.83500000000049
0.0 1.0 8.592832565307617 86.86999999999944 172.28000000000043 69.98000000000025
0.0 2.0 15.394849061965942 70.20999999999958 180.93000000000075 138.86500000000024
0.0 3.0 22.77266001701355 143.70000000000073 180.93000000000075 138.86500000000024
0.0 4.0 32.4456901550293 302.1100000000001 180.93000000000075 138.86500000000024
0.0 5.0 39.20217680931091 22.74000000000001 180.93000000000075 138.86500000000024
0.0 6.0 45.26771330833435 396.1050000000005 297.75 262.27499999999964
0.0 7.0 53.37136793136597 177.57999999999993 297.75 262.27499999999964
0.0 8.0 59.75351619720459 185.0299999999993 185.77500000000032 151.3050000000003
0.0 9.0 67.04416370391846 124.7800000000002 185.77500000000032 151.3050000000003
0.0 10.0 73.05291318893433 50.63999999999987 119.05499999999984 86.84999999999968
0.0 11.0 99.26674008369446 197.03500000000008 119.05499999999984 86.84999999999968
0.0 12.0 110.16514801979065 211.34000000000015 119.05499999999984 86.84999999999968
0.0 13.0 119.43243217468262 152.6550000000002 119.05499999999984 86.84999999999968
0.0 14.0 127.33162689208984 60.8700000000008 405.4849999999999 197.92499999999927
0.0 15.0 133.46710634231567 101.21000000000004 186.68000000000006 41.92000000000007
0.0 16.0 139.8895092010498 264.47 186.68000000000006 41.92000000000007
0.0 17.0 145.879478931427 255.02999999999975 186.68000000000006 41.92000000000007
1.0 18.0 152.07550740242004 101.21000000000004 186.68000000000006 41.92000000000007
1.0 19.0 158.73981404304504 264.47 186.68000000000006 41.92000000000007
1.0 20.0 165.21417951583862 156.09000000000015 186.68000000000006 41.92000000000007
1.0 21.0 171.6121907234192 196.27000000000044 186.68000000000006 41.92000000000007
1.0 22.0 178.4199767112732 133.71500000000015 186.68000000000006 41.92000000000007
1.0 23.0 185.66201424598694 98.49499999999944 208.385 94.16999999999962
1.0 24.0 192.69264125823975 568.655 208.385 94.16999999999962
1.0 25.0 199.69662714004517 379.605 208.385 94.16999999999962
1.0 26.0 207.01454639434814 334.63499999999976 208.385 94.16999999999962
1.0 27.0 213.60898804664612 70.75499999999965 241.37000000000035 99.56499999999915
1.0 28.0 225.14153003692627 28.235000000000127 218.45499999999993 68.33999999999969
1.0 29.0 254.16067147254944 265.45500000000015 218.45499999999993 68.33999999999969
1.0 30.0 274.76320934295654 418.4749999999999 325.67499999999995 98.44499999999994
1.0 31.0 284.47762537002563 31.80499999999938 259.4050000000002 76.74499999999966
1.0 32.0 303.3561737537384 397.9349999999995 259.4050000000002 76.74499999999966
1.0 33.0 309.4353711605072 246.6649999999995 282.405 142.35000000000036
1.0 34.0 315.24110889434814 78.45000000000027 267.16499999999996 130.80000000000018
2.0 35.0 320.85009503364563 78.45000000000027 267.16499999999996 130.80000000000018
2.0 36.0 327.0292625427246 277.02 267.16499999999996 130.80000000000018
2.0 37.0 409.1780095100403 96.0649999999996 258.0 130.80000000000018
2.0 38.0 415.4845495223999 102.43000000000029 258.0 130.80000000000018
2.0 39.0 428.2240526676178 28.235000000000127 258.0 130.80000000000018
2.0 40.0 434.39590644836426 308.8599999999997 258.0 130.80000000000018
2.0 41.0 440.82943654060364 211.78500000000008 258.0 130.80000000000018
2.0 42.0 448.1419503688812 315.55500000000075 258.0 130.80000000000018
2.0 43.0 454.7628004550934 210.51000000000067 258.0 130.80000000000018
2.0 44.0 460.8692955970764 153.70500000000038 258.0 130.80000000000018
2.0 45.0 468.0638470649719 554.6050000000005 258.0 130.80000000000018
2.0 46.0 750.1068477630615 65.95000000000027 260.2249999999999 58.00999999999908
2.0 47.0 1031.9226524829865 237.67500000000018 260.2249999999999 58.00999999999908
