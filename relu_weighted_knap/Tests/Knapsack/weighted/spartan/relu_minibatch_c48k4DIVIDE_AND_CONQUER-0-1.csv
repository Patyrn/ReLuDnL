Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4503.13 138.52499999999986 176.65499999999975
0.0 1.0 4.032364368438721 195.85000000000014 138.52499999999986 176.65499999999975
0.0 2.0 7.918699026107788 207.85500000000047 138.52499999999986 176.65499999999975
0.0 3.0 11.62538766860962 31.980000000000473 117.99000000000024 201.37999999999943
0.0 4.0 15.047795534133911 119.08000000000038 90.10000000000014 181.76500000000033
0.0 5.0 18.347940921783447 195.05499999999938 90.10000000000014 181.76500000000033
0.0 6.0 22.186782836914062 81.15000000000032 107.11000000000013 193.18999999999983
0.0 7.0 26.428966522216797 497.57999999999925 229.18499999999995 231.90499999999997
0.0 8.0 31.531879901885986 365.01 229.18499999999995 231.90499999999997
0.0 9.0 35.60855484008789 309.4749999999999 229.18499999999995 231.90499999999997
0.0 10.0 40.36223840713501 334.86500000000024 229.18499999999995 231.90499999999997
0.0 11.0 43.74668312072754 83.77999999999975 83.98000000000002 155.25499999999965
0.0 12.0 47.003639459609985 46.63999999999987 82.88500000000067 184.00499999999965
0.0 13.0 50.55748128890991 192.11500000000024 74.17999999999984 126.85000000000014
0.0 14.0 54.02291250228882 111.03999999999951 74.17999999999984 126.85000000000014
0.0 15.0 57.50777530670166 203.71999999999957 74.17999999999984 126.85000000000014
0.0 16.0 60.90043497085571 50.63999999999987 77.36499999999978 129.99000000000046
0.0 17.0 64.5147602558136 59.8599999999999 78.29000000000042 170.67499999999973
1.0 18.0 69.63380169868469 161.46000000000095 78.29000000000042 170.67499999999973
1.0 19.0 73.44725823402405 50.63999999999987 80.24499999999989 101.20499999999993
1.0 20.0 84.407883644104 416.00999999999885 237.47999999999956 243.3150000000005
1.0 21.0 90.13855981826782 43.005000000000564 120.0750000000005 208.9599999999998
1.0 22.0 121.78839111328125 165.0249999999994 120.0750000000005 208.9599999999998
1.0 23.0 239.495037317276 264.7999999999997 120.0750000000005 208.9599999999998
1.0 24.0 258.8332679271698 196.76 121.67000000000007 133.33000000000038
1.0 25.0 271.31602478027344 39.42499999999973 98.67000000000007 155.19000000000005
1.0 26.0 287.2470934391022 139.1300000000001 116.27499999999964 129.34500000000003
1.0 27.0 320.2911603450775 109.17000000000075 116.27499999999964 129.34500000000003
1.0 28.0 373.83138251304626 171.25 116.27499999999964 129.34500000000003
1.0 29.0 393.40770530700684 69.16499999999996 98.67000000000007 136.93000000000006
1.0 30.0 506.53151655197144 69.08500000000049 106.18000000000052 194.39999999999964
1.0 31.0 757.3883090019226 149.99 106.18000000000052 194.39999999999964
1.0 32.0 800.8225843906403 17.99000000000069 123.57500000000027 164.43500000000017
1.0 33.0 1284.3142852783203 339.13499999999976 123.57500000000027 164.43500000000017
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4352.74 239.67000000000053 308.35999999999945
0.0 1.0 5.488247632980347 358.0550000000005 239.67000000000053 308.35999999999945
0.0 2.0 10.255433320999146 330.28499999999985 239.67000000000053 308.35999999999945
0.0 3.0 16.03486943244934 78.57499999999982 199.4050000000002 155.54999999999973
0.0 4.0 21.03409695625305 236.09500000000048 307.52 265.37999999999965
0.0 5.0 25.75986337661743 361.66499999999974 307.52 265.37999999999965
0.0 6.0 30.85131597518921 105.39999999999964 834.5 351.87999999999965
0.0 7.0 36.00778007507324 696.6250000000005 396.77499999999964 251.6099999999999
0.0 8.0 41.01295828819275 340.27499999999986 396.77499999999964 251.6099999999999
0.0 9.0 45.427393198013306 237.0650000000005 396.77499999999964 251.6099999999999
0.0 10.0 49.135966062545776 194.80499999999938 396.77499999999964 251.6099999999999
0.0 11.0 52.61057949066162 74.17499999999927 385.40999999999985 249.88000000000056
0.0 12.0 121.43035840988159 58.465000000001055 145.51499999999965 145.9300000000003
0.0 13.0 145.843923330307 222.39999999999964 135.32500000000005 164.76
0.0 14.0 166.03861021995544 217.95000000000005 135.32500000000005 164.76
0.0 15.0 215.77035427093506 133.84000000000015 135.32500000000005 164.76
0.0 16.0 228.18231225013733 45.284999999999854 148.70999999999913 247.96000000000072
0.0 17.0 253.27648043632507 94.03000000000065 135.32500000000005 235.07000000000016
1.0 18.0 258.34868454933167 107.44500000000039 135.32500000000005 235.07000000000016
1.0 19.0 267.0836501121521 51.01999999999998 154.17499999999927 249.45499999999993
1.0 20.0 278.44775104522705 377.2049999999999 115.42999999999984 130.33999999999992
1.0 21.0 282.66388416290283 67.85499999999956 160.23499999999967 247.96000000000072
1.0 22.0 287.11216974258423 152.00999999999976 160.23499999999967 247.96000000000072
1.0 23.0 292.99040699005127 209.4350000000004 160.23499999999967 247.96000000000072
1.0 24.0 488.5403847694397 65.21500000000015 103.01000000000022 164.61499999999978
1.0 25.0 549.897697687149 27.675000000001546 113.78999999999951 176.09999999999968
1.0 26.0 584.0430703163147 196.8849999999993 126.04999999999973 242.6750000000004
1.0 27.0 589.9943401813507 118.85999999999967 126.04999999999973 242.6750000000004
1.0 28.0 595.414370059967 109.5900000000006 126.04999999999973 242.6750000000004
1.0 29.0 600.864958524704 77.62999999999943 140.2750000000001 254.07500000000027
1.0 30.0 607.1771535873413 112.20999999999935 164.875 247.91000000000008
1.0 31.0 613.1823272705078 260.0500000000002 164.875 247.91000000000008
1.0 32.0 693.1692597866058 58.465000000001055 122.8299999999997 159.97999999999956
1.0 33.0 803.1291379928589 369.37499999999955 122.8299999999997 159.97999999999956
1.0 34.0 873.2632145881653 126.48000000000025 122.8299999999997 159.97999999999956
2.0 35.0 938.5448310375214 126.48000000000025 122.8299999999997 159.97999999999956
2.0 36.0 1115.098955154419 61.194999999999936 117.45000000000027 113.03999999999928
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4492.47 148.13999999999987 147.12999999999943
0.0 1.0 7.946127653121948 108.81500000000028 148.13999999999987 147.12999999999943
0.0 2.0 16.056278705596924 196.07999999999947 148.13999999999987 147.12999999999943
0.0 3.0 24.305219650268555 61.94499999999971 143.80499999999938 195.68999999999937
0.0 4.0 33.49943685531616 162.36500000000024 143.80499999999938 238.20000000000005
0.0 5.0 41.38165259361267 108.87999999999988 143.80499999999938 238.20000000000005
0.0 6.0 47.47286558151245 83.63500000000022 152.58499999999958 234.33499999999958
0.0 7.0 54.62684988975525 415.1249999999991 181.06499999999983 193.54999999999973
0.0 8.0 61.119548082351685 265.18000000000006 181.06499999999983 193.54999999999973
0.0 9.0 67.57463884353638 211.23500000000013 181.06499999999983 193.54999999999973
0.0 10.0 76.32516241073608 224.71000000000026 181.06499999999983 193.54999999999973
0.0 11.0 84.48217940330505 113.61000000000013 141.52499999999964 226.72499999999968
0.0 12.0 90.61427354812622 29.09999999999991 117.02000000000044 166.19499999999948
0.0 13.0 95.91677355766296 183.08000000000084 117.02000000000044 166.19499999999948
0.0 14.0 103.6410346031189 180.78999999999996 117.02000000000044 166.19499999999948
0.0 15.0 112.46157598495483 177.3149999999996 117.02000000000044 166.19499999999948
0.0 16.0 120.04749917984009 53.16000000000031 153.60500000000002 166.38499999999954
0.0 17.0 127.02329349517822 71.60499999999956 114.72499999999991 224.73000000000002
1.0 18.0 131.93928861618042 139.75499999999988 114.72499999999991 224.73000000000002
1.0 19.0 137.20928311347961 47.07999999999993 207.35999999999967 261.28500000000054
1.0 20.0 143.83706426620483 417.6550000000002 106.18000000000052 216.0
1.0 21.0 150.73299908638 45.370000000000346 106.18000000000052 216.0
1.0 22.0 157.65427327156067 171.38499999999976 106.18000000000052 216.0
1.0 23.0 164.92253494262695 260.5749999999996 106.18000000000052 216.0
1.0 24.0 172.2166211605072 175.22999999999956 106.01500000000055 226.01499999999987
1.0 25.0 177.8775556087494 25.435000000000855 106.93499999999995 140.7650000000001
1.0 26.0 183.64346575737 185.89999999999918 133.99999999999977 219.0499999999995
1.0 27.0 190.52073645591736 137.4749999999999 133.99999999999977 219.0499999999995
1.0 28.0 195.61376643180847 155.68500000000017 133.99999999999977 219.0499999999995
1.0 29.0 202.02123546600342 66.40999999999985 120.84500000000025 197.08500000000004
1.0 30.0 208.5429985523224 95.72500000000014 126.20499999999993 218.63500000000022
1.0 31.0 214.44771027565002 181.87500000000023 126.20499999999993 218.63500000000022
1.0 32.0 250.7546145915985 37.67499999999973 107.52499999999986 110.44499999999994
1.0 33.0 295.5008931159973 384.27000000000044 107.52499999999986 110.44499999999994
1.0 34.0 314.2360870838165 200.0899999999997 107.52499999999986 110.44499999999994
2.0 35.0 333.6204686164856 200.0899999999997 107.52499999999986 110.44499999999994
2.0 36.0 340.7477583885193 51.01999999999998 117.19000000000051 234.15499999999952
2.0 37.0 347.650915145874 221.39500000000044 117.19000000000051 234.15499999999952
2.0 38.0 356.3320744037628 161.61000000000058 117.19000000000051 234.15499999999952
2.0 39.0 363.0493505001068 122.35000000000036 117.19000000000051 234.15499999999952
2.0 40.0 369.47810673713684 65.60999999999967 117.19000000000051 228.83499999999958
2.0 41.0 375.6040573120117 179.94499999999994 117.19000000000051 228.83499999999958
2.0 42.0 381.94720935821533 87.15000000000009 117.19000000000051 228.83499999999958
2.0 43.0 388.8076207637787 185.86999999999898 161.0899999999997 210.16500000000042
2.0 44.0 395.705593585968 35.73500000000013 136.15499999999975 227.9399999999996
2.0 45.0 461.2370934486389 88.59999999999991 112.11000000000013 184.7700000000002
2.0 46.0 570.4824981689453 267.60499999999956 112.11000000000013 184.7700000000002
2.0 47.0 580.618714094162 434.7450000000008 115.42999999999984 166.87499999999977
2.0 48.0 620.4063053131104 31.80499999999938 93.19500000000016 170.39499999999998
2.0 49.0 627.9209549427032 94.03000000000065 115.8449999999998 197.08500000000004
2.0 50.0 637.7434532642365 311.8249999999998 115.8449999999998 197.08500000000004
2.0 51.0 645.2396168708801 166.27000000000044 115.8449999999998 197.08500000000004
3.0 52.0 819.4782855510712 66.24500000000012 110.36999999999944 181.1749999999995
3.0 53.0 830.2759659290314 109.90499999999975 115.8449999999998 227.56999999999994
3.0 54.0 840.30610871315 153.28500000000008 115.8449999999998 227.56999999999994
3.0 55.0 850.4796013832092 309.2949999999996 115.8449999999998 227.56999999999994
3.0 56.0 857.999261379242 109.50500000000011 115.8449999999998 227.56999999999994
3.0 57.0 865.9799983501434 144.44999999999982 115.8449999999998 227.56999999999994
3.0 58.0 875.6231665611267 166.27000000000044 115.8449999999998 227.56999999999994
3.0 59.0 890.0760960578918 450.99000000000024 107.64499999999953 139.2100000000005
3.0 60.0 956.3086402416229 140.67000000000007 107.64499999999953 139.2100000000005
3.0 61.0 968.0794765949249 70.80499999999984 123.61500000000001 177.3199999999997
3.0 62.0 981.9172160625458 386.20999999999935 123.61500000000001 177.3199999999997
3.0 63.0 993.3861393928528 83.5649999999996 222.3699999999992 295.9650000000008
3.0 64.0 1004.2255730628967 49.789999999999964 134.77500000000032 177.3199999999997
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4456.34 131.33500000000004 176.65499999999975
0.0 1.0 4.833607196807861 237.4750000000006 131.33500000000004 176.65499999999975
0.0 2.0 9.179276943206787 182.5899999999997 131.33500000000004 176.65499999999975
0.0 3.0 14.18612289428711 83.4050000000002 174.10999999999967 215.48499999999967
0.0 4.0 18.151867389678955 88.59999999999991 116.61499999999978 164.84500000000025
0.0 5.0 24.5143461227417 157.5 116.61499999999978 164.84500000000025
0.0 6.0 29.620660066604614 64.49500000000035 194.0399999999995 258.64999999999964
0.0 7.0 46.43530035018921 420.5949999999996 386.00999999999976 276.53
0.0 8.0 63.81886601448059 315.9399999999996 386.00999999999976 276.53
0.0 9.0 77.31915760040283 141.68999999999983 386.00999999999976 276.53
0.0 10.0 125.89178347587585 403.3199999999995 386.00999999999976 276.53
0.0 11.0 131.12163066864014 96.54999999999973 409.05499999999984 292.5750000000003
0.0 12.0 137.58273077011108 23.090000000000146 409.05499999999984 295.3049999999996
0.0 13.0 144.52677965164185 144.64000000000033 144.66000000000076 241.19500000000016
0.0 14.0 148.62791299819946 176.92499999999995 144.66000000000076 241.19500000000016
0.0 15.0 152.60557317733765 172.9350000000004 144.66000000000076 241.19500000000016
0.0 16.0 163.8005633354187 41.054999999999836 212.40000000000055 125.82000000000039
0.0 17.0 168.43542885780334 119.5300000000002 160.74500000000035 272.04000000000065
1.0 18.0 172.27106285095215 170.3499999999999 160.74500000000035 272.04000000000065
1.0 19.0 179.41410303115845 52.94999999999936 133.72000000000025 156.66000000000008
1.0 20.0 389.86748147010803 479.69999999999936 307.09500000000025 250.52999999999997
1.0 21.0 395.4427373409271 69.80000000000018 173.8400000000006 280.3599999999997
1.0 22.0 404.1696252822876 281.5750000000005 173.8400000000006 280.3599999999997
1.0 23.0 419.15092611312866 418.9200000000001 173.8400000000006 280.3599999999997
1.0 24.0 423.3212523460388 233.21499999999924 164.5649999999996 249.85000000000014
1.0 25.0 431.12348794937134 215.17000000000053 147.88500000000045 184.87999999999965
1.0 26.0 438.198712348938 235.73000000000047 150.50499999999988 189.2850000000003
1.0 27.0 446.2389576435089 112.73999999999955 150.50499999999988 189.2850000000003
1.0 28.0 458.8664400577545 185.2299999999998 150.50499999999988 189.2850000000003
1.0 29.0 469.3282628059387 101.21000000000004 170.13500000000022 232.46000000000004
1.0 30.0 485.9914562702179 296.59500000000025 155.48500000000013 250.92500000000018
1.0 31.0 500.07366132736206 208.96499999999992 155.48500000000013 250.92500000000018
1.0 32.0 531.9243016242981 91.08500000000004 149.20500000000084 192.1599999999994
1.0 33.0 759.4211480617523 355.8499999999999 149.20500000000084 192.1599999999994
1.0 34.0 1028.4231765270233 240.5800000000006 149.20500000000084 192.1599999999994
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4559.72 88.7800000000002 235.8299999999997
0.0 1.0 5.800784349441528 182.50500000000056 88.7800000000002 235.8299999999997
0.0 2.0 11.337899684906006 175.60500000000002 88.7800000000002 235.8299999999997
0.0 3.0 17.76043438911438 48.60999999999967 123.85499999999979 225.00499999999965
0.0 4.0 22.94169807434082 134.65500000000043 270.345 285.5849999999998
0.0 5.0 27.51239538192749 335.7649999999999 270.345 285.5849999999998
0.0 6.0 32.93112635612488 115.73999999999955 462.9899999999993 387.9249999999995
0.0 7.0 40.40068817138672 566.165 173.45499999999993 169.92500000000018
0.0 8.0 44.871185302734375 300.5 173.45499999999993 169.92500000000018
0.0 9.0 49.111610889434814 178.38999999999942 173.45499999999993 169.92500000000018
0.0 10.0 53.48561906814575 302.12000000000035 173.45499999999993 169.92500000000018
0.0 11.0 57.861451625823975 23.900000000001 106.01500000000055 110.44499999999994
0.0 12.0 71.79252457618713 19.420000000000528 131.3150000000005 169.9699999999998
0.0 13.0 117.42240357398987 148.5 107.17999999999961 127.76999999999975
0.0 14.0 171.8439428806305 228.15999999999963 107.17999999999961 127.76999999999975
0.0 15.0 289.96425700187683 240.79500000000053 107.17999999999961 127.76999999999975
0.0 16.0 293.6249327659607 56.29999999999973 184.28500000000008 258.5949999999998
0.0 17.0 384.6171977519989 60.30000000000018 151.12000000000012 233.35000000000036
1.0 18.0 470.82024002075195 370.8249999999998 151.12000000000012 233.35000000000036
1.0 19.0 474.9741368293762 61.194999999999936 145.34499999999935 169.9699999999998
1.0 20.0 501.3336133956909 408.3449999999989 150.4399999999996 130.0250000000001
1.0 21.0 507.9178583621979 74.65999999999985 135.32500000000005 145.79999999999995
1.0 22.0 524.4505405426025 299.6699999999996 135.32500000000005 145.79999999999995
1.0 23.0 579.2835693359375 215.73999999999978 135.32500000000005 145.79999999999995
1.0 24.0 584.2708902359009 21.63000000000011 98.33500000000026 118.79999999999973
1.0 25.0 589.1291089057922 46.41999999999962 111.13499999999999 125.61000000000058
1.0 26.0 594.200229883194 185.86999999999898 128.9349999999995 196.81499999999937
1.0 27.0 599.8275718688965 102.88999999999987 128.9349999999995 196.81499999999937
1.0 28.0 606.2590801715851 129.57000000000016 128.9349999999995 196.81499999999937
1.0 29.0 617.4140782356262 70.80499999999984 93.11000000000013 127.55999999999995
1.0 30.0 622.9655470848083 71.05500000000029 116.72000000000025 214.32000000000016
1.0 31.0 628.3114540576935 167.5250000000001 116.72000000000025 214.32000000000016
1.0 32.0 636.0492777824402 44.57500000000073 108.91500000000019 151.85499999999956
1.0 33.0 657.8633811473846 369.3200000000006 108.91500000000019 151.85499999999956
1.0 34.0 667.6670291423798 147.72500000000082 108.91500000000019 151.85499999999956
2.0 35.0 677.3025457859039 147.72500000000082 108.91500000000019 151.85499999999956
2.0 36.0 682.8971416950226 98.49499999999944 146.71999999999957 167.20999999999958
2.0 37.0 697.842453956604 373.15999999999985 146.71999999999957 167.20999999999958
2.0 38.0 703.7134985923767 248.67499999999995 146.71999999999957 167.20999999999958
2.0 39.0 710.5645039081573 250.15999999999985 146.71999999999957 167.20999999999958
2.0 40.0 716.3070433139801 97.81500000000005 167.11999999999944 257.5850000000005
2.0 41.0 723.5948302745819 150.0999999999999 167.11999999999944 257.5850000000005
2.0 42.0 730.6442470550537 53.89500000000021 158.2850000000003 250.1850000000004
2.0 43.0 746.8926908969879 196.86499999999978 117.21500000000015 259.77999999999975
2.0 44.0 753.6880524158478 31.440000000000055 103.89999999999986 209.03999999999996
2.0 45.0 761.2339406013489 233.00999999999976 136.29500000000053 337.39500000000044
2.0 46.0 781.5803542137146 168.46499999999992 136.29500000000053 337.39500000000044
2.0 47.0 795.190755367279 565.1100000000001 131.67999999999984 260.34000000000015
2.0 48.0 844.5023283958435 55.23000000000002 177.34500000000025 213.1649999999995
2.0 49.0 852.8885989189148 89.73000000000093 221.5849999999998 375.3850000000002
2.0 50.0 874.2053549289703 344.63500000000045 221.5849999999998 375.3850000000002
2.0 51.0 906.7708790302277 466.47 221.5849999999998 375.3850000000002
3.0 52.0 914.4591794013977 173.50500000000056 227.16499999999996 233.84000000000015
3.0 53.0 1052.0603120326996 342.14499999999975 227.16499999999996 233.84000000000015
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4493.610000000001 211.14999999999986 244.67499999999995
0.0 1.0 6.147852897644043 203.05999999999995 211.14999999999986 244.67499999999995
0.0 2.0 12.691245794296265 207.85500000000047 211.14999999999986 244.67499999999995
0.0 3.0 19.867310047149658 36.16500000000087 232.09999999999968 268.9100000000001
0.0 4.0 25.475099802017212 195.4449999999997 653.5850000000003 344.615
0.0 5.0 30.79648518562317 338.81999999999994 653.5850000000003 344.615
0.0 6.0 44.571921825408936 98.79000000000019 458.33500000000004 268.9100000000001
0.0 7.0 64.74670481681824 417.2149999999999 218.7750000000001 212.86499999999955
0.0 8.0 101.68473267555237 394.05999999999995 218.7750000000001 212.86499999999955
0.0 9.0 131.69837474822998 300.2899999999995 218.7750000000001 212.86499999999955
0.0 10.0 240.58142352104187 365.4249999999997 218.7750000000001 212.86499999999955
0.0 11.0 246.68466091156006 87.59500000000025 121.67000000000007 176.60500000000002
0.0 12.0 254.1175401210785 24.514999999999873 91.86999999999989 103.5799999999997
0.0 13.0 270.0718584060669 204.84500000000025 111.21500000000015 182.22999999999956
0.0 14.0 286.5816345214844 135.40499999999952 111.21500000000015 182.22999999999956
0.0 15.0 299.39680194854736 151.7650000000001 111.21500000000015 182.22999999999956
0.0 16.0 324.3524913787842 100.25 228.69999999999936 193.29499999999985
0.0 17.0 471.5846297740936 117.3700000000008 317.19500000000016 358.6999999999998
1.0 18.0 581.3247730731964 233.85500000000002 317.19500000000016 358.6999999999998
1.0 19.0 663.1158835887909 134.27999999999975 238.38999999999942 187.14999999999964
1.0 20.0 2286.3287892341614 455.1800000000005 391.4350000000002 277.75
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4420.6 205.98000000000002 205.2099999999998
0.0 1.0 6.735805988311768 237.87500000000045 205.98000000000002 205.2099999999998
0.0 2.0 13.305545568466187 275.845 205.98000000000002 205.2099999999998
0.0 3.0 19.16447138786316 49.49000000000024 177.2900000000002 202.2849999999994
0.0 4.0 32.093796491622925 196.58500000000004 116.61499999999978 196.9949999999999
0.0 5.0 55.04893088340759 193.1500000000001 116.61499999999978 196.9949999999999
0.0 6.0 85.1015739440918 112.91499999999974 247.3499999999999 238.42000000000007
0.0 7.0 93.491042137146 714.0900000000001 675.2099999999994 551.2949999999998
0.0 8.0 193.26017212867737 403.2000000000003 675.2099999999994 551.2949999999998
0.0 9.0 244.84769439697266 372.44500000000016 675.2099999999994 551.2949999999998
0.0 10.0 267.0577440261841 385.0999999999999 675.2099999999994 551.2949999999998
0.0 11.0 282.622811794281 84.79500000000007 204.3699999999999 288.5049999999994
0.0 12.0 299.50727128982544 65.95000000000027 272.2000000000003 327.71000000000004
0.0 13.0 310.3944535255432 383.11500000000024 338.4649999999997 233.1899999999996
0.0 14.0 315.36585235595703 307.0099999999991 338.4649999999997 233.1899999999996
0.0 15.0 320.9919083118439 247.6099999999999 338.4649999999997 233.1899999999996
0.0 16.0 326.5638349056244 79.58999999999969 190.14500000000044 233.1899999999996
0.0 17.0 332.8583393096924 113.66000000000076 178.27499999999986 180.46999999999957
1.0 18.0 1223.9107546806335 289.6050000000005 178.27499999999986 180.46999999999957
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4513.7 95.52499999999964 148.32999999999993
0.0 1.0 6.525913238525391 108.23500000000013 95.52499999999964 148.32999999999993
0.0 2.0 12.783734798431396 173.1550000000002 95.52499999999964 148.32999999999993
0.0 3.0 20.063753843307495 89.57000000000016 142.49999999999977 274.90000000000055
0.0 4.0 26.09294080734253 306.33500000000004 149.44000000000096 226.72499999999968
0.0 5.0 31.180747985839844 224.5550000000003 149.44000000000096 226.72499999999968
0.0 6.0 38.16054844856262 121.33999999999992 171.71500000000015 126.85000000000014
0.0 7.0 44.1358962059021 534.0799999999997 173.59500000000025 182.22999999999956
0.0 8.0 50.7152841091156 345.74000000000024 173.59500000000025 182.22999999999956
0.0 9.0 56.98129391670227 210.5500000000004 173.59500000000025 182.22999999999956
0.0 10.0 63.94125962257385 226.9100000000003 173.59500000000025 182.22999999999956
0.0 11.0 69.54570031166077 73.72999999999956 102.71000000000004 106.53499999999985
0.0 12.0 74.39631628990173 42.75 88.7800000000002 84.4099999999994
0.0 13.0 79.19110417366028 144.64000000000033 97.01999999999998 84.4099999999994
0.0 14.0 85.84031391143799 208.96499999999992 97.01999999999998 84.4099999999994
0.0 15.0 91.22125554084778 269.7900000000002 97.01999999999998 84.4099999999994
0.0 16.0 105.16428303718567 51.01999999999998 102.38000000000056 134.4250000000004
0.0 17.0 117.75233602523804 89.69999999999982 102.25000000000045 145.22000000000025
1.0 18.0 127.46963453292847 205.46999999999957 102.25000000000045 145.22000000000025
1.0 19.0 133.23129200935364 50.375 106.93499999999995 206.86999999999944
1.0 20.0 177.72882533073425 702.5899999999999 532.1450000000004 333.8299999999997
1.0 21.0 223.52654695510864 60.66499999999951 241.29499999999916 191.24500000000057
1.0 22.0 277.48164558410645 251.70500000000084 241.29499999999916 191.24500000000057
1.0 23.0 399.9036388397217 259.44499999999994 241.29499999999916 191.24500000000057
1.0 24.0 423.1906361579895 301.80499999999984 148.87500000000045 227.51999999999998
1.0 25.0 511.75297141075134 113.02999999999975 162.29999999999973 227.51999999999998
1.0 26.0 793.5457186698914 151.03499999999985 177.04500000000007 139.16999999999962
1.0 27.0 880.5928747653961 100.07999999999993 177.04500000000007 139.16999999999962
1.0 28.0 928.6420133113861 113.03500000000054 177.04500000000007 139.16999999999962
1.0 29.0 1678.0725502967834 112.46000000000095 161.86000000000058 189.3449999999998
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4411.25 192.7100000000005 203.17999999999984
0.0 1.0 6.207644462585449 208.3000000000004 192.7100000000005 203.17999999999984
0.0 2.0 12.414437532424927 274.31500000000074 192.7100000000005 203.17999999999984
0.0 3.0 19.928330659866333 12.474999999999909 109.63499999999999 176.65499999999975
0.0 4.0 26.660338401794434 88.59999999999991 133.72000000000025 176.65499999999975
0.0 5.0 33.78870368003845 185.45000000000027 133.72000000000025 176.65499999999975
0.0 6.0 44.135677337646484 182.09999999999945 351.0949999999996 171.99000000000046
0.0 7.0 52.38212442398071 475.49499999999944 287.22499999999945 210.8649999999991
0.0 8.0 59.815237522125244 442.2099999999996 287.22499999999945 210.8649999999991
0.0 9.0 70.12402987480164 149.19999999999936 287.22499999999945 210.8649999999991
0.0 10.0 83.76207375526428 353.22500000000014 287.22499999999945 210.8649999999991
0.0 11.0 91.25465440750122 128.83499999999958 136.80999999999995 157.20000000000005
0.0 12.0 96.8186297416687 29.609999999999673 128.44000000000028 176.65499999999975
0.0 13.0 102.46377038955688 141.5350000000003 138.2850000000003 165.1400000000001
0.0 14.0 108.55586624145508 287.47499999999945 138.2850000000003 165.1400000000001
0.0 15.0 114.12947964668274 282.6750000000002 138.2850000000003 165.1400000000001
0.0 16.0 119.77904105186462 98.49499999999944 153.31000000000017 199.17500000000064
0.0 17.0 151.20585441589355 113.66000000000076 171.14500000000044 206.0300000000002
1.0 18.0 370.98276233673096 314.9249999999997 171.14500000000044 206.0300000000002
1.0 19.0 465.5255026817322 105.18499999999995 171.14500000000044 206.0300000000002
1.0 20.0 555.5228998661041 610.3449999999998 512.4749999999999 373.26
1.0 21.0 624.7419302463531 67.82499999999982 173.48500000000035 111.19999999999936
1.0 22.0 1018.3137352466583 165.97500000000014 173.48500000000035 111.19999999999936
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4477.35 143.32499999999982 144.72500000000014
0.0 1.0 6.611474514007568 186.1599999999994 143.32499999999982 144.72500000000014
0.0 2.0 12.608407974243164 182.5899999999997 143.32499999999982 144.72500000000014
0.0 3.0 18.72055411338806 53.220000000000255 134.7100000000005 125.12500000000023
0.0 4.0 24.246148109436035 114.02500000000055 117.59499999999957 117.86500000000001
0.0 5.0 29.88359498977661 183.73000000000002 117.59499999999957 117.86500000000001
0.0 6.0 36.219117879867554 54.544999999999845 143.80499999999938 182.22999999999956
0.0 7.0 44.32364058494568 547.1300000000001 521.7099999999998 285.6149999999998
0.0 8.0 66.86302709579468 445.5449999999996 521.7099999999998 285.6149999999998
0.0 9.0 78.2369658946991 458.2149999999997 521.7099999999998 285.6149999999998
0.0 10.0 86.83399558067322 336.9949999999992 521.7099999999998 285.6149999999998
0.0 11.0 92.23079037666321 57.65000000000009 143.80499999999938 226.72499999999968
0.0 12.0 97.1276478767395 11.100000000000364 147.67500000000018 171.02999999999952
0.0 13.0 102.35308766365051 169.39999999999964 93.18500000000017 84.4099999999994
0.0 14.0 110.11486601829529 183.5849999999998 93.18500000000017 84.4099999999994
0.0 15.0 120.16761994361877 301.17500000000064 93.18500000000017 84.4099999999994
0.0 16.0 124.74250316619873 83.00999999999976 90.08500000000026 193.18999999999983
0.0 17.0 129.38884830474854 101.70000000000027 87.09000000000015 178.42500000000018
1.0 18.0 135.01545405387878 275.68500000000085 87.09000000000015 178.42500000000018
1.0 19.0 140.796560049057 82.625 87.09000000000015 178.42500000000018
1.0 20.0 146.3502721786499 602.1050000000002 225.5700000000004 184.00499999999965
1.0 21.0 151.49767351150513 63.095000000000255 225.5700000000004 184.00499999999965
1.0 22.0 156.84231901168823 253.1700000000003 225.5700000000004 184.00499999999965
1.0 23.0 163.11016654968262 270.1999999999996 225.5700000000004 184.00499999999965
1.0 24.0 168.34889674186707 288.44000000000074 111.21500000000015 97.59500000000025
1.0 25.0 174.02161288261414 112.49000000000024 170.95499999999993 229.08500000000004
1.0 26.0 179.14701867103577 232.9199999999987 199.10500000000002 266.20999999999935
1.0 27.0 183.6804382801056 161.33000000000015 199.10500000000002 266.20999999999935
1.0 28.0 188.5114769935608 152.19499999999994 199.10500000000002 266.20999999999935
1.0 29.0 194.7555022239685 98.32000000000016 200.9099999999994 258.64999999999964
1.0 30.0 214.28536534309387 115.44499999999971 176.66499999999996 229.08500000000004
1.0 31.0 219.84538459777832 225.7449999999992 176.66499999999996 229.08500000000004
1.0 32.0 225.47756385803223 29.609999999999673 148.86000000000013 173.08500000000004
1.0 33.0 233.41051077842712 466.27999999999884 148.86000000000013 173.08500000000004
1.0 34.0 244.7929663658142 259.80999999999995 148.86000000000013 173.08500000000004
2.0 35.0 255.5205204486847 259.80999999999995 148.86000000000013 173.08500000000004
2.0 36.0 261.98728609085083 66.20000000000005 145.0099999999993 181.01999999999975
2.0 37.0 270.4388072490692 381.3100000000004 145.0099999999993 181.01999999999975
2.0 38.0 277.5851800441742 218.82500000000027 145.0099999999993 181.01999999999975
2.0 39.0 284.831835269928 152.84000000000015 145.0099999999993 181.01999999999975
2.0 40.0 290.69299817085266 90.07999999999947 186.82500000000073 246.0849999999998
2.0 41.0 296.2266387939453 172.1500000000001 186.82500000000073 246.0849999999998
2.0 42.0 302.57192730903625 205.40999999999985 186.82500000000073 246.0849999999998
2.0 43.0 308.0616080760956 276.0649999999996 237.52500000000055 240.55000000000064
2.0 44.0 314.0667037963867 97.26000000000022 367.4300000000003 261.4799999999998
2.0 45.0 320.9381353855133 232.30499999999984 474.34500000000025 219.08999999999992
2.0 46.0 350.18781757354736 242.28499999999963 474.34500000000025 219.08999999999992
2.0 47.0 681.7322256565094 459.5399999999995 182.21500000000015 180.46999999999957
2.0 48.0 1475.1405124664307 62.07999999999993 176.12000000000012 131.60000000000014
