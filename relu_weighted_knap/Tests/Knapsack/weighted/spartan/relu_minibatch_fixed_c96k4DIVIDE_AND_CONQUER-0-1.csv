Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7972.999999999999 88.89000000000078 119.18000000000029
0.0 1.0 90.67030143737793 82.66000000000076 88.89000000000078 119.18000000000029
0.0 2.0 146.4126489162445 209.18499999999995 88.89000000000078 119.18000000000029
0.0 3.0 166.57568836212158 102.88000000000056 102.88000000000011 132.43499999999904
0.0 4.0 190.12194442749023 85.02500000000009 98.70500000000038 153.96500000000015
0.0 5.0 261.4324223995209 282.7399999999998 98.70500000000038 153.96500000000015
0.0 6.0 295.2136347293854 221.21999999999935 98.70500000000038 153.96500000000015
0.0 7.0 326.42985010147095 414.83000000000084 95.45499999999993 109.20500000000084
0.0 8.0 448.65190267562866 342.375 95.45499999999993 109.20500000000084
0.0 9.0 503.5175242424011 145.79000000000087 123.59999999999945 145.70000000000027
0.0 10.0 562.322692155838 319.78000000000065 123.59999999999945 145.70000000000027
0.0 11.0 587.7174053192139 119.90499999999975 100.84999999999991 229.6699999999987
0.0 12.0 600.3005681037903 62.51499999999942 138.00499999999874 291.1549999999993
0.0 13.0 654.9310176372528 281.06999999999925 135.71500000000015 348.05000000000064
0.0 14.0 791.505294084549 274.47500000000036 135.71500000000015 348.05000000000064
0.0 15.0 1389.690062046051 339.0249999999992 135.71500000000015 348.05000000000064
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7980.210000000001 92.23000000000047 108.09000000000015
0.0 1.0 35.71885633468628 81.21000000000004 92.23000000000047 108.09000000000015
0.0 2.0 71.63547205924988 178.3699999999999 92.23000000000047 108.09000000000015
0.0 3.0 85.94301962852478 99.16500000000042 112.63500000000022 201.08000000000038
0.0 4.0 115.31999921798706 197.10999999999922 185.64000000000078 286.97500000000036
0.0 5.0 288.8848788738251 367.0500000000002 185.64000000000078 286.97500000000036
0.0 6.0 394.4391031265259 229.37499999999955 185.64000000000078 286.97500000000036
0.0 7.0 516.8531699180603 529.1300000000006 222.02499999999918 350.74000000000024
0.0 8.0 534.5567343235016 341.78499999999985 222.02499999999918 350.74000000000024
0.0 9.0 616.4332897663116 62.69499999999971 104.18000000000075 149.64999999999964
0.0 10.0 665.4286386966705 313.61500000000115 104.18000000000075 149.64999999999964
0.0 11.0 707.5935804843903 115.22000000000071 73.06500000000051 96.98500000000013
0.0 12.0 807.4591603279114 92.40999999999985 103.42499999999973 149.64999999999964
0.0 13.0 922.7699091434479 132.0850000000005 97.08500000000049 132.18499999999813
0.0 14.0 1027.934611082077 177.39499999999953 97.08500000000049 132.18499999999813
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7988.46 92.88000000000147 90.80499999999938
0.0 1.0 30.13280963897705 72.98999999999978 92.88000000000147 90.80499999999938
0.0 2.0 41.25825381278992 173.07999999999993 92.88000000000147 90.80499999999938
0.0 3.0 53.6105682849884 102.88000000000056 102.33000000000038 90.80499999999938
0.0 4.0 64.15230178833008 115.97499999999945 198.95999999999867 334.2700000000009
0.0 5.0 73.24030494689941 367.0500000000002 198.95999999999867 334.2700000000009
0.0 6.0 84.12151885032654 354.6750000000011 198.95999999999867 334.2700000000009
0.0 7.0 104.92599892616272 569.2900000000018 302.7699999999995 300.58999999999924
0.0 8.0 114.29129433631897 646.1349999999984 302.7699999999995 300.58999999999924
0.0 9.0 122.87355136871338 192.82500000000027 611.7600000000002 784.5649999999996
0.0 10.0 213.77494597434998 728.474999999999 611.7600000000002 784.5649999999996
0.0 11.0 223.61916971206665 105.35000000000036 103.29999999999927 124.49000000000069
0.0 12.0 232.82188320159912 112.68999999999915 83.40999999999894 94.65499999999929
0.0 13.0 243.35916018486023 165.52999999999975 89.4399999999996 102.22000000000025
0.0 14.0 253.00192975997925 178.63500000000113 89.4399999999996 102.22000000000025
0.0 15.0 261.69033765792847 270.14500000000044 89.4399999999996 102.22000000000025
0.0 16.0 271.315105676651 76.51999999999907 83.86999999999898 105.17500000000064
0.0 17.0 281.72359466552734 108.40499999999975 274.37000000000126 1748.0400000000013
1.0 18.0 290.4832806587219 2432.7800000000016 274.37000000000126 1748.0400000000013
1.0 19.0 300.54201579093933 71.85999999999922 82.87499999999955 101.22499999999991
1.0 20.0 313.05729722976685 379.3050000000012 165.07500000000027 296.31500000000096
1.0 21.0 323.92043375968933 83.62500000000091 102.16499999999996 172.95499999999947
1.0 22.0 336.32043409347534 107.04499999999916 99.23999999999978 191.61000000000013
1.0 23.0 349.4992537498474 397.6400000000008 99.23999999999978 191.61000000000013
1.0 24.0 360.35795545578003 192.41999999999962 249.1649999999986 588.0650000000014
1.0 25.0 759.6467604637146 108.40000000000009 93.75999999999976 214.94999999999936
1.0 26.0 2357.0984127521515 303.2350000000006 200.10999999999967 339.7199999999998
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7980.210000000001 82.44999999999845 119.04500000000053
0.0 1.0 11.19478988647461 78.80499999999938 82.44999999999845 119.04500000000053
0.0 2.0 18.526881456375122 142.8799999999992 82.44999999999845 119.04500000000053
0.0 3.0 27.32919692993164 64.75500000000147 84.04999999999973 94.86000000000058
0.0 4.0 39.18285608291626 283.8349999999996 132.16999999999962 200.7400000000007
0.0 5.0 308.6928005218506 382.06999999999925 132.16999999999962 200.7400000000007
0.0 6.0 347.3655285835266 245.83499999999913 132.16999999999962 200.7400000000007
0.0 7.0 396.2449617385864 483.6149999999998 251.43500000000085 291.09000000000106
0.0 8.0 441.30541729927063 375.63999999999805 251.43500000000085 291.09000000000106
0.0 9.0 487.2040026187897 87.83499999999913 151.0350000000003 116.07499999999982
0.0 10.0 543.8365547657013 336.4150000000013 151.0350000000003 116.07499999999982
0.0 11.0 585.2155566215515 130.10000000000218 210.0950000000007 344.7950000000001
0.0 12.0 687.8391849994659 106.34999999999854 157.83999999999924 293.7049999999999
0.0 13.0 865.4434406757355 353.1750000000002 156.9949999999999 240.31999999999925
0.0 14.0 927.8742756843567 199.25999999999976 156.9949999999999 240.31999999999925
0.0 15.0 935.588769197464 166.69999999999845 156.9949999999999 240.31999999999925
0.0 16.0 941.5733320713043 81.60999999999967 113.30499999999984 158.80000000000018
0.0 17.0 948.2119345664978 204.04500000000098 149.04500000000098 409.7100000000005
1.0 18.0 953.4747755527496 546.3449999999984 149.04500000000098 409.7100000000005
1.0 19.0 959.901837348938 76.75 493.65499999999884 476.8299999999999
1.0 20.0 1968.7865977287292 543.3900000000003 230.73499999999876 264.46000000000095
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7971.5599999999995 90.87500000000091 94.86000000000058
0.0 1.0 9.892071962356567 97.27999999999929 90.87500000000091 94.86000000000058
0.0 2.0 20.47635507583618 194.0399999999995 90.87500000000091 94.86000000000058
0.0 3.0 31.07196831703186 84.03999999999996 78.02999999999884 97.36500000000024
0.0 4.0 41.84647488594055 155.46999999999844 116.51000000000022 242.2700000000009
0.0 5.0 51.9900164604187 303.23 116.51000000000022 242.2700000000009
0.0 6.0 62.51207947731018 236.78499999999894 116.51000000000022 242.2700000000009
0.0 7.0 78.66743040084839 565.4399999999996 226.52499999999964 342.80499999999984
0.0 8.0 96.15197443962097 427.0899999999988 226.52499999999964 342.80499999999984
0.0 9.0 108.85150003433228 112.1949999999988 124.5 108.31500000000005
0.0 10.0 143.43009495735168 383.0050000000001 124.5 108.31500000000005
0.0 11.0 170.40822672843933 189.92000000000053 155.9650000000006 145.4399999999996
0.0 12.0 197.38991236686707 76.43499999999949 166.86500000000024 236.025000000001
0.0 13.0 210.8943567276001 354.28499999999985 156.68000000000075 402.9099999999994
0.0 14.0 223.75217723846436 355.9500000000003 156.68000000000075 402.9099999999994
0.0 15.0 235.9085078239441 444.8649999999989 156.68000000000075 402.9099999999994
0.0 16.0 246.30914044380188 85.08499999999822 124.5049999999992 242.88499999999976
0.0 17.0 254.5418734550476 132.05499999999938 162.95000000000073 519.1349999999989
1.0 18.0 261.98635697364807 500.0 162.95000000000073 519.1349999999989
1.0 19.0 269.3965768814087 130.83000000000084 121.85000000000036 247.3650000000016
1.0 20.0 277.1990489959717 558.1050000000005 186.75000000000227 539.1749999999997
1.0 21.0 285.4940960407257 103.5600000000004 127.99000000000024 376.47999999999865
1.0 22.0 293.9842052459717 119.14499999999862 98.94499999999971 230.7849999999985
1.0 23.0 302.1141142845154 331.70500000000084 98.94499999999971 230.7849999999985
1.0 24.0 312.40676951408386 166.05000000000018 125.57999999999993 241.57499999999936
1.0 25.0 323.7702798843384 294.73000000000184 150.6500000000001 417.1799999999989
1.0 26.0 331.2679145336151 453.9450000000011 239.93500000000085 475.2049999999995
1.0 27.0 339.4532651901245 349.81000000000085 239.93500000000085 475.2049999999995
1.0 28.0 347.48992228507996 515.264999999999 239.93500000000085 475.2049999999995
1.0 29.0 355.90209341049194 116.96999999999844 154.8449999999998 450.61500000000024
1.0 30.0 364.0510606765747 372.3250000000021 154.8449999999998 450.61500000000024
1.0 31.0 372.57883048057556 276.50499999999965 154.8449999999998 450.61500000000024
1.0 32.0 382.0336639881134 124.2549999999992 146.91999999999962 428.5199999999991
1.0 33.0 392.105345249176 444.2299999999991 146.91999999999962 428.5199999999991
1.0 34.0 401.5660719871521 335.47500000000036 146.91999999999962 428.5199999999991
2.0 35.0 410.9787073135376 335.47500000000036 146.91999999999962 428.5199999999991
2.0 36.0 421.7815525531769 90.34000000000015 112.03000000000065 159.8750000000009
2.0 37.0 430.97803378105164 529.005000000001 112.03000000000065 159.8750000000009
2.0 38.0 439.78240275382996 278.375 112.03000000000065 159.8750000000009
2.0 39.0 448.1624708175659 314.83000000000084 112.03000000000065 159.8750000000009
2.0 40.0 457.40189266204834 294.73000000000184 146.91999999999962 325.7149999999997
2.0 41.0 466.5702476501465 122.36499999999887 162.62500000000045 217.92500000000064
2.0 42.0 475.63549184799194 278.4899999999998 162.62500000000045 217.92500000000064
2.0 43.0 485.4282464981079 366.494999999999 233.94000000000005 453.65000000000146
2.0 44.0 494.9021372795105 125.04500000000007 154.61000000000013 403.2949999999996
2.0 45.0 504.4469530582428 356.73499999999876 198.83499999999913 238.07999999999993
2.0 46.0 513.8680355548859 293.82000000000016 198.83499999999913 238.07999999999993
2.0 47.0 524.2672605514526 462.2200000000007 147.60999999999967 347.25000000000045
2.0 48.0 535.2190079689026 128.6849999999995 179.32000000000062 417.43999999999915
2.0 49.0 547.1238396167755 143.96499999999924 183.34500000000025 450.61500000000024
2.0 50.0 558.6275219917297 444.2299999999991 183.34500000000025 450.61500000000024
2.0 51.0 571.6926379203796 330.7900000000009 183.34500000000025 450.61500000000024
3.0 52.0 582.5985970497131 286.829999999999 212.97499999999945 244.31499999999915
3.0 53.0 593.4431607723236 311.0799999999999 212.97499999999945 244.31499999999915
3.0 54.0 604.5670874118805 369.0399999999995 212.97499999999945 244.31499999999915
3.0 55.0 615.5093493461609 647.25 212.97499999999945 244.31499999999915
3.0 56.0 627.6928765773773 330.4499999999998 163.17999999999984 450.61500000000024
3.0 57.0 639.0521121025085 144.42999999999938 183.04500000000053 208.9950000000008
3.0 58.0 650.6309442520142 162.70000000000073 183.04500000000053 208.9950000000008
3.0 59.0 665.1327292919159 570.8250000000007 307.56000000000085 467.6049999999991
3.0 60.0 677.4502272605896 410.37000000000035 307.56000000000085 467.6049999999991
3.0 61.0 689.7673332691193 233.32000000000153 215.32999999999993 504.42999999999984
3.0 62.0 703.0064260959625 496.88499999999976 215.32999999999993 504.42999999999984
3.0 63.0 715.1827471256256 122.96000000000004 153.27499999999964 428.5199999999991
3.0 64.0 727.5064511299133 206.10500000000093 215.6600000000003 386.95500000000084
3.0 65.0 740.158940076828 154.54000000000087 163.14500000000044 355.9750000000013
3.0 66.0 752.6682636737823 276.50499999999965 163.14500000000044 355.9750000000013
3.0 67.0 763.9938423633575 419.1750000000002 229.1500000000001 362.1250000000009
3.0 68.0 775.9464712142944 529.4499999999989 229.1500000000001 362.1250000000009
4.0 69.0 788.4179854393005 413.89500000000044 178.05999999999995 347.13499999999885
4.0 70.0 800.5872533321381 404.2500000000009 178.05999999999995 347.13499999999885
4.0 71.0 812.8983144760132 239.02000000000135 148.33500000000004 450.61500000000024
4.0 72.0 825.4385395050049 143.96499999999924 149.23000000000093 352.1400000000008
4.0 73.0 837.8094568252563 469.75999999999976 149.23000000000093 352.1400000000008
4.0 74.0 850.3997967243195 322.16000000000076 149.23000000000093 352.1400000000008
4.0 75.0 862.7817153930664 355.48 149.23000000000093 352.1400000000008
4.0 76.0 876.8125195503235 125.6899999999996 162.62500000000045 273.00999999999976
4.0 77.0 889.9737496376038 104.62499999999909 148.33500000000004 428.5199999999991
4.0 78.0 902.4347813129425 113.025000000001 156.51499999999987 250.0900000000006
4.0 79.0 915.9880812168121 552.1500000000005 175.32000000000016 467.6049999999991
4.0 80.0 929.7049989700317 332.5199999999995 175.32000000000016 467.6049999999991
4.0 81.0 943.4540586471558 493.19999999999936 175.32000000000016 467.6049999999991
4.0 82.0 956.9814693927765 321.9250000000011 171.14499999999998 250.37000000000035
4.0 83.0 971.0509459972382 107.47500000000036 233.1899999999996 487.69499999999925
4.0 84.0 985.4374940395355 320.20500000000084 233.1899999999996 487.69499999999925
4.0 85.0 999.8204712867737 269.6500000000001 233.1899999999996 487.69499999999925
5.0 86.0 1013.9700217247009 147.0799999999972 138.80000000000018 467.6049999999991
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7980.819999999999 82.44999999999845 86.93999999999915
0.0 1.0 24.12975549697876 82.32499999999891 82.44999999999845 86.93999999999915
0.0 2.0 34.651463747024536 192.5900000000006 82.44999999999845 86.93999999999915
0.0 3.0 49.48755216598511 76.46500000000015 89.80500000000075 103.01999999999998
0.0 4.0 64.91172075271606 140.9699999999998 96.23000000000093 131.15999999999894
0.0 5.0 145.8429365158081 199.54999999999973 96.23000000000093 131.15999999999894
0.0 6.0 257.80326533317566 205.70000000000073 96.23000000000093 131.15999999999894
0.0 7.0 283.70587277412415 376.01000000000204 126.14999999999918 99.27999999999975
0.0 8.0 334.9907314777374 375.52000000000044 126.14999999999918 99.27999999999975
0.0 9.0 359.6920030117035 118.70499999999993 95.24999999999864 88.99999999999955
0.0 10.0 391.3397831916809 314.8600000000006 95.24999999999864 88.99999999999955
0.0 11.0 401.0832767486572 115.92999999999938 87.71000000000049 115.71000000000004
0.0 12.0 417.76066875457764 64.04500000000007 118.9099999999994 179.61500000000024
0.0 13.0 428.67446303367615 115.84499999999935 107.54499999999916 221.85499999999956
0.0 14.0 434.078164100647 241.37500000000136 107.54499999999916 221.85499999999956
0.0 15.0 439.8675000667572 259.8549999999982 107.54499999999916 221.85499999999956
0.0 16.0 445.96094965934753 157.10999999999967 120.95500000000038 166.7100000000005
0.0 17.0 453.3160469532013 170.27499999999873 120.95500000000038 166.7100000000005
1.0 18.0 458.7445077896118 270.7549999999983 120.95500000000038 166.7100000000005
1.0 19.0 464.86514139175415 157.10999999999967 120.95500000000038 166.7100000000005
1.0 20.0 494.7797963619232 503.59000000000106 345.1849999999995 469.78999999999996
1.0 21.0 528.6159248352051 140.14999999999964 126.75000000000045 134.96000000000004
1.0 22.0 851.526941537857 198.61999999999944 126.75000000000045 134.96000000000004
1.0 23.0 1186.8989639282227 550.0749999999994 126.75000000000045 134.96000000000004
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7977.650000000001 92.93500000000085 101.34999999999945
0.0 1.0 12.435667276382446 83.04499999999962 92.93500000000085 101.34999999999945
0.0 2.0 25.679027795791626 177.19000000000005 92.93500000000085 101.34999999999945
0.0 3.0 34.88713073730469 93.88500000000022 163.7849999999994 307.0700000000006
0.0 4.0 43.609936237335205 84.88000000000011 119.44000000000005 207.11999999999898
0.0 5.0 52.34775233268738 311.375 119.44000000000005 207.11999999999898
0.0 6.0 63.830849409103394 250.92999999999847 119.44000000000005 207.11999999999898
0.0 7.0 71.82005667686462 615.21 376.71000000000004 679.0749999999989
0.0 8.0 79.34931468963623 618.3299999999995 376.71000000000004 679.0749999999989
0.0 9.0 86.53988337516785 78.11499999999978 137.48999999999887 131.69499999999925
0.0 10.0 98.11458945274353 304.47000000000025 137.48999999999887 131.69499999999925
0.0 11.0 106.41444444656372 156.79500000000007 132.16999999999962 117.16000000000031
0.0 12.0 113.80413937568665 100.29999999999927 217.9250000000011 308.5749999999998
0.0 13.0 242.05614614486694 154.7150000000015 100.53999999999951 122.67999999999984
0.0 14.0 451.93862748146057 179.9149999999995 100.53999999999951 122.67999999999984
0.0 15.0 644.1201524734497 279.7799999999993 100.53999999999951 122.67999999999984
0.0 16.0 722.1188650131226 86.38500000000022 121.73499999999922 195.4649999999997
0.0 17.0 972.2108340263367 108.40499999999975 148.75499999999965 438.74499999999944
1.0 18.0 1335.9707207679749 340.1799999999994 148.75499999999965 438.74499999999944
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7990.830000000002 81.61999999999944 109.73500000000104
0.0 1.0 13.479706525802612 94.29499999999916 81.61999999999944 109.73500000000104
0.0 2.0 26.98213267326355 196.57500000000073 81.61999999999944 109.73500000000104
0.0 3.0 41.942453384399414 69.96000000000095 115.28999999999905 90.43499999999995
0.0 4.0 58.829017877578735 73.17999999999984 100.94500000000107 119.18000000000029
0.0 5.0 124.19265246391296 197.50999999999885 100.94500000000107 119.18000000000029
0.0 6.0 139.48676466941833 103.06499999999824 100.94500000000107 119.18000000000029
0.0 7.0 155.5882546901703 594.5200000000013 277.1100000000001 372.3900000000008
0.0 8.0 208.33644914627075 358.72499999999854 277.1100000000001 372.3900000000008
0.0 9.0 254.32565093040466 126.40000000000055 121.42000000000053 130.91499999999905
0.0 10.0 267.67252373695374 416.58500000000004 121.42000000000053 130.91499999999905
0.0 11.0 281.7101080417633 156.79500000000007 146.14499999999998 220.42000000000098
0.0 12.0 295.0483877658844 82.10000000000036 111.93499999999949 195.68499999999858
0.0 13.0 307.3968243598938 157.33999999999924 124.33500000000004 170.69499999999925
0.0 14.0 318.48435068130493 248.57999999999993 124.33500000000004 170.69499999999925
0.0 15.0 329.09129881858826 403.5149999999999 124.33500000000004 170.69499999999925
0.0 16.0 342.3632912635803 141.33500000000095 115.25499999999965 189.70999999999867
0.0 17.0 354.67153692245483 108.40499999999975 94.65999999999985 205.31999999999925
1.0 18.0 366.41086196899414 323.65000000000055 94.65999999999985 205.31999999999925
1.0 19.0 378.19808888435364 90.19500000000016 110.97499999999991 131.28499999999985
1.0 20.0 389.5716030597687 472.56000000000176 126.35999999999922 251.61500000000024
1.0 21.0 401.5963170528412 125.91000000000076 143.03499999999894 157.0599999999995
1.0 22.0 412.34842443466187 90.19000000000005 110.53999999999951 158.80000000000018
1.0 23.0 424.0902507305145 464.4400000000005 110.53999999999951 158.80000000000018
1.0 24.0 435.91204023361206 115.59000000000015 116.41499999999905 158.80000000000018
1.0 25.0 447.4690110683441 114.9300000000012 111.3799999999992 157.0599999999995
1.0 26.0 490.7656309604645 339.0749999999998 116.01000000000113 248.29499999999962
1.0 27.0 529.185329914093 88.24999999999955 116.01000000000113 248.29499999999962
1.0 28.0 582.4620895385742 223.51999999999907 116.01000000000113 248.29499999999962
1.0 29.0 593.7313120365143 122.60000000000036 112.99000000000024 212.83500000000004
1.0 30.0 604.2763237953186 104.99499999999989 112.99000000000024 212.83500000000004
1.0 31.0 615.4022431373596 213.08500000000276 112.99000000000024 212.83500000000004
1.0 32.0 627.1635315418243 141.11000000000013 107.38999999999942 149.58999999999924
1.0 33.0 648.0461752414703 314.5849999999991 107.38999999999942 149.58999999999924
1.0 34.0 673.8612892627716 168.92999999999938 107.38999999999942 149.58999999999924
2.0 35.0 698.892492055893 168.92999999999938 107.38999999999942 149.58999999999924
2.0 36.0 711.3397696018219 89.52499999999964 101.11000000000058 207.46500000000015
2.0 37.0 751.8427715301514 362.8900000000008 101.11000000000058 207.46500000000015
2.0 38.0 767.1851303577423 176.6849999999995 101.11000000000058 207.46500000000015
2.0 39.0 785.1837766170502 181.4749999999981 101.11000000000058 207.46500000000015
2.0 40.0 797.0505352020264 114.9300000000012 102.29500000000053 124.53999999999996
2.0 41.0 819.2789850234985 72.57000000000107 93.16000000000031 135.41999999999962
2.0 42.0 841.8808019161224 117.37500000000091 93.16000000000031 135.41999999999962
2.0 43.0 948.5208222866058 291.09000000000015 125.03999999999996 240.31999999999925
2.0 44.0 981.608323097229 165.4449999999997 149.08999999999924 340.6099999999997
2.0 45.0 1031.3199663162231 211.70500000000175 149.08999999999924 340.6099999999997
