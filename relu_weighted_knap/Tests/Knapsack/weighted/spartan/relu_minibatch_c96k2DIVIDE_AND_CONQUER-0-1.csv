Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7423.38 170.67999999999984 514.0500000000011
0.0 1.0 9.67538070678711 540.4800000000009 170.67999999999984 514.0500000000011
0.0 2.0 15.911618947982788 336.1349999999993 170.67999999999984 514.0500000000011
0.0 3.0 22.825368642807007 294.3599999999983 274.81499999999915 912.7750000000015
0.0 4.0 31.555891752243042 500.5799999999999 274.81499999999915 912.7750000000015
0.0 5.0 51.79202437400818 315.97500000000036 274.81499999999915 912.7750000000015
0.0 6.0 64.25680494308472 479.4899999999998 274.81499999999915 912.7750000000015
0.0 7.0 70.25723361968994 93.71499999999878 313.75999999999976 877.625
0.0 8.0 77.32386207580566 648.2749999999996 313.75999999999976 877.625
0.0 9.0 92.70274591445923 775.5049999999997 313.75999999999976 877.625
0.0 10.0 98.80368447303772 306.78499999999894 313.75999999999976 877.625
0.0 11.0 103.34060144424438 197.38999999999987 189.59500000000025 513.1999999999998
0.0 12.0 112.12718152999878 161.57500000000027 233.77000000000044 632.3650000000002
0.0 13.0 123.65646600723267 114.28999999999951 184.9399999999987 629.659999999999
0.0 14.0 129.33167815208435 59.83499999999913 148.68499999999995 489.1350000000002
0.0 15.0 142.07999277114868 185.82499999999982 148.68499999999995 489.1350000000002
0.0 16.0 179.1728093624115 470.13499999999885 148.68499999999995 489.1350000000002
0.0 17.0 245.36163330078125 290.3299999999999 161.2199999999998 509.34000000000015
1.0 18.0 325.4544241428375 190.8849999999993 161.2199999999998 509.34000000000015
1.0 19.0 452.5126202106476 451.1999999999989 161.2199999999998 509.34000000000015
1.0 20.0 469.2876675128937 107.95499999999947 140.06999999999925 546.5450000000005
1.0 21.0 480.8242428302765 270.5100000000002 185.23999999999887 575.0349999999994
1.0 22.0 521.2056615352631 245.0049999999992 144.61000000000058 409.9349999999995
1.0 23.0 562.5185668468475 119.26499999999987 144.61000000000058 409.9349999999995
1.0 24.0 615.5685577392578 47.07499999999982 137.25 541.0950000000012
1.0 25.0 1002.1679358482361 120.48500000000058 203.82499999999982 669.5449999999992
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7443.19 207.7849999999994 561.5149999999994
0.0 1.0 28.860937356948853 301.08999999999924 190.29500000000007 722.5799999999999
0.0 2.0 41.81379270553589 314.99500000000035 190.29500000000007 722.5799999999999
0.0 3.0 61.48486542701721 235.96500000000015 194.67500000000018 599.8049999999994
0.0 4.0 134.7872211933136 126.71999999999935 90.57000000000153 471.97999999999956
0.0 5.0 142.37344646453857 112.96999999999889 90.57000000000153 471.97999999999956
0.0 6.0 150.23169660568237 267.6650000000004 90.57000000000153 471.97999999999956
0.0 7.0 155.93140625953674 118.93499999999995 142.19500000000062 483.3500000000008
0.0 8.0 162.24755954742432 236.37000000000035 142.19500000000062 483.3500000000008
0.0 9.0 168.2908833026886 291.6749999999997 97.19500000000062 398.08500000000095
0.0 10.0 173.64789056777954 84.3149999999996 97.19500000000062 398.08500000000095
0.0 11.0 405.4609651565552 115.599999999999 161.88999999999987 541.7050000000008
0.0 12.0 630.4804084300995 176.55499999999984 112.93499999999949 589.335
0.0 13.0 871.3531420230865 113.54999999999973 100.34500000000116 574.1199999999999
0.0 14.0 955.1598765850067 89.47500000000036 119.900000000001 487.5600000000013
0.0 15.0 1087.5589463710785 178.6850000000004 119.900000000001 487.5600000000013
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7313.610000000001 218.9749999999999 561.5149999999994
0.0 1.0 5.522433280944824 688.0350000000008 218.9749999999999 561.5149999999994
0.0 2.0 10.41337513923645 561.2600000000011 218.9749999999999 561.5149999999994
0.0 3.0 18.40160584449768 200.57499999999936 410.6050000000005 1337.0150000000003
0.0 4.0 24.595859050750732 106.10499999999911 144.30999999999813 478.1800000000003
0.0 5.0 30.153835773468018 96.16500000000042 144.30999999999813 478.1800000000003
0.0 6.0 35.67898917198181 284.19500000000016 144.30999999999813 478.1800000000003
0.0 7.0 40.98429822921753 198.58000000000038 238.42499999999836 727.2950000000001
0.0 8.0 48.65143179893494 273.2599999999993 238.42499999999836 727.2950000000001
0.0 9.0 53.32340908050537 367.8349999999996 613.9700000000003 1401.5150000000012
0.0 10.0 66.00740194320679 638.764999999998 613.9700000000003 1401.5150000000012
0.0 11.0 72.42775392532349 184.32999999999902 1172.3450000000003 4917.430000000002
0.0 12.0 78.88556694984436 108.68999999999869 922.3399999999979 6192.055
0.0 13.0 85.64297866821289 179.2599999999975 268.33999999999924 742.7400000000011
0.0 14.0 90.21465945243835 102.91500000000087 193.19000000000005 401.72999999999956
0.0 15.0 94.66971015930176 316.9899999999993 193.19000000000005 401.72999999999956
0.0 16.0 98.76391863822937 424.0500000000002 154.1200000000008 331.59500000000025
0.0 17.0 102.43267607688904 194.0899999999997 143.625 501.96000000000095
1.0 18.0 106.24003767967224 271.8899999999999 143.625 501.96000000000095
1.0 19.0 110.85571789741516 310.63499999999976 112.34000000000015 537.6050000000018
1.0 20.0 115.14612579345703 154.74000000000115 156.0649999999987 508.4549999999999
1.0 21.0 119.30199360847473 221.74499999999944 161.45999999999867 470.8949999999995
1.0 22.0 130.152911901474 220.73500000000058 116.47499999999945 389.85999999999876
1.0 23.0 135.2488090991974 77.41999999999916 116.47499999999945 389.85999999999876
1.0 24.0 144.85772967338562 79.74499999999944 116.47499999999945 389.85999999999876
1.0 25.0 152.57101702690125 112.28999999999951 202.03499999999985 554.8899999999999
1.0 26.0 166.25083589553833 190.9649999999997 202.03499999999985 554.8899999999999
1.0 27.0 189.82635879516602 524.6850000000004 202.03499999999985 554.8899999999999
1.0 28.0 203.23785257339478 88.93000000000075 202.03499999999985 554.8899999999999
1.0 29.0 211.72657799720764 240.86000000000195 202.03499999999985 554.8899999999999
1.0 30.0 235.6519820690155 132.01500000000033 202.03499999999985 554.8899999999999
1.0 31.0 244.3585455417633 239.93500000000085 202.03499999999985 554.8899999999999
1.0 32.0 250.1874544620514 272.0949999999998 212.08999999999924 573.2349999999997
1.0 33.0 310.5903067588806 452.8550000000005 212.08999999999924 573.2349999999997
1.0 34.0 341.9350848197937 368.6700000000005 212.08999999999924 573.2349999999997
2.0 35.0 372.5551199913025 368.6700000000005 212.08999999999924 573.2349999999997
2.0 36.0 401.66042828559875 655.8750000000005 212.08999999999924 573.2349999999997
2.0 37.0 407.6525230407715 181.50499999999965 212.08999999999924 573.2349999999997
2.0 38.0 477.3551814556122 277.0500000000002 212.08999999999924 573.2349999999997
2.0 39.0 490.2347617149353 89.57000000000062 212.08999999999924 573.2349999999997
2.0 40.0 622.8375568389893 109.28999999999951 202.03499999999985 562.3599999999997
2.0 41.0 786.5466704368591 210.4699999999998 146.21500000000106 449.08500000000004
2.0 42.0 808.8110337257385 145.70000000000027 146.21500000000106 449.08500000000004
2.0 43.0 814.342307806015 153.84500000000025 146.21500000000106 449.08500000000004
2.0 44.0 820.416051864624 312.50500000000056 186.30000000000018 527.255000000001
2.0 45.0 926.0329530239105 71.5 164.82000000000062 484.6600000000003
2.0 46.0 934.7805025577545 65.01999999999998 101.60000000000082 401.605
2.0 47.0 965.4716002941132 136.81999999999925 132.69000000000096 474.67999999999984
2.0 48.0 1006.5826652050018 243.58500000000004 101.03000000000065 399.2549999999983
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7521.63 223.84499999999935 498.47499999999945
0.0 1.0 9.490643501281738 325.3150000000014 223.84499999999935 498.47499999999945
0.0 2.0 15.00906753540039 169.92999999999893 223.84499999999935 498.47499999999945
0.0 3.0 21.405044317245483 289.0450000000005 139.00499999999874 362.90999999999894
0.0 4.0 27.33978581428528 114.79499999999962 139.00499999999874 362.90999999999894
0.0 5.0 33.52031373977661 32.16500000000042 139.00499999999874 362.90999999999894
0.0 6.0 38.678510665893555 131.9749999999999 139.00499999999874 362.90999999999894
0.0 7.0 43.23368191719055 73.52500000000055 156.26000000000067 577.2399999999998
0.0 8.0 48.879239320755005 188.4349999999995 156.26000000000067 577.2399999999998
0.0 9.0 53.47028183937073 179.46500000000015 87.73500000000058 362.6200000000008
0.0 10.0 60.13272476196289 91.76499999999987 87.73500000000058 362.6200000000008
0.0 11.0 65.16533637046814 98.48999999999751 100.21999999999935 469.65000000000055
0.0 12.0 69.92875981330872 110.58000000000084 137.25 547.7650000000008
0.0 13.0 74.6618287563324 139.92499999999973 140.4000000000001 611.3150000000005
0.0 14.0 79.01442098617554 239.93500000000085 188.28000000000065 564.1550000000002
0.0 15.0 85.38515210151672 265.24500000000035 188.28000000000065 564.1550000000002
0.0 16.0 94.60548424720764 531.7949999999996 188.28000000000065 564.1550000000002
0.0 17.0 100.29993176460266 223.89000000000033 187.70000000000027 545.5600000000009
1.0 18.0 106.8664038181305 265.24500000000035 187.70000000000027 545.5600000000009
1.0 19.0 116.51126194000244 531.7949999999996 187.70000000000027 545.5600000000009
1.0 20.0 122.72957229614258 180.2150000000006 186.80999999999995 530.6600000000008
1.0 21.0 129.39624762535095 243.12000000000035 241.17500000000064 670.0300000000025
1.0 22.0 174.85056066513062 399.0000000000009 181.65999999999894 576.1900000000019
1.0 23.0 179.65439295768738 104.02999999999975 181.65999999999894 576.1900000000019
1.0 24.0 206.03445553779602 203.71999999999935 181.65999999999894 576.1900000000019
1.0 25.0 219.9669041633606 159.6699999999987 218.94999999999982 579.7400000000002
1.0 26.0 228.48054671287537 208.83500000000004 222.3100000000004 579.7400000000002
1.0 27.0 261.54259157180786 533.4949999999994 222.3100000000004 579.7400000000002
1.0 28.0 271.5570888519287 93.33000000000084 222.3100000000004 579.7400000000002
1.0 29.0 279.95762729644775 303.7900000000013 222.3100000000004 579.7400000000002
1.0 30.0 315.65118980407715 259.30500000000075 222.3100000000004 579.7400000000002
1.0 31.0 322.53784346580505 246.60500000000138 232.57000000000016 668.165
1.0 32.0 338.6326584815979 225.40499999999884 232.57000000000016 717.6299999999992
1.0 33.0 352.5977566242218 444.5150000000003 232.57000000000016 717.6299999999992
1.0 34.0 366.4707283973694 245.24999999999955 232.57000000000016 717.6299999999992
2.0 35.0 379.531126499176 245.24999999999955 232.57000000000016 717.6299999999992
2.0 36.0 397.5659577846527 564.860000000001 232.57000000000016 717.6299999999992
2.0 37.0 403.9600079059601 159.59000000000015 232.57000000000016 717.6299999999992
2.0 38.0 419.28635263442993 277.0000000000009 232.57000000000016 717.6299999999992
2.0 39.0 424.47052097320557 116.47499999999991 232.57000000000016 717.6299999999992
2.0 40.0 437.5035858154297 125.73500000000013 204.14000000000033 609.9200000000001
2.0 41.0 459.88458156585693 197.0 202.03499999999985 562.3599999999997
2.0 42.0 529.7913494110107 145.4399999999996 202.03499999999985 562.3599999999997
2.0 43.0 549.3776643276215 244.9099999999985 217.64999999999964 578.2849999999994
2.0 44.0 607.2870135307312 427.0 222.3100000000004 578.2849999999994
2.0 45.0 827.4872665405273 278.2950000000001 222.3100000000004 578.2849999999994
2.0 46.0 883.571234703064 246.60500000000138 222.3100000000004 578.2849999999994
2.0 47.0 926.4977827072144 243.44000000000005 222.3100000000004 578.2849999999994
2.0 48.0 1060.9908068180084 204.79500000000098 214.51999999999953 578.2849999999994
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7542.670000000001 109.59000000000015 353.49500000000126
0.0 1.0 6.040659427642822 438.55000000000064 109.59000000000015 353.49500000000126
0.0 2.0 11.184313297271729 272.849999999999 109.59000000000015 353.49500000000126
0.0 3.0 18.848533630371094 244.5449999999987 206.11000000000058 466.204999999999
0.0 4.0 25.007683038711548 99.89499999999862 206.11000000000058 466.204999999999
0.0 5.0 37.32194185256958 187.14499999999953 206.11000000000058 466.204999999999
0.0 6.0 43.8459849357605 159.48000000000047 206.11000000000058 466.204999999999
0.0 7.0 51.86769413948059 82.53000000000065 136.95499999999947 378.869999999999
0.0 8.0 69.81743884086609 105.95000000000027 136.95499999999947 378.869999999999
0.0 9.0 76.95665454864502 332.9500000000003 162.10499999999865 480.2699999999986
0.0 10.0 90.28467345237732 108.51499999999987 162.10499999999865 480.2699999999986
0.0 11.0 95.90875124931335 159.38999999999942 182.9099999999994 562.4350000000004
0.0 12.0 136.82014679908752 119.43499999999995 138.22500000000082 529.4399999999996
0.0 13.0 150.000385761261 149.04000000000087 151.3650000000007 554.8899999999999
0.0 14.0 194.7253978252411 119.66999999999916 171.39499999999907 512.0549999999994
0.0 15.0 250.67729449272156 228.60499999999956 171.39499999999907 512.0549999999994
0.0 16.0 376.4075493812561 433.97999999999956 171.39499999999907 512.0549999999994
0.0 17.0 418.17483615875244 350.7349999999992 230.6199999999999 549.3050000000003
1.0 18.0 662.0325500965118 313.06000000000085 230.6199999999999 549.3050000000003
1.0 19.0 746.1212587356567 479.9450000000015 230.6199999999999 549.3050000000003
1.0 20.0 838.9130094051361 141.89499999999998 179.57500000000073 535.585000000001
1.0 21.0 872.1914234161377 264.90999999999804 87.91000000000076 398.8200000000006
1.0 22.0 977.970715045929 281.9399999999987 100.26000000000022 422.4349999999995
1.0 23.0 1131.9148752689362 94.2599999999984 100.26000000000022 422.4349999999995
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7521.63 217.45499999999993 467.23
0.0 1.0 5.953741788864136 300.2950000000005 217.45499999999993 467.23
0.0 2.0 11.381929159164429 205.86000000000013 217.45499999999993 467.23
0.0 3.0 17.637884378433228 129.60499999999956 141.57500000000255 671.3149999999996
0.0 4.0 22.336284160614014 59.87499999999909 107.54500000000007 461.454999999999
0.0 5.0 30.07819652557373 54.059999999999945 107.54500000000007 461.454999999999
0.0 6.0 35.17721199989319 160.15000000000055 107.54500000000007 461.454999999999
0.0 7.0 39.616912841796875 118.35999999999967 350.0500000000011 951.2600000000007
0.0 8.0 53.48856067657471 813.5099999999993 350.0500000000011 951.2600000000007
0.0 9.0 60.6396267414093 150.6800000000003 104.2450000000008 423.2400000000016
0.0 10.0 65.27188181877136 78.0699999999988 104.2450000000008 423.2400000000016
0.0 11.0 71.12718987464905 137.6300000000001 142.78999999999996 573.2049999999999
0.0 12.0 107.93837118148804 209.96499999999924 164.21499999999924 701.550000000002
0.0 13.0 112.87539410591125 113.54999999999973 131.69000000000005 609.6249999999982
0.0 14.0 122.24379539489746 51.91000000000031 116.79999999999927 424.9450000000011
0.0 15.0 202.91507649421692 296.4000000000001 116.79999999999927 424.9450000000011
0.0 16.0 223.36563444137573 417.4849999999997 116.79999999999927 424.9450000000011
0.0 17.0 232.28415155410767 161.7400000000007 204.14000000000033 600.625
1.0 18.0 556.3252131938934 282.65500000000065 204.14000000000033 600.625
1.0 19.0 901.8195009231567 377.93499999999995 204.14000000000033 600.625
1.0 20.0 981.2193729877472 218.55000000000018 165.73499999999876 554.8899999999999
1.0 21.0 2242.123547554016 322.8099999999977 128.11000000000013 464.5350000000017
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7554.749999999998 187.76500000000124 536.5799999999999
0.0 1.0 10.42013669013977 305.7900000000009 194.14999999999918 552.4950000000008
0.0 2.0 19.71212673187256 257.30499999999984 194.14999999999918 552.4950000000008
0.0 3.0 29.419976711273193 206.59999999999945 169.1199999999999 530.4150000000027
0.0 4.0 38.76756691932678 213.14499999999953 169.1199999999999 530.4150000000027
0.0 5.0 49.282225370407104 85.7549999999992 169.1199999999999 530.4150000000027
0.0 6.0 57.57435417175293 245.47499999999945 169.1199999999999 530.4150000000027
0.0 7.0 67.44956135749817 65.21000000000004 140.7199999999998 590.8199999999988
0.0 8.0 79.01966881752014 256.8850000000007 140.7199999999998 590.8199999999988
0.0 9.0 86.60874962806702 307.81500000000096 158.20499999999993 698.9850000000015
0.0 10.0 94.79574012756348 98.94000000000005 158.20499999999993 698.9850000000015
0.0 11.0 102.26435256004333 112.01000000000022 176.72499999999945 644.0949999999989
0.0 12.0 110.4014220237732 160.03999999999996 190.68500000000085 630.4550000000013
0.0 13.0 120.17426466941833 140.9000000000001 207.5850000000005 706.5850000000005
0.0 14.0 128.96870636940002 101.43000000000075 143.2500000000009 462.85499999999956
0.0 15.0 137.89004755020142 254.08500000000004 143.2500000000009 462.85499999999956
0.0 16.0 146.54105925559998 230.79999999999927 138.44500000000016 523.1700000000001
0.0 17.0 157.46409273147583 60.88500000000022 134.96000000000004 608.98
1.0 18.0 166.57067704200745 235.58999999999924 134.96000000000004 608.98
1.0 19.0 175.98350715637207 221.9049999999993 165.41500000000042 659.0599999999995
1.0 20.0 184.4221532344818 68.69000000000005 127.29000000000087 607.3950000000009
1.0 21.0 216.73085570335388 171.3199999999997 160.79500000000007 682.1150000000011
1.0 22.0 226.89930653572083 191.27999999999975 260.1449999999995 470.1749999999997
1.0 23.0 243.7518129348755 117.72499999999991 260.1449999999995 470.1749999999997
1.0 24.0 251.88998818397522 53.95500000000038 260.1449999999995 470.1749999999997
1.0 25.0 273.4474835395813 186.59000000000106 150.1800000000003 683.3199999999988
1.0 26.0 318.8482756614685 184.67499999999927 185.96500000000015 795.3749999999982
1.0 27.0 430.6693465709686 658.3550000000014 185.96500000000015 795.3749999999982
1.0 28.0 672.7727282047272 204.90999999999985 185.96500000000015 795.3749999999982
1.0 29.0 736.1505968570709 194.0899999999997 566.2600000000007 1234.4050000000007
1.0 30.0 747.4458992481232 956.9350000000004 566.2600000000007 1234.4050000000007
1.0 31.0 758.5075566768646 80.17500000000109 253.71500000000015 488.97999999999956
1.0 32.0 773.4450125694275 179.66999999999962 132.42999999999984 331.99999999999864
1.0 33.0 786.6794414520264 132.11500000000024 132.42999999999984 331.99999999999864
1.0 34.0 799.4985563755035 200.02500000000055 132.42999999999984 331.99999999999864
2.0 35.0 810.756804227829 200.02500000000055 132.42999999999984 331.99999999999864
2.0 36.0 827.0469741821289 298.6899999999996 133.27499999999918 486.52500000000055
2.0 37.0 840.1725018024445 112.05999999999949 133.27499999999918 486.52500000000055
2.0 38.0 862.3754453659058 247.41999999999962 133.27499999999918 486.52500000000055
2.0 39.0 889.9505114555359 170.76500000000033 133.27499999999918 486.52500000000055
2.0 40.0 910.8270783424377 148.8149999999996 132.42999999999984 395.60999999999876
2.0 41.0 926.4538161754608 294.52 131.53499999999985 367.50499999999965
2.0 42.0 940.4701180458069 147.2799999999993 131.53499999999985 367.50499999999965
2.0 43.0 951.6375865936279 183.0749999999989 165.5350000000003 331.99999999999864
2.0 44.0 962.0634155273438 185.11499999999933 153.78000000000065 424.15499999999975
2.0 45.0 980.9806189537048 242.51499999999987 153.78000000000065 424.15499999999975
2.0 46.0 994.9403209686279 50.64500000000044 186.55000000000018 404.0850000000005
2.0 47.0 1005.8338265419006 103.50500000000011 115.90499999999884 390.8200000000006
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 7435.31 220.48000000000002 401.7599999999984
0.0 1.0 7.353592872619629 631.5100000000002 220.48000000000002 401.7599999999984
0.0 2.0 13.50557804107666 342.62999999999965 220.48000000000002 401.7599999999984
0.0 3.0 20.15101909637451 187.06499999999915 135.01999999999998 547.9800000000005
0.0 4.0 26.000568389892578 60.504999999999654 201.5500000000011 576.9749999999995
0.0 5.0 32.881381034851074 157.96000000000004 201.5500000000011 576.9749999999995
0.0 6.0 39.554853677749634 252.35999999999967 201.5500000000011 576.9749999999995
0.0 7.0 45.4228892326355 50.68999999999869 95.01499999999942 345.8450000000016
0.0 8.0 52.23244333267212 161.18499999999995 95.01499999999942 345.8450000000016
0.0 9.0 57.20055150985718 261.8099999999995 86.94499999999971 342.6950000000015
0.0 10.0 62.783406019210815 97.60000000000036 86.94499999999971 342.6950000000015
0.0 11.0 67.21461892127991 93.3449999999998 102.60999999999967 455.51500000000124
0.0 12.0 72.96317863464355 159.71500000000015 96.30000000000018 434.0050000000001
0.0 13.0 84.41211867332458 119.29999999999882 123.95000000000073 529.25
0.0 14.0 230.32935619354248 63.10500000000002 85.48000000000138 363.125
0.0 15.0 239.20639538764954 146.89499999999998 85.48000000000138 363.125
0.0 16.0 323.9435017108917 381.83500000000004 191.79500000000007 504.1850000000022
0.0 17.0 638.7401223182678 371.14999999999964 375.28499999999894 604.5400000000018
1.0 18.0 939.8817007541656 485.1000000000008 375.28499999999894 604.5400000000018
1.0 19.0 1214.2578041553497 428.5599999999995 262.2200000000007 497.8249999999998
