Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 10721.749999999996 123.98499999999876 42.599999999998545
0.0 1.0 9.20326566696167 33.26999999999998 123.98499999999876 42.599999999998545
0.0 2.0 18.153676509857178 33.04999999999745 123.98499999999876 42.599999999998545
0.0 3.0 26.823732376098633 46.36500000000069 123.98499999999876 42.599999999998545
0.0 4.0 35.916918992996216 238.42000000000098 123.98499999999876 42.599999999998545
0.0 5.0 45.33128833770752 61.625 153.08000000000175 60.05999999999858
0.0 6.0 57.82480072975159 289.5150000000003 350.1300000000001 125.47500000000036
0.0 7.0 66.95544290542603 112.44000000000051 138.19999999999982 58.414999999999054
0.0 8.0 93.21372175216675 80.46000000000186 342.22000000000025 207.20499999999902
0.0 9.0 109.11876702308655 117.83999999999924 342.22000000000025 207.20499999999902
0.0 10.0 117.07179808616638 144.5550000000012 240.3349999999973 99.79499999999825
0.0 11.0 125.23220133781433 280.2200000000021 240.3349999999973 99.79499999999825
0.0 12.0 134.84183382987976 188.4950000000017 240.3349999999973 99.79499999999825
0.0 13.0 140.5556764602661 73.19499999999971 105.58999999999924 38.39499999999953
0.0 14.0 146.9322726726532 58.32499999999891 137.16499999999905 60.219999999999345
0.0 15.0 153.4379198551178 35.83999999999833 104.72499999999854 47.6299999999992
0.0 16.0 163.01195001602173 70.19499999999971 104.72499999999854 47.6299999999992
0.0 17.0 169.4664397239685 40.245000000000346 104.72499999999854 47.6299999999992
1.0 18.0 176.30750060081482 35.83999999999833 104.72499999999854 47.6299999999992
1.0 19.0 185.3388955593109 70.19499999999971 104.72499999999854 47.6299999999992
1.0 20.0 193.7888388633728 115.13499999999931 141.3749999999991 92.99499999999898
1.0 21.0 200.23409914970398 91.92999999999938 141.3749999999991 92.99499999999898
1.0 22.0 212.2307014465332 91.88000000000193 141.3749999999991 92.99499999999898
1.0 23.0 219.45850038528442 19.279999999999745 123.90500000000065 61.99999999999818
1.0 24.0 229.58202052116394 289.21000000000186 123.90500000000065 61.99999999999818
1.0 25.0 248.8024845123291 116.24000000000069 123.90500000000065 61.99999999999818
1.0 26.0 309.1492021083832 72.90499999999884 94.90999999999894 33.46499999999833
1.0 27.0 326.7281684875488 20.075000000000728 94.90999999999894 33.46499999999833
1.0 28.0 415.8368773460388 99.20999999999822 156.70499999999902 58.529999999998836
1.0 29.0 546.8157985210419 79.22000000000025 156.70499999999902 58.529999999998836
1.0 30.0 702.8880808353424 176.71500000000015 101.75 39.32499999999891
1.0 31.0 777.4943251609802 69.49500000000262 110.27499999999964 44.61000000000149
1.0 32.0 1369.7365310192108 55.3050000000012 110.27499999999964 44.61000000000149
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 10700.809999999998 97.08500000000004 45.58000000000084
0.0 1.0 10.600348234176636 50.655000000000655 97.08500000000004 45.58000000000084
0.0 2.0 21.49926447868347 27.839999999999236 97.08500000000004 45.58000000000084
0.0 3.0 31.189239740371704 49.13000000000102 97.08500000000004 45.58000000000084
0.0 4.0 41.393471479415894 258.5500000000002 97.08500000000004 45.58000000000084
0.0 5.0 52.54979205131531 91.05499999999938 108.32499999999891 60.55000000000018
0.0 6.0 63.48477816581726 211.82999999999993 111.16000000000076 56.539999999999054
0.0 7.0 73.90460324287415 99.72000000000116 163.3199999999988 71.65999999999985
0.0 8.0 84.8386116027832 74.41500000000087 405.4049999999979 242.9999999999991
0.0 9.0 98.83234405517578 63.215000000001055 405.4049999999979 242.9999999999991
0.0 10.0 109.05380940437317 211.08500000000095 255.17000000000098 299.04999999999836
0.0 11.0 127.69803881645203 518.1499999999992 255.17000000000098 299.04999999999836
0.0 12.0 143.6819143295288 630.5800000000008 255.17000000000098 299.04999999999836
0.0 13.0 153.59642624855042 74.75999999999931 137.59499999999935 119.45499999999902
0.0 14.0 160.85818529129028 91.10499999999956 290.52000000000135 90.64500000000135
0.0 15.0 167.1133110523224 38.01999999999953 130.34500000000025 51.39499999999771
0.0 16.0 173.4887444972992 75.25499999999738 130.34500000000025 51.39499999999771
0.0 17.0 180.02817296981812 104.23999999999978 130.34500000000025 51.39499999999771
1.0 18.0 186.4423656463623 38.01999999999953 130.34500000000025 51.39499999999771
1.0 19.0 193.01800417900085 75.25499999999738 130.34500000000025 51.39499999999771
1.0 20.0 199.18204736709595 62.45500000000084 130.34500000000025 51.39499999999771
1.0 21.0 206.06309270858765 73.19999999999709 130.34500000000025 51.39499999999771
1.0 22.0 212.84062910079956 53.45000000000073 130.34500000000025 51.39499999999771
1.0 23.0 219.8268084526062 198.50500000000193 267.76500000000215 64.81500000000051
1.0 24.0 250.894380569458 456.97499999999854 267.76500000000215 64.81500000000051
1.0 25.0 277.9969871044159 280.8049999999994 267.76500000000215 64.81500000000051
1.0 26.0 285.16374230384827 81.28499999999894 137.66000000000258 44.69999999999982
1.0 27.0 292.3855650424957 23.480000000000473 137.66000000000258 44.69999999999982
1.0 28.0 320.1125445365906 99.20999999999822 287.5099999999993 58.70999999999913
1.0 29.0 327.539528131485 197.92000000000098 287.5099999999993 58.70999999999913
1.0 30.0 334.8269534111023 388.08500000000004 157.47000000000025 58.529999999998836
1.0 31.0 341.7829957008362 107.90499999999975 299.1000000000013 58.70999999999913
1.0 32.0 349.36439323425293 126.36999999999989 299.1000000000013 58.70999999999913
1.0 33.0 356.7579481601715 129.22000000000207 158.77999999999975 58.529999999998836
1.0 34.0 364.3984661102295 53.26999999999862 158.77999999999975 58.529999999998836
2.0 35.0 372.2127468585968 53.26999999999862 158.77999999999975 58.529999999998836
2.0 36.0 380.5001356601715 167.3299999999972 158.77999999999975 58.529999999998836
2.0 37.0 388.1327269077301 93.3700000000008 158.77999999999975 58.529999999998836
2.0 38.0 395.6654107570648 102.51499999999851 183.94500000000062 81.05000000000018
2.0 39.0 403.64362716674805 86.21000000000004 181.72999999999683 57.719999999999345
2.0 40.0 410.97853088378906 164.1300000000001 181.72999999999683 57.719999999999345
2.0 41.0 418.8489873409271 87.71000000000004 181.72999999999683 57.719999999999345
2.0 42.0 427.3859543800354 303.0350000000017 146.29999999999927 78.20000000000073
2.0 43.0 435.65944051742554 139.63500000000022 146.29999999999927 78.20000000000073
2.0 44.0 443.5561776161194 108.375 146.29999999999927 78.20000000000073
2.0 45.0 451.92646837234497 353.6650000000018 146.29999999999927 78.20000000000073
2.0 46.0 460.60079312324524 107.90499999999975 303.83500000000095 58.70999999999913
2.0 47.0 469.33757495880127 131.3199999999988 148.2649999999985 58.529999999998836
2.0 48.0 478.24365282058716 110.49499999999989 148.2649999999985 58.529999999998836
2.0 49.0 487.06561946868896 87.48000000000138 148.2649999999985 58.529999999998836
2.0 50.0 496.4778780937195 172.98999999999978 204.09500000000025 87.7450000000008
2.0 51.0 505.65843987464905 83.48999999999978 204.09500000000025 87.7450000000008
3.0 52.0 514.9576098918915 564.7700000000041 204.09500000000025 87.7450000000008
3.0 53.0 524.5537378787994 327.1950000000006 225.01999999999862 87.7450000000008
3.0 54.0 534.0745403766632 83.98999999999887 225.01999999999862 87.7450000000008
3.0 55.0 543.9306218624115 72.27499999999964 153.3199999999988 61.020000000002256
3.0 56.0 554.463442325592 167.15500000000065 153.3199999999988 61.020000000002256
3.0 57.0 565.8343117237091 103.67500000000018 153.3199999999988 61.020000000002256
3.0 58.0 576.6840977668762 70.57000000000062 153.3199999999988 61.020000000002256
3.0 59.0 588.0043723583221 131.3199999999988 155.35999999999876 56.26999999999862
3.0 60.0 598.6791944503784 86.21000000000004 158.77999999999975 58.529999999998836
3.0 61.0 609.5447196960449 95.85000000000036 158.77999999999975 58.529999999998836
3.0 62.0 620.2456905841827 167.97500000000036 141.97499999999945 81.05000000000018
3.0 63.0 631.1947584152222 105.76999999999953 141.97499999999945 81.05000000000018
3.0 64.0 642.677148103714 153.16499999999996 141.97499999999945 81.05000000000018
3.0 65.0 654.789146900177 109.93499999999949 141.97499999999945 81.05000000000018
3.0 66.0 666.4382419586182 116.50500000000011 157.83499999999822 79.90000000000055
3.0 67.0 677.4841477870941 118.46499999999924 157.83499999999822 79.90000000000055
3.0 68.0 688.7806510925293 110.42999999999847 185.15000000000055 81.13499999999931
4.0 69.0 701.0007231235504 148.82499999999982 185.15000000000055 81.13499999999931
4.0 70.0 712.7146837711334 110.42999999999847 185.15000000000055 81.13499999999931
4.0 71.0 724.4694826602936 209.05999999999767 185.15000000000055 81.13499999999931
4.0 72.0 736.2657721042633 122.34500000000207 185.15000000000055 81.13499999999931
4.0 73.0 748.2052886486053 86.21000000000004 181.72999999999683 61.72000000000298
4.0 74.0 760.2275912761688 62.8199999999988 181.72999999999683 61.72000000000298
4.0 75.0 772.4693744182587 173.28000000000247 157.83499999999822 78.20000000000073
4.0 76.0 785.1032197475433 126.74999999999955 157.83499999999822 78.20000000000073
4.0 77.0 797.1709661483765 106.27499999999964 157.83499999999822 78.20000000000073
4.0 78.0 810.053552865982 153.16499999999996 157.83499999999822 78.20000000000073
4.0 79.0 823.2354962825775 138.47499999999854 132.73999999999978 84.90499999999975
4.0 80.0 836.2262053489685 310.0100000000002 143.91499999999814 74.81500000000051
4.0 81.0 848.6375751495361 71.03999999999905 143.91499999999814 61.020000000002256
4.0 82.0 861.0780544281006 258.5500000000002 143.91499999999814 61.020000000002256
4.0 83.0 873.2654759883881 110.49499999999989 143.91499999999814 61.020000000002256
4.0 84.0 885.9924097061157 53.26999999999862 143.91499999999814 61.020000000002256
4.0 85.0 898.1453130245209 107.90499999999975 291.35999999999694 58.70999999999913
5.0 86.0 911.3294773101807 290.84499999999935 291.35999999999694 58.70999999999913
5.0 87.0 925.0582804679871 111.73999999999978 162.03000000000065 56.26999999999862
5.0 88.0 938.1884167194366 64.37499999999909 162.03000000000065 56.26999999999862
5.0 89.0 952.1442270278931 82.16000000000076 155.35999999999876 56.26999999999862
5.0 90.0 967.2902362346649 131.3199999999988 155.35999999999876 56.26999999999862
5.0 91.0 981.446010351181 53.26999999999862 155.35999999999876 56.26999999999862
5.0 92.0 995.8079929351807 110.49499999999989 155.35999999999876 56.26999999999862
5.0 93.0 1009.8208668231964 86.21000000000004 155.35999999999876 56.26999999999862
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 10700.809999999998 104.72499999999854 38.340000000001055
0.0 1.0 11.269833087921143 45.39499999999862 104.72499999999854 38.340000000001055
0.0 2.0 22.66183614730835 27.839999999999236 104.72499999999854 38.340000000001055
0.0 3.0 50.86272740364075 35.00500000000193 104.72499999999854 38.340000000001055
0.0 4.0 64.00098896026611 176.57999999999902 193.16999999999825 99.59999999999945
0.0 5.0 76.91746282577515 115.57000000000062 209.300000000002 114.40499999999884
0.0 6.0 86.76987886428833 397.3550000000014 313.02500000000055 135.59999999999945
0.0 7.0 98.28282141685486 261.8299999999999 259.90500000000065 96.04499999999916
0.0 8.0 108.89369440078735 204.05999999999676 441.8249999999998 417.1499999999978
0.0 9.0 133.4082543849945 168.96500000000015 441.8249999999998 417.1499999999978
0.0 10.0 143.0266191959381 66.99000000000069 152.875 78.02000000000135
0.0 11.0 465.69694471359253 264.5400000000027 152.875 78.02000000000135
0.0 12.0 512.429696559906 228.64000000000124 152.875 78.02000000000135
0.0 13.0 525.1827168464661 109.86999999999807 186.82499999999982 137.36499999999887
0.0 14.0 3460.872058391571 59.909999999998945 269.5700000000015 39.32499999999891
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 10700.809999999998 94.82000000000062 31.529999999999745
0.0 1.0 10.62888240814209 43.039999999999054 94.82000000000062 31.529999999999745
0.0 2.0 21.396178007125854 36.68499999999767 94.82000000000062 31.529999999999745
0.0 3.0 32.686525106430054 34.779999999999745 94.82000000000062 31.529999999999745
0.0 4.0 43.810410261154175 245.83999999999924 94.82000000000062 31.529999999999745
0.0 5.0 56.57746911048889 177.3800000000001 291.65999999999894 77.06999999999971
0.0 6.0 65.50141716003418 493.704999999999 262.79499999999916 171.07500000000073
0.0 7.0 74.51892971992493 66.08500000000095 156.46000000000095 96.12500000000182
0.0 8.0 83.57310175895691 97.72000000000207 190.22500000000036 128.8199999999997
0.0 9.0 92.25900435447693 103.35500000000229 190.22500000000036 128.8199999999997
0.0 10.0 101.34867191314697 110.4350000000004 188.29999999999927 82.44499999999971
0.0 11.0 109.80256700515747 137.39000000000215 188.29999999999927 82.44499999999971
0.0 12.0 117.94790744781494 67.46500000000196 188.29999999999927 82.44499999999971
0.0 13.0 127.6295747756958 91.03499999999894 146.82500000000073 49.359999999997854
0.0 14.0 136.9453308582306 57.914999999999054 126.12499999999909 57.650000000000546
0.0 15.0 145.69470930099487 33.164999999999964 151.57499999999982 48.62999999999829
0.0 16.0 155.26149320602417 67.3199999999988 151.57499999999982 48.62999999999829
0.0 17.0 164.22280955314636 52.720000000001164 151.57499999999982 48.62999999999829
1.0 18.0 173.4203507900238 33.164999999999964 151.57499999999982 48.62999999999829
1.0 19.0 183.67754244804382 67.3199999999988 151.57499999999982 48.62999999999829
1.0 20.0 192.5853786468506 66.47500000000218 110.25 42.54500000000007
1.0 21.0 202.82690143585205 42.80500000000029 110.25 42.54500000000007
1.0 22.0 235.0756754875183 20.25499999999829 110.25 42.54500000000007
1.0 23.0 246.69097352027893 56.35500000000047 186.23999999999978 72.67000000000007
1.0 24.0 479.515501499176 492.6100000000024 186.23999999999978 72.67000000000007
1.0 25.0 780.1299345493317 279.07999999999856 186.23999999999978 72.67000000000007
1.0 26.0 795.3414070606232 143.9350000000004 166.53500000000076 48.92999999999847
1.0 27.0 1876.829556941986 248.49499999999944 166.53500000000076 48.92999999999847
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 10707.960000000006 114.14499999999862 53.05999999999949
0.0 1.0 11.435414552688599 45.524999999999636 114.14499999999862 53.05999999999949
0.0 2.0 22.058770895004272 27.50999999999931 114.14499999999862 53.05999999999949
0.0 3.0 32.39739441871643 91.05999999999949 114.14499999999862 53.05999999999949
0.0 4.0 43.67688775062561 251.55000000000018 114.14499999999862 53.05999999999949
0.0 5.0 54.43027639389038 65.19999999999891 133.21499999999742 56.98999999999887
0.0 6.0 112.71943831443787 277.0749999999998 125.48499999999876 56.98999999999887
0.0 7.0 122.63159823417664 108.75 106.60499999999956 40.460000000000036
0.0 8.0 132.77420020103455 59.469999999999345 100.97999999999956 43.73499999999967
0.0 9.0 142.32019233703613 37.10500000000047 100.97999999999956 43.73499999999967
0.0 10.0 150.28485941886902 129.35499999999956 257.0699999999997 107.54999999999927
0.0 11.0 161.04768872261047 267.90000000000146 257.0699999999997 107.54999999999927
0.0 12.0 170.992041349411 185.54000000000087 257.0699999999997 107.54999999999927
0.0 13.0 185.70085668563843 96.78499999999894 135.16000000000076 55.20499999999902
0.0 14.0 193.75630402565002 45.32499999999982 153.8800000000001 64.76999999999953
0.0 15.0 202.0884029865265 54.07499999999982 101.15999999999985 50.24999999999909
0.0 16.0 210.27964663505554 66.36999999999898 101.15999999999985 50.24999999999909
0.0 17.0 218.69651174545288 52.720000000001164 101.15999999999985 50.24999999999909
1.0 18.0 227.39960622787476 54.07499999999982 101.15999999999985 50.24999999999909
1.0 19.0 236.01811289787292 66.36999999999898 101.15999999999985 50.24999999999909
1.0 20.0 243.62274503707886 93.34000000000015 154.8799999999983 55.099999999998545
1.0 21.0 251.446679353714 87.35999999999967 154.8799999999983 55.099999999998545
1.0 22.0 260.024662733078 43.73499999999967 154.8799999999983 55.099999999998545
1.0 23.0 267.9466836452484 129.94999999999982 178.77000000000044 104.5600000000004
1.0 24.0 276.211252450943 424.5400000000009 178.77000000000044 104.5600000000004
1.0 25.0 284.64044070243835 210.35999999999967 178.77000000000044 104.5600000000004
1.0 26.0 292.5938124656677 81.74499999999989 98.19000000000142 57.76499999999851
1.0 27.0 305.1573295593262 43.60499999999956 98.19000000000142 57.76499999999851
1.0 28.0 313.8283431529999 100.90499999999975 197.5550000000012 60.219999999999345
1.0 29.0 323.0035238265991 82.2450000000008 197.5550000000012 60.219999999999345
1.0 30.0 331.8824462890625 299.8249999999998 155.51499999999942 62.3849999999984
1.0 31.0 340.17315697669983 154.52499999999873 334.6800000000003 183.1349999999993
1.0 32.0 348.6149592399597 263.90000000000146 334.6800000000003 183.1349999999993
1.0 33.0 356.46786165237427 94.41000000000258 163.375 78.20000000000073
1.0 34.0 365.08193039894104 54.2549999999992 163.375 78.20000000000073
2.0 35.0 373.6082606315613 54.2549999999992 163.375 78.20000000000073
2.0 36.0 382.5467734336853 103.18999999999869 163.375 78.20000000000073
2.0 37.0 398.7465443611145 100.33499999999913 221.8149999999996 229.40000000000055
2.0 38.0 408.7146921157837 96.20499999999993 196.40499999999975 70.27499999999873
2.0 39.0 417.64959478378296 79.0550000000012 196.40499999999975 70.27499999999873
2.0 40.0 426.65441608428955 155.65999999999894 196.40499999999975 70.27499999999873
2.0 41.0 436.1735761165619 85.56000000000222 196.40499999999975 70.27499999999873
2.0 42.0 445.6658720970154 329.2900000000009 163.1899999999987 66.324999999998
2.0 43.0 455.03982877731323 164.8799999999983 242.2449999999999 167.5000000000009
2.0 44.0 465.4979145526886 122.21500000000106 242.2449999999999 167.5000000000009
2.0 45.0 482.92043471336365 394.4349999999995 242.2449999999999 167.5000000000009
2.0 46.0 493.17657017707825 109.36499999999887 252.45499999999993 351.0049999999992
2.0 47.0 503.8164873123169 172.5550000000003 262.16000000000076 190.02500000000146
2.0 48.0 514.9872310161591 157.73500000000058 262.16000000000076 190.02500000000146
2.0 49.0 525.5628023147583 117.70499999999993 262.16000000000076 190.02500000000146
2.0 50.0 537.0116202831268 90.01000000000113 284.3100000000022 212.39000000000306
2.0 51.0 554.1125316619873 101.42500000000018 284.3100000000022 212.39000000000306
3.0 52.0 580.9387085437775 371.5749999999989 206.14000000000033 89.58999999999924
3.0 53.0 593.3153841495514 380.34000000000015 193.20500000000084 97.44000000000051
3.0 54.0 682.7167420387268 168.23999999999978 193.20500000000084 97.44000000000051
3.0 55.0 697.7778451442719 94.15499999999884 207.7499999999991 94.54500000000098
3.0 56.0 740.4252502918243 187.04000000000042 207.7499999999991 94.54500000000098
3.0 57.0 980.9754180908203 230.23500000000058 207.7499999999991 94.54500000000098
3.0 58.0 1030.2106728553772 216.05499999999938 207.7499999999991 94.54500000000098
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 10699.37 100.3799999999992 42.404999999997926
0.0 1.0 11.971024513244629 33.57499999999891 100.3799999999992 42.404999999997926
0.0 2.0 23.536330223083496 36.68499999999767 100.3799999999992 42.404999999997926
0.0 3.0 34.86743521690369 42.475000000000364 100.3799999999992 42.404999999997926
0.0 4.0 46.25925874710083 264.53999999999905 100.3799999999992 42.404999999997926
0.0 5.0 62.01589894294739 155.43499999999767 216.39499999999862 71.94499999999789
0.0 6.0 74.27996563911438 292.6950000000006 114.89999999999873 47.26000000000113
0.0 7.0 86.57772994041443 163.15499999999884 196.27999999999793 99.17500000000018
0.0 8.0 107.74397110939026 381.244999999999 503.96000000000004 505.66499999999905
0.0 9.0 204.47636246681213 414.3750000000009 503.96000000000004 505.66499999999905
0.0 10.0 220.41505599021912 88.57499999999891 163.89999999999873 125.1150000000016
0.0 11.0 242.88172054290771 175.85500000000138 163.89999999999873 125.1150000000016
0.0 12.0 256.2973072528839 148.88500000000022 163.89999999999873 125.1150000000016
0.0 13.0 279.4671425819397 109.61999999999898 93.08000000000266 32.74499999999898
0.0 14.0 299.65042757987976 57.914999999999054 165.21500000000015 51.38000000000011
0.0 15.0 317.05248761177063 40.6850000000004 109.97000000000025 59.3149999999996
0.0 16.0 329.56776785850525 76.76499999999669 109.97000000000025 59.3149999999996
0.0 17.0 344.0893044471741 44.279999999998836 109.97000000000025 59.3149999999996
1.0 18.0 356.631719827652 40.6850000000004 109.97000000000025 59.3149999999996
1.0 19.0 368.59357619285583 76.76499999999669 109.97000000000025 59.3149999999996
1.0 20.0 385.55828285217285 93.36000000000058 153.01500000000033 41.835000000000036
1.0 21.0 400.70986771583557 71.87999999999738 153.01500000000033 41.835000000000036
1.0 22.0 530.085028886795 91.22500000000218 153.01500000000033 41.835000000000036
1.0 23.0 561.6107819080353 32.775000000000546 174.0099999999993 83.25500000000011
1.0 24.0 599.4354329109192 315.53499999999985 174.0099999999993 83.25500000000011
1.0 25.0 627.7053790092468 223.07499999999982 174.0099999999993 83.25500000000011
1.0 26.0 689.7971634864807 108.98000000000138 179.98999999999796 63.87499999999909
1.0 27.0 708.4256052970886 24.149999999999636 179.98999999999796 63.87499999999909
1.0 28.0 905.7553925514221 66.47500000000036 109.94999999999982 53.79999999999927
1.0 29.0 1752.3682856559753 72.699999999998 109.94999999999982 53.79999999999927
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 10706.020000000002 109.08499999999913 77.16999999999825
0.0 1.0 13.391668796539307 27.670000000000073 109.08499999999913 77.16999999999825
0.0 2.0 27.019989490509033 23.4449999999988 109.08499999999913 77.16999999999825
0.0 3.0 39.308992862701416 95.57499999999982 109.08499999999913 77.16999999999825
0.0 4.0 51.64971446990967 324.119999999999 283.3199999999988 170.7450000000008
0.0 5.0 65.52915239334106 85.89499999999953 270.4249999999993 143.19999999999982
0.0 6.0 78.13825345039368 357.1700000000037 268.8199999999997 136.07499999999982
0.0 7.0 93.15023589134216 220.5099999999993 228.3700000000008 117.74999999999818
0.0 8.0 106.34401202201843 65.38500000000113 142.48000000000047 88.04000000000087
0.0 9.0 121.26440167427063 64.86999999999989 142.48000000000047 88.04000000000087
0.0 10.0 131.07321095466614 135.63500000000113 166.1900000000005 89.56500000000142
0.0 11.0 154.50542569160461 228.77999999999975 166.1900000000005 89.56500000000142
0.0 12.0 164.33020734786987 148.88500000000022 166.1900000000005 89.56500000000142
0.0 13.0 173.404376745224 47.465000000000146 124.3700000000008 62.24999999999909
0.0 14.0 182.68007493019104 55.729999999997744 105.78500000000076 55.099999999998545
0.0 15.0 193.41052889823914 44.159999999999854 109.13000000000102 41.664999999999964
0.0 16.0 204.5431613922119 54.404999999999745 109.13000000000102 41.664999999999964
0.0 17.0 215.3835756778717 51.000000000000455 109.13000000000102 41.664999999999964
1.0 18.0 225.90873789787292 83.53000000000065 128.11499999999887 61.05000000000018
1.0 19.0 236.15446043014526 66.36999999999898 128.11499999999887 61.05000000000018
1.0 20.0 245.04768800735474 87.3149999999996 145.3849999999993 50.24999999999909
1.0 21.0 254.0939564704895 78.14000000000033 145.3849999999993 50.24999999999909
1.0 22.0 284.9879515171051 30.024999999999636 145.3849999999993 50.24999999999909
1.0 23.0 294.10757756233215 144.5550000000012 203.41500000000087 124.75500000000102
1.0 24.0 303.2387900352478 412.0050000000001 203.41500000000087 124.75500000000102
1.0 25.0 311.88493967056274 179.9449999999997 203.41500000000087 124.75500000000102
1.0 26.0 321.7483069896698 103.38499999999931 104.26999999999862 41.149999999999636
1.0 27.0 401.31219267845154 63.69000000000051 104.26999999999862 41.149999999999636
1.0 28.0 421.71054553985596 94.57999999999902 163.1249999999991 61.72000000000298
1.0 29.0 431.5762710571289 82.95000000000073 163.1249999999991 61.72000000000298
1.0 30.0 441.92777156829834 239.35000000000036 131.6949999999997 71.90999999999985
1.0 31.0 452.2713363170624 110.53500000000167 149.83999999999924 71.90999999999985
1.0 32.0 462.48022866249084 63.19500000000153 149.83999999999924 71.90999999999985
1.0 33.0 472.565388917923 84.88000000000102 153.96500000000106 90.64500000000135
1.0 34.0 485.18484830856323 68.47500000000036 153.96500000000106 90.64500000000135
2.0 35.0 496.70514369010925 68.47500000000036 153.96500000000106 90.64500000000135
2.0 36.0 508.60143637657166 106.19999999999891 153.96500000000106 90.64500000000135
2.0 37.0 519.7504980564117 85.38000000000011 177.73499999999876 81.08499999999913
2.0 38.0 531.9229643344879 110.42999999999847 139.0650000000005 81.13499999999931
2.0 39.0 544.5462644100189 94.57999999999902 300.3399999999983 58.70999999999913
2.0 40.0 556.1046211719513 256.9200000000001 300.3399999999983 58.70999999999913
2.0 41.0 566.9506931304932 116.81999999999971 300.3399999999983 58.70999999999913
2.0 42.0 577.2336604595184 255.79499999999916 179.375 75.3799999999992
2.0 43.0 588.2398552894592 85.52499999999964 125.21499999999833 56.05000000000018
2.0 44.0 599.2521872520447 45.25500000000011 125.21499999999833 56.05000000000018
2.0 45.0 611.3517949581146 329.70000000000255 125.21499999999833 56.05000000000018
2.0 46.0 623.6843173503876 66.02499999999873 125.21499999999833 56.05000000000018
2.0 47.0 635.0813419818878 62.10500000000138 125.21499999999833 56.05000000000018
2.0 48.0 646.105327129364 79.02999999999975 125.21499999999833 56.05000000000018
2.0 49.0 657.9656579494476 48.030000000000655 125.21499999999833 56.05000000000018
2.0 50.0 669.0530622005463 84.88000000000102 107.56999999999971 55.20499999999902
2.0 51.0 682.9735515117645 50.86500000000069 107.56999999999971 55.20499999999902
3.0 52.0 695.7229120731354 326.2650000000003 107.56999999999971 55.20499999999902
3.0 53.0 708.1028003692627 206.89000000000124 107.56999999999971 55.20499999999902
3.0 54.0 720.0221214294434 55.13999999999942 107.56999999999971 55.20499999999902
3.0 55.0 801.6512320041656 134.9950000000017 270.4949999999999 64.97000000000025
3.0 56.0 822.4535191059113 259.8550000000009 270.4949999999999 64.97000000000025
3.0 57.0 844.6682896614075 80.60500000000138 270.4949999999999 64.97000000000025
3.0 58.0 874.4660811424255 20.154999999999745 270.4949999999999 64.97000000000025
3.0 59.0 897.3539278507233 90.18000000000029 119.81000000000222 43.75
3.0 60.0 1044.189194202423 45.81500000000051 152.9349999999995 41.19500000000062
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 10709.100000000006 103.42999999999847 42.404999999997926
0.0 1.0 11.595111846923828 34.60500000000002 103.42999999999847 42.404999999997926
0.0 2.0 22.83509349822998 36.68499999999767 103.42999999999847 42.404999999997926
0.0 3.0 33.32614803314209 42.475000000000364 103.42999999999847 42.404999999997926
0.0 4.0 44.43459177017212 258.96999999999844 103.42999999999847 42.404999999997926
0.0 5.0 57.09152865409851 151.45499999999902 270.40499999999975 90.64500000000135
0.0 6.0 68.66149568557739 173.89500000000135 97.08500000000004 42.52000000000044
0.0 7.0 196.20496487617493 52.62000000000171 113.56999999999971 35.344999999999345
0.0 8.0 206.21138334274292 237.20499999999902 351.1100000000006 88.88000000000102
0.0 9.0 222.32977294921875 134.2649999999985 351.1100000000006 88.88000000000102
0.0 10.0 256.35880494117737 149.7400000000016 265.0450000000001 61.25000000000091
0.0 11.0 277.29329800605774 315.4050000000034 265.0450000000001 61.25000000000091
0.0 12.0 289.3313183784485 217.35500000000047 265.0450000000001 61.25000000000091
0.0 13.0 301.9836015701294 118.84499999999935 149.20999999999913 33.89499999999953
0.0 14.0 316.3611810207367 42.229999999997744 149.20999999999913 33.89499999999953
0.0 15.0 327.19095253944397 38.01999999999953 139.0650000000005 43.75
0.0 16.0 338.0856957435608 88.47499999999673 139.0650000000005 43.75
0.0 17.0 349.52003931999207 85.96500000000106 139.0650000000005 43.75
1.0 18.0 361.8546733856201 43.659999999999854 126.53499999999985 59.150000000001455
1.0 19.0 373.51934337615967 82.90999999999985 126.53499999999985 59.150000000001455
1.0 20.0 385.049280166626 62.45500000000084 126.53499999999985 59.150000000001455
1.0 21.0 397.9983956813812 65.24999999999727 126.53499999999985 59.150000000001455
1.0 22.0 410.99466943740845 36.64000000000033 126.53499999999985 59.150000000001455
1.0 23.0 423.7350697517395 174.48999999999978 198.21500000000015 55.13500000000113
1.0 24.0 460.69755840301514 412.5700000000006 198.21500000000015 55.13500000000113
1.0 25.0 497.2337284088135 215.83500000000004 198.21500000000015 55.13500000000113
1.0 26.0 510.4637484550476 142.89000000000033 183.8099999999995 49.29999999999927
1.0 27.0 523.2574727535248 30.084999999999127 183.8099999999995 49.29999999999927
1.0 28.0 535.2568304538727 47.475000000000364 195.11499999999978 39.51500000000033
1.0 29.0 547.7106223106384 87.51500000000124 195.11499999999978 39.51500000000033
1.0 30.0 560.1453051567078 310.0100000000002 195.11499999999978 39.51500000000033
1.0 31.0 572.0003118515015 63.63999999999851 195.11499999999978 39.51500000000033
1.0 32.0 583.9308533668518 150.1800000000003 195.11499999999978 39.51500000000033
1.0 33.0 595.8909113407135 107.01000000000295 173.1250000000009 33.89499999999953
1.0 34.0 609.0055260658264 34.88500000000022 173.1250000000009 33.89499999999953
2.0 35.0 621.2985646724701 34.88500000000022 173.1250000000009 33.89499999999953
2.0 36.0 633.6527144908905 147.91499999999905 173.1250000000009 33.89499999999953
2.0 37.0 711.3206231594086 176.45000000000073 349.77500000000055 68.97500000000036
2.0 38.0 723.0621135234833 39.00000000000091 173.5000000000009 35.86999999999898
2.0 39.0 734.7259922027588 52.724999999999454 273.0150000000003 58.5099999999984
2.0 40.0 748.5751211643219 363.1899999999996 273.0150000000003 58.5099999999984
2.0 41.0 762.1092133522034 117.44999999999982 273.0150000000003 58.5099999999984
2.0 42.0 773.8953113555908 235.72499999999764 147.6200000000017 45.58000000000084
2.0 43.0 786.8930554389954 142.89000000000033 173.1250000000009 40.460000000000036
2.0 44.0 798.5984423160553 112.875 173.1250000000009 40.460000000000036
2.0 45.0 811.4638845920563 457.7600000000011 173.1250000000009 40.460000000000036
2.0 46.0 824.5040390491486 63.63999999999851 173.1250000000009 40.460000000000036
2.0 47.0 836.6904528141022 119.69500000000062 150.0699999999997 50.24999999999909
2.0 48.0 848.4885051250458 49.88000000000102 150.0699999999997 50.24999999999909
2.0 49.0 860.8211724758148 69.57499999999982 150.0699999999997 50.24999999999909
2.0 50.0 873.2901790142059 474.1149999999998 506.4599999999991 101.45500000000084
2.0 51.0 885.0604813098907 106.15499999999884 506.4599999999991 101.45500000000084
3.0 52.0 896.1796870231628 693.8900000000012 506.4599999999991 101.45500000000084
3.0 53.0 908.1724469661713 235.72499999999764 157.48499999999967 45.58000000000084
3.0 54.0 920.5672445297241 34.88500000000022 157.48499999999967 45.58000000000084
3.0 55.0 938.8536291122437 100.95500000000084 269.65500000000156 46.77000000000044
3.0 56.0 959.1716170310974 259.8550000000009 269.65500000000156 46.77000000000044
3.0 57.0 978.6674294471741 110.60499999999956 269.65500000000156 46.77000000000044
3.0 58.0 997.3331158161163 41.914999999999054 269.65500000000156 46.77000000000044
3.0 59.0 1029.9798336029053 72.39000000000033 127.87000000000171 40.51999999999953
