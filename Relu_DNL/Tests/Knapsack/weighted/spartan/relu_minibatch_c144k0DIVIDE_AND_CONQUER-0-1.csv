Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 10616.35 88.62500000000091 44.529999999999745
0.0 1.0 7.4197916984558105 82.00500000000011 88.62500000000091 44.529999999999745
0.0 2.0 14.232106447219849 90.95000000000073 88.62500000000091 44.529999999999745
0.0 3.0 21.766192197799683 122.81500000000051 88.62500000000091 44.529999999999745
0.0 4.0 29.444766521453857 331.1050000000023 89.18499999999858 54.06499999999869
0.0 5.0 39.12360429763794 163.34999999999854 108.51999999999953 33.89499999999862
0.0 6.0 46.03465247154236 150.28000000000065 97.08500000000004 54.95999999999913
0.0 7.0 52.81427216529846 103.14999999999873 154.94999999999982 56.17999999999938
0.0 8.0 58.85380220413208 85.23999999999978 171.85999999999967 108.6899999999996
0.0 9.0 83.77035713195801 164.41499999999996 171.85999999999967 108.6899999999996
0.0 10.0 105.73084855079651 128.40500000000065 185.72000000000116 108.6899999999996
0.0 11.0 192.69350290298462 260.04999999999654 185.72000000000116 108.6899999999996
0.0 12.0 244.07372522354126 175.77499999999964 185.72000000000116 108.6899999999996
0.0 13.0 249.9826419353485 80.57999999999993 164.43499999999858 55.099999999998545
0.0 14.0 258.77149510383606 57.914999999999054 135.54999999999654 60.0649999999996
0.0 15.0 264.17430329322815 97.99499999999989 147.45999999999822 49.359999999997854
0.0 16.0 270.0413980484009 100.66499999999633 147.45999999999822 49.359999999997854
0.0 17.0 275.6723117828369 48.67500000000018 147.45999999999822 49.359999999997854
1.0 18.0 281.3400514125824 40.6850000000004 99.625 42.52000000000044
1.0 19.0 286.8447058200836 54.404999999999745 99.625 42.52000000000044
1.0 20.0 292.3594582080841 87.5049999999992 135.23999999999887 48.63499999999749
1.0 21.0 297.8175995349884 42.80500000000029 135.23999999999887 48.63499999999749
1.0 22.0 303.97532963752747 43.76499999999942 135.23999999999887 48.63499999999749
1.0 23.0 349.49381828308105 74.42999999999938 235.27999999999793 102.1349999999984
1.0 24.0 413.81376934051514 352.77000000000044 186.98999999999887 115.07500000000073
1.0 25.0 439.84749937057495 165.13500000000113 186.98999999999887 115.07500000000073
1.0 26.0 465.1629548072815 149.42000000000098 219.78499999999804 104.49499999999716
1.0 27.0 554.9987137317657 132.8050000000003 219.78499999999804 104.49499999999716
1.0 28.0 561.6666812896729 82.47500000000036 201.64500000000044 113.16999999999916
1.0 29.0 634.0321929454803 85.80500000000029 201.64500000000044 113.16999999999916
1.0 30.0 656.6688661575317 421.4349999999986 188.16499999999996 161.29000000000178
1.0 31.0 665.23508644104 107.574999999998 191.09000000000106 179.22500000000036
1.0 32.0 675.2946064472198 142.8800000000001 191.09000000000106 179.22500000000036
1.0 33.0 688.9055879116058 140.65500000000156 202.96500000000106 210.57500000000255
1.0 34.0 791.1089990139008 141.3700000000008 202.96500000000106 210.57500000000255
2.0 35.0 892.7726023197174 141.3700000000008 202.96500000000106 210.57500000000255
2.0 36.0 977.5342173576355 182.33500000000095 202.96500000000106 210.57500000000255
2.0 37.0 1033.0240116119385 161.33999999999924 257.420000000001 261.33500000000004
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 10569.390000000003 173.28499999999985 59.55999999999767
0.0 1.0 8.287779569625854 43.60499999999956 173.28499999999985 59.55999999999767
0.0 2.0 15.402748823165894 42.36499999999887 173.28499999999985 59.55999999999767
0.0 3.0 23.33318519592285 159.72499999999945 173.28499999999985 59.55999999999767
0.0 4.0 30.443341970443726 507.02000000000226 173.28499999999985 59.55999999999767
0.0 5.0 36.319544315338135 99.35000000000036 119.6200000000008 51.20499999999811
0.0 6.0 41.1149845123291 334.26500000000124 112.88500000000113 41.05999999999858
0.0 7.0 45.03404688835144 52.62000000000171 130.01000000000113 61.96499999999833
0.0 8.0 48.93624973297119 76.97000000000298 153.14000000000124 73.31499999999869
0.0 9.0 53.21242642402649 36.4350000000004 153.14000000000124 73.31499999999869
0.0 10.0 60.68378233909607 110.4350000000004 211.5600000000013 166.17000000000007
0.0 11.0 195.62091660499573 153.1649999999995 211.5600000000013 166.17000000000007
0.0 12.0 235.09866762161255 115.35500000000047 211.5600000000013 166.17000000000007
0.0 13.0 247.83636260032654 58.284999999999854 211.5600000000013 166.17000000000007
0.0 14.0 527.4112973213196 59.909999999998945 149.9499999999989 45.58000000000084
0.0 15.0 541.4936442375183 39.00000000000091 186.02999999999975 88.67999999999938
0.0 16.0 605.6248579025269 75.8700000000008 186.02999999999975 88.67999999999938
0.0 17.0 643.5329005718231 75.47500000000127 186.02999999999975 88.67999999999938
1.0 18.0 656.5593137741089 39.00000000000091 186.02999999999975 88.67999999999938
1.0 19.0 716.2275536060333 75.8700000000008 186.02999999999975 88.67999999999938
1.0 20.0 729.9815926551819 74.49000000000069 119.26500000000033 41.49499999999989
1.0 21.0 742.7083542346954 29.730000000000473 119.26500000000033 41.49499999999989
1.0 22.0 1010.6506190299988 97.15000000000055 119.26500000000033 41.49499999999989
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 10569.390000000003 182.625 73.42999999999938
0.0 1.0 7.5887110233306885 27.1299999999992 182.625 73.42999999999938
0.0 2.0 14.02079725265503 42.36499999999887 182.625 73.42999999999938
0.0 3.0 20.10443353652954 374.93499999999995 182.625 73.42999999999938
0.0 4.0 27.278928995132446 427.6799999999994 85.87499999999909 63.10500000000047
0.0 5.0 33.53392457962036 189.84000000000106 251.83500000000095 148.97500000000036
0.0 6.0 39.33912897109985 502.15499999999884 102.43000000000029 50.839999999999236
0.0 7.0 45.51617670059204 40.529999999999745 76.29500000000007 55.26999999999953
0.0 8.0 50.99680757522583 133.07999999999993 113.14000000000033 45.58000000000084
0.0 9.0 57.5222647190094 129.33999999999833 113.14000000000033 45.58000000000084
0.0 10.0 62.82216763496399 127.53499999999985 196.10499999999865 72.73500000000058
0.0 11.0 68.10773968696594 358.77999999999884 196.10499999999865 72.73500000000058
0.0 12.0 73.2161476612091 220.86499999999978 196.10499999999865 72.73500000000058
0.0 13.0 78.28132390975952 51.335000000000946 97.08500000000004 37.94999999999891
0.0 14.0 86.3217248916626 47.64499999999862 85.44500000000062 32.10999999999967
0.0 15.0 95.84881019592285 46.150000000000546 691.6900000000005 354.83500000000004
0.0 16.0 515.3211143016815 234.60000000000036 691.6900000000005 354.83500000000004
0.0 17.0 598.6731827259064 406.4250000000002 691.6900000000005 354.83500000000004
1.0 18.0 607.3721718788147 46.150000000000546 691.6900000000005 354.83500000000004
1.0 19.0 1025.271487236023 234.60000000000036 691.6900000000005 354.83500000000004
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 10550.480000000001 160.64000000000033 81.21500000000015
0.0 1.0 8.236343383789062 56.17000000000098 160.64000000000033 81.21500000000015
0.0 2.0 15.375276327133179 79.56499999999778 160.64000000000033 81.21500000000015
0.0 3.0 22.839662790298462 255.69500000000062 160.64000000000033 81.21500000000015
0.0 4.0 29.445373058319092 364.2250000000022 160.64000000000033 81.21500000000015
0.0 5.0 36.58039164543152 94.11499999999978 133.34999999999945 54.274999999999636
0.0 6.0 41.45130801200867 302.96999999999935 135.54999999999654 47.48499999999967
0.0 7.0 46.88701272010803 72.61499999999978 170.40999999999894 79.72000000000025
0.0 8.0 52.07604479789734 136.27000000000135 121.06500000000142 44.61000000000149
0.0 9.0 56.807324171066284 271.2900000000009 121.06500000000142 44.61000000000149
0.0 10.0 62.02055263519287 54.29500000000189 133.82999999999993 74.75999999999931
0.0 11.0 67.3289909362793 160.85999999999967 133.82999999999993 74.75999999999931
0.0 12.0 72.31317353248596 155.44000000000142 133.82999999999993 74.75999999999931
0.0 13.0 77.45520091056824 133.09000000000015 104.72499999999854 51.74999999999909
0.0 14.0 82.47494220733643 53.43000000000029 111.30999999999949 56.98999999999887
0.0 15.0 87.9281861782074 81.1299999999992 115.97000000000207 69.38500000000022
0.0 16.0 93.29817056655884 54.404999999999745 115.97000000000207 69.38500000000022
0.0 17.0 98.88078713417053 48.625 115.97000000000207 69.38500000000022
1.0 18.0 104.63801789283752 81.1299999999992 115.97000000000207 69.38500000000022
1.0 19.0 110.33248567581177 54.404999999999745 115.97000000000207 69.38500000000022
1.0 20.0 115.23265528678894 86.68500000000131 145.48499999999967 58.529999999998836
1.0 21.0 120.07680749893188 80.97999999999774 145.48499999999967 58.529999999998836
1.0 22.0 125.60284924507141 79.67000000000007 145.48499999999967 58.529999999998836
1.0 23.0 130.59292936325073 75.44000000000051 152.0 71.94500000000062
1.0 24.0 135.72115802764893 326.2650000000003 152.0 71.94500000000062
1.0 25.0 140.36382508277893 175.10000000000036 152.0 71.94500000000062
1.0 26.0 145.10234570503235 72.90499999999884 136.64999999999964 46.76499999999942
1.0 27.0 150.1352138519287 71.03500000000076 136.64999999999964 46.76499999999942
1.0 28.0 155.36942410469055 94.57999999999902 115.78999999999996 55.099999999998545
1.0 29.0 161.33867692947388 64.99999999999909 115.78999999999996 55.099999999998545
1.0 30.0 167.18645930290222 263.60999999999785 104.28999999999905 48.41999999999916
1.0 31.0 173.645446062088 66.64999999999964 104.28999999999905 48.41999999999916
1.0 32.0 183.00690722465515 37.409999999998945 104.28999999999905 48.41999999999916
1.0 33.0 188.9750096797943 84.88000000000102 170.48999999999978 46.77000000000044
1.0 34.0 195.19311785697937 43.659999999998035 170.48999999999978 46.77000000000044
2.0 35.0 200.91201853752136 43.659999999998035 170.48999999999978 46.77000000000044
2.0 36.0 211.8916871547699 176.58000000000084 170.48999999999978 46.77000000000044
2.0 37.0 221.90420413017273 129.77000000000135 290.91499999999905 107.54999999999927
2.0 38.0 255.49220609664917 39.00000000000091 128.3050000000003 35.344999999999345
2.0 39.0 270.37977409362793 44.17500000000109 124.52500000000055 33.89499999999953
2.0 40.0 598.2717463970184 177.52000000000135 124.52500000000055 33.89499999999953
2.0 41.0 776.2967355251312 34.229999999998654 124.52500000000055 33.89499999999953
2.0 42.0 827.3883624076843 282.40999999999804 124.52500000000055 33.89499999999953
2.0 43.0 891.2663385868073 117.83499999999913 127.36499999999887 35.344999999999345
2.0 44.0 908.5132081508636 87.8199999999988 127.36499999999887 35.344999999999345
2.0 45.0 1002.182051897049 431.5149999999994 127.36499999999887 35.344999999999345
