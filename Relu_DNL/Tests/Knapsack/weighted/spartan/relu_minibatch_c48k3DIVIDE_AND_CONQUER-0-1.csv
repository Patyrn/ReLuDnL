Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4582.4400000000005 209.9150000000002 83.68000000000029
0.0 1.0 5.574956655502319 34.965000000000146 177.39499999999953 71.19000000000005
0.0 2.0 10.362188339233398 48.72499999999991 263.85999999999945 147.92999999999984
0.0 3.0 15.747925519943237 405.2099999999996 263.85999999999945 147.92999999999984
0.0 4.0 21.190871238708496 70.20999999999958 269.5000000000007 114.4950000000008
0.0 5.0 26.79918909072876 114.83500000000049 282.2449999999992 202.6150000000007
0.0 6.0 31.56647777557373 150.6849999999995 303.7199999999998 224.06500000000005
0.0 7.0 36.894524335861206 641.01 303.7199999999998 224.06500000000005
0.0 8.0 41.21542501449585 40.85500000000047 248.19500000000016 101.33500000000004
0.0 9.0 45.736751317977905 126.94999999999982 213.26000000000045 128.4350000000004
0.0 10.0 50.353655099868774 216.82999999999993 213.26000000000045 128.4350000000004
0.0 11.0 55.17239260673523 63.70999999999981 213.26000000000045 128.4350000000004
0.0 12.0 59.76396298408508 374.6349999999991 213.26000000000045 128.4350000000004
0.0 13.0 63.67472219467163 266.395 213.26000000000045 128.4350000000004
0.0 14.0 67.99194693565369 59.67500000000018 211.55999999999972 117.61500000000024
0.0 15.0 72.29950618743896 232.24500000000035 327.98000000000025 341.1699999999996
0.0 16.0 77.69438004493713 416.55999999999995 360.49 342.7950000000001
0.0 17.0 82.67027354240417 456.67999999999984 360.49 342.7950000000001
1.0 18.0 86.65181040763855 226.53499999999985 313.4150000000002 159.84500000000025
1.0 19.0 89.96402096748352 452.97999999999956 234.57500000000027 98.68500000000017
1.0 20.0 93.1396131515503 579.9199999999996 234.57500000000027 98.68500000000017
1.0 21.0 96.27785873413086 299.52999999999975 234.57500000000027 98.68500000000017
1.0 22.0 128.82450795173645 174.04999999999973 313.54999999999995 336.6649999999995
1.0 23.0 133.02536273002625 257.1849999999997 313.54999999999995 336.6649999999995
1.0 24.0 136.94829106330872 70.96500000000015 259.78999999999996 113.32000000000016
1.0 25.0 153.26777029037476 136.10999999999967 259.78999999999996 113.32000000000016
1.0 26.0 157.74467515945435 227.10999999999967 259.78999999999996 113.32000000000016
1.0 27.0 161.5233554840088 45.775000000001 246.01499999999987 85.49500000000035
1.0 28.0 165.33804941177368 50.76500000000033 180.54999999999973 84.7199999999998
1.0 29.0 168.97812819480896 239.96499999999946 180.54999999999973 84.7199999999998
1.0 30.0 172.532883644104 64.55000000000018 228.15000000000077 74.79999999999995
1.0 31.0 176.32055926322937 143.60500000000025 180.69999999999982 86.86999999999989
1.0 32.0 179.87532591819763 389.8250000000003 180.69999999999982 86.86999999999989
1.0 33.0 184.2486879825592 40.85500000000047 299.2349999999999 116.30500000000075
1.0 34.0 189.38219714164734 62.16500000000019 299.2349999999999 116.30500000000075
2.0 35.0 194.4805405139923 62.16500000000019 299.2349999999999 116.30500000000075
2.0 36.0 198.32182478904724 441.48 248.87999999999988 104.75999999999931
2.0 37.0 201.96513843536377 183.2949999999994 248.87999999999988 104.75999999999931
2.0 38.0 205.91586208343506 86.00499999999965 325.1199999999999 105.03999999999996
2.0 39.0 209.92785382270813 32.9699999999998 325.1199999999999 105.03999999999996
2.0 40.0 214.58723521232605 337.27 325.1199999999999 105.03999999999996
2.0 41.0 218.6002426147461 102.43000000000029 246.33500000000026 98.25999999999954
2.0 42.0 222.5050859451294 64.55000000000018 246.33500000000026 98.25999999999954
2.0 43.0 226.82692694664001 308.66999999999985 246.33500000000026 98.25999999999954
2.0 44.0 230.92199563980103 348.0649999999996 246.33500000000026 98.25999999999954
2.0 45.0 234.91511845588684 81.63500000000022 246.33500000000026 98.25999999999954
2.0 46.0 238.99590849876404 164.19500000000016 218.00500000000034 89.92999999999938
2.0 47.0 243.49195504188538 454.6599999999994 218.00500000000034 89.92999999999938
2.0 48.0 248.45669627189636 528.1599999999996 218.00500000000034 89.92999999999938
2.0 49.0 253.01251435279846 244.59999999999945 218.00500000000034 89.92999999999938
2.0 50.0 257.80413007736206 34.89500000000044 310.1450000000002 116.30500000000075
2.0 51.0 262.5193176269531 40.38999999999987 307.5600000000002 99.44999999999982
3.0 52.0 267.08265948295593 84.53499999999985 368.5300000000002 107.65000000000009
3.0 53.0 271.9979364871979 64.55000000000018 368.5300000000002 107.65000000000009
3.0 54.0 276.7120907306671 50.32499999999982 368.5300000000002 107.65000000000009
3.0 55.0 281.61297702789307 289.5499999999993 368.5300000000002 107.65000000000009
3.0 56.0 287.07977294921875 204.61500000000046 368.5300000000002 107.65000000000009
3.0 57.0 292.21810364723206 114.80499999999984 304.98000000000025 89.92999999999938
3.0 58.0 297.35857009887695 40.38999999999987 310.1450000000002 99.44999999999982
3.0 59.0 302.6197741031647 711.0749999999994 310.1450000000002 99.44999999999982
3.0 60.0 308.00129556655884 25.444999999999254 310.1450000000002 99.44999999999982
3.0 61.0 313.2527837753296 358.9949999999999 310.1450000000002 99.44999999999982
3.0 62.0 318.60623264312744 34.89500000000044 312.2550000000001 115.33500000000095
3.0 63.0 324.3000090122223 342.4099999999994 312.2550000000001 115.33500000000095
3.0 64.0 330.0243887901306 407.2099999999991 227.19500000000085 106.98999999999933
3.0 65.0 335.3473606109619 368.44500000000016 227.19500000000085 106.98999999999933
3.0 66.0 341.0793731212616 121.81500000000051 227.19500000000085 98.49499999999944
3.0 67.0 346.49614119529724 206.65000000000077 227.19500000000085 98.49499999999944
3.0 68.0 351.9896101951599 66.00499999999965 227.19500000000085 100.72499999999945
4.0 69.0 357.4917666912079 206.65000000000077 227.19500000000085 100.72499999999945
4.0 70.0 363.0569648742676 66.00499999999965 227.19500000000085 100.72499999999945
4.0 71.0 368.9826657772064 150.12999999999988 227.19500000000085 100.72499999999945
4.0 72.0 374.9149627685547 285.3049999999996 227.19500000000085 100.72499999999945
4.0 73.0 380.5196704864502 25.444999999999254 227.19500000000085 100.72499999999945
4.0 74.0 386.14564776420593 68.83499999999958 227.19500000000085 100.72499999999945
4.0 75.0 401.31418561935425 40.85500000000047 377.79499999999916 140.1850000000004
4.0 76.0 406.9108603000641 115.26500000000033 291.24499999999966 99.44999999999982
4.0 77.0 412.1055271625519 348.0649999999996 291.24499999999966 99.44999999999982
4.0 78.0 418.04445695877075 420.8599999999997 214.53500000000008 100.72499999999945
4.0 79.0 423.59428119659424 454.6599999999994 214.53500000000008 100.72499999999945
4.0 80.0 429.1315438747406 59.46499999999969 285.1749999999997 101.2549999999992
4.0 81.0 435.00443601608276 218.29999999999995 285.1749999999997 101.2549999999992
4.0 82.0 440.7403709888458 83.63499999999999 312.2550000000001 102.51999999999998
4.0 83.0 446.8567135334015 544.6650000000006 312.2550000000001 102.51999999999998
4.0 84.0 452.3643262386322 50.32499999999982 312.2550000000001 102.51999999999998
4.0 85.0 458.1774959564209 164.19500000000016 312.2550000000001 102.51999999999998
5.0 86.0 464.4449369907379 199.53500000000008 312.2550000000001 102.51999999999998
5.0 87.0 470.75180077552795 231.31500000000074 312.2550000000001 102.51999999999998
5.0 88.0 477.36599802970886 40.38999999999987 303.41999999999985 99.44999999999982
5.0 89.0 484.39438581466675 152.2750000000001 303.41999999999985 99.44999999999982
5.0 90.0 491.6348159313202 746.3950000000004 303.41999999999985 99.44999999999982
5.0 91.0 498.23663449287415 50.8599999999999 310.1450000000002 109.79500000000053
5.0 92.0 506.76814818382263 495.0149999999994 310.1450000000002 109.79500000000053
5.0 93.0 513.8638925552368 25.444999999999254 263.8700000000001 99.44999999999982
5.0 94.0 521.1718804836273 164.19500000000016 263.8700000000001 99.44999999999982
5.0 95.0 528.5545921325684 348.0649999999996 263.8700000000001 99.44999999999982
5.0 96.0 535.6072413921356 38.29500000000007 310.1450000000002 105.03999999999996
5.0 97.0 542.8544750213623 115.26500000000033 237.42499999999973 98.68500000000017
5.0 98.0 550.3833608627319 231.4050000000002 237.42499999999973 98.68500000000017
5.0 99.0 557.6941499710083 81.63500000000022 237.42499999999973 98.68500000000017
5.0 100.0 565.5023949146271 407.2099999999991 211.26499999999987 100.72499999999945
5.0 101.0 572.9910883903503 66.00499999999965 260.46999999999935 98.68500000000017
5.0 102.0 580.541097164154 66.52500000000009 265.96000000000004 101.2549999999992
6.0 103.0 588.1242783069611 239.6600000000003 265.96000000000004 101.2549999999992
6.0 104.0 597.2800703048706 37.88499999999976 308.9200000000001 133.10000000000036
6.0 105.0 609.43936419487 599.0699999999995 308.9200000000001 133.10000000000036
6.0 106.0 622.4665925502777 384.6199999999999 308.9200000000001 133.10000000000036
6.0 107.0 632.2020792961121 62.16500000000019 308.9200000000001 133.10000000000036
6.0 108.0 639.9802765846252 70.92999999999938 269.5199999999995 98.68500000000017
6.0 109.0 647.7787506580353 144.42999999999984 269.5199999999995 98.68500000000017
6.0 110.0 656.1116342544556 84.48000000000093 269.5199999999995 98.68500000000017
6.0 111.0 664.0217618942261 25.444999999999254 269.5199999999995 98.68500000000017
6.0 112.0 672.2702434062958 137.65499999999997 265.96000000000004 101.2549999999992
6.0 113.0 681.2230846881866 423.24000000000024 265.96000000000004 101.2549999999992
6.0 114.0 689.6434988975525 66.00499999999965 265.96000000000004 101.2549999999992
6.0 115.0 698.3571243286133 199.17999999999915 265.96000000000004 101.2549999999992
6.0 116.0 706.6819393634796 407.2099999999991 212.13500000000045 106.98999999999933
6.0 117.0 726.0696313381195 66.52500000000009 299.1899999999998 103.79499999999962
6.0 118.0 734.477432012558 165.50000000000068 227.19500000000085 98.49499999999944
6.0 119.0 743.5163216590881 285.3049999999996 227.19500000000085 98.49499999999944
7.0 120.0 752.3765749931335 68.83499999999958 227.19500000000085 98.49499999999944
7.0 121.0 761.6047387123108 97.01999999999998 248.4150000000002 99.44999999999982
7.0 122.0 770.4036045074463 519.7849999999992 248.4150000000002 99.44999999999982
7.0 123.0 779.0408174991608 66.00499999999965 248.4150000000002 99.44999999999982
7.0 124.0 787.3374619483948 285.3049999999996 248.4150000000002 99.44999999999982
7.0 125.0 810.841418504715 40.85500000000047 369.69999999999914 140.1850000000004
7.0 126.0 856.0630841255188 408.16499999999974 369.69999999999914 140.1850000000004
7.0 127.0 865.3460328578949 87.22000000000025 227.94000000000028 100.72499999999945
7.0 128.0 873.4785349369049 165.50000000000068 227.94000000000028 100.72499999999945
7.0 129.0 883.4996953010559 150.12999999999988 227.94000000000028 100.72499999999945
7.0 130.0 891.6672532558441 25.444999999999254 227.94000000000028 100.72499999999945
7.0 131.0 899.6531453132629 406.11999999999944 242.89000000000078 137.83000000000038
7.0 132.0 907.5830798149109 74.16999999999985 242.89000000000078 137.83000000000038
7.0 133.0 964.1459233760834 137.65499999999997 312.54999999999995 108.25500000000011
7.0 134.0 979.679360628128 57.575000000000045 369.69999999999914 136.33000000000038
7.0 135.0 1008.9073569774628 531.855 369.69999999999914 136.33000000000038
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4647.05 159.38500000000022 74.2199999999998
0.0 1.0 5.537461996078491 46.64000000000033 287.55500000000006 160.8050000000003
0.0 2.0 10.29023289680481 48.10500000000002 181.5449999999994 86.32999999999993
0.0 3.0 16.191762685775757 270.2149999999999 181.5449999999994 86.32999999999993
0.0 4.0 21.319613456726074 70.20999999999958 181.5449999999994 91.18499999999995
0.0 5.0 25.95872163772583 59.97000000000071 188.2199999999998 126.34000000000015
0.0 6.0 30.3542001247406 106.92499999999927 263.85999999999945 328.69500000000016
0.0 7.0 38.35921859741211 477.28499999999985 263.85999999999945 328.69500000000016
0.0 8.0 43.028656005859375 67.57000000000016 183.45999999999958 218.48000000000047
0.0 9.0 55.95482540130615 129.8449999999998 176.65499999999975 153.65999999999985
0.0 10.0 76.04702663421631 224.32999999999993 176.65499999999975 153.65999999999985
0.0 11.0 82.24850368499756 150.97000000000025 176.65499999999975 153.65999999999985
0.0 12.0 95.73069715499878 311.6800000000003 176.65499999999975 153.65999999999985
0.0 13.0 103.52357769012451 253.28999999999974 176.65499999999975 153.65999999999985
0.0 14.0 110.16101479530334 74.65999999999985 170.17999999999984 101.05500000000029
0.0 15.0 114.93231654167175 53.51499999999942 173.80500000000075 113.67000000000053
0.0 16.0 125.80041837692261 331.2550000000001 209.14500000000066 161.75999999999976
0.0 17.0 141.9429235458374 225.51000000000022 209.14500000000066 161.75999999999976
1.0 18.0 146.65485167503357 41.46499999999969 173.79500000000007 62.44999999999982
1.0 19.0 1082.8463516235352 487.5250000000001 320.8600000000006 508.0650000000005
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4589.529999999999 226.51499999999942 122.59500000000025
0.0 1.0 8.907624006271362 43.27000000000044 179.45500000000038 104.22000000000025
0.0 2.0 15.563706159591675 57.575000000000045 198.12499999999955 200.00500000000056
0.0 3.0 22.995776176452637 315.80999999999926 198.12499999999955 200.00500000000056
0.0 4.0 29.56149125099182 70.03999999999951 176.3399999999997 156.74499999999944
0.0 5.0 36.62676668167114 48.25500000000011 281.6100000000001 116.30500000000075
0.0 6.0 43.90892791748047 51.659999999999854 288.38999999999965 99.02499999999918
0.0 7.0 54.439637899398804 441.59999999999945 288.38999999999965 99.02499999999918
0.0 8.0 60.96962928771973 133.57499999999982 405.1049999999998 306.0349999999994
0.0 9.0 67.02411890029907 91.58500000000049 196.27000000000044 141.10999999999876
0.0 10.0 72.95459008216858 141.13499999999976 196.27000000000044 141.10999999999876
0.0 11.0 80.21104550361633 149.11499999999978 196.27000000000044 141.10999999999876
0.0 12.0 87.08255696296692 341.70500000000084 196.27000000000044 141.10999999999876
0.0 13.0 93.17870569229126 160.59000000000015 196.27000000000044 141.10999999999876
0.0 14.0 105.24817132949829 228.96000000000004 168.635 115.89500000000089
0.0 15.0 111.7261335849762 199.92499999999927 168.635 115.89500000000089
0.0 16.0 127.47489356994629 273.17500000000086 179.19499999999948 242.7450000000008
0.0 17.0 226.19868898391724 174.80500000000006 179.19499999999948 242.7450000000008
1.0 18.0 231.05405855178833 65.66499999999928 197.79999999999995 64.05999999999972
1.0 19.0 686.6648900508881 431.5199999999991 274.84500000000025 400.34500000000025
1.0 20.0 1055.3965559005737 599.0699999999995 274.84500000000025 400.34500000000025
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4589.529999999999 254.53999999999996 84.7199999999998
0.0 1.0 4.646823406219482 24.49999999999909 207.44499999999994 95.19999999999982
0.0 2.0 8.724014520645142 27.390000000000782 228.61500000000046 150.67499999999973
0.0 3.0 14.121566772460938 271.56500000000074 228.61500000000046 150.67499999999973
0.0 4.0 17.56142258644104 78.45000000000027 196.07999999999947 162.83499999999958
0.0 5.0 21.232711791992188 22.639999999999418 231.6499999999994 45.30499999999938
0.0 6.0 24.895864725112915 84.00499999999965 261.14499999999975 136.0
0.0 7.0 31.239858150482178 460.7149999999997 261.14499999999975 136.0
0.0 8.0 34.483808755874634 150.45000000000005 187.74499999999944 218.48000000000047
0.0 9.0 38.1760995388031 129.8449999999998 153.19500000000016 51.22999999999956
0.0 10.0 45.45941400527954 139.20999999999958 153.19500000000016 51.22999999999956
0.0 11.0 50.31421113014221 135.34500000000003 153.19500000000016 51.22999999999956
0.0 12.0 55.51589107513428 379.5949999999998 153.19500000000016 51.22999999999956
0.0 13.0 59.97280144691467 219.14499999999998 153.19500000000016 51.22999999999956
0.0 14.0 64.02547669410706 98.85500000000002 159.77499999999964 51.22999999999956
0.0 15.0 67.69306468963623 98.79499999999916 150.66499999999996 43.72999999999956
0.0 16.0 71.84615421295166 359.6349999999993 154.0599999999995 43.72999999999956
0.0 17.0 76.4627468585968 165.17499999999995 154.0599999999995 43.72999999999956
1.0 18.0 79.88367748260498 102.60499999999956 150.40999999999963 82.62999999999965
1.0 19.0 142.85507726669312 393.74 212.14499999999998 153.65999999999985
1.0 20.0 208.53543376922607 311.4100000000003 212.14499999999998 153.65999999999985
1.0 21.0 288.21704721450806 321.1850000000002 212.14499999999998 153.65999999999985
1.0 22.0 293.25497007369995 129.8449999999998 159.63999999999987 80.14499999999998
1.0 23.0 359.72492027282715 164.99999999999977 159.63999999999987 80.14499999999998
1.0 24.0 363.9508216381073 64.5949999999998 166.70499999999993 69.40499999999975
1.0 25.0 372.4409017562866 135.34500000000003 166.70499999999993 69.40499999999975
1.0 26.0 378.2252559661865 210.25499999999965 166.70499999999993 69.40499999999975
1.0 27.0 384.245347738266 27.854999999999563 179.19499999999948 86.86999999999989
1.0 28.0 398.4254250526428 42.9699999999998 179.19499999999948 86.86999999999989
1.0 29.0 541.3794400691986 193.53999999999996 179.19499999999948 86.86999999999989
1.0 30.0 563.2033519744873 86.86999999999944 152.9000000000001 73.15499999999997
1.0 31.0 586.9173405170441 120.51999999999907 152.9000000000001 73.15499999999997
1.0 32.0 630.4110050201416 341.70500000000084 152.9000000000001 73.15499999999997
1.0 33.0 634.211597442627 120.38499999999999 176.19000000000028 125.83999999999969
1.0 34.0 640.2834141254425 40.914999999999964 152.9000000000001 66.20000000000005
2.0 35.0 646.5601141452789 40.914999999999964 152.9000000000001 66.20000000000005
2.0 36.0 665.0884652137756 328.7449999999999 168.635 80.14499999999998
2.0 37.0 776.0356795787811 117.44499999999994 168.635 80.14499999999998
2.0 38.0 782.5323178768158 70.33999999999969 160.52999999999975 89.20500000000038
2.0 39.0 787.5341136455536 237.47499999999945 168.80999999999972 99.54999999999973
2.0 40.0 796.4111506938934 211.84999999999968 168.80999999999972 99.54999999999973
2.0 41.0 804.1519064903259 129.8449999999998 170.68999999999983 87.82000000000016
2.0 42.0 809.0424990653992 106.92499999999927 166.70499999999993 80.14499999999998
2.0 43.0 817.3363974094391 233.93000000000006 166.70499999999993 80.14499999999998
2.0 44.0 862.7467665672302 264.49499999999944 166.70499999999993 80.14499999999998
2.0 45.0 867.83757853508 64.5949999999998 168.80999999999972 99.54999999999973
2.0 46.0 876.0071964263916 87.53499999999985 163.37499999999977 80.14499999999998
2.0 47.0 885.9262299537659 547.1399999999999 163.37499999999977 80.14499999999998
2.0 48.0 898.9018135070801 359.11500000000024 163.37499999999977 80.14499999999998
2.0 49.0 909.7606356143951 156.7299999999998 163.37499999999977 80.14499999999998
2.0 50.0 914.7269051074982 109.63000000000011 237.79500000000053 160.78500000000076
2.0 51.0 919.6979875564575 43.99000000000024 152.6450000000002 62.585000000000036
3.0 52.0 935.2633283138275 66.02500000000055 152.6450000000002 62.585000000000036
3.0 53.0 954.5641160011292 86.86999999999944 152.9000000000001 66.20000000000005
3.0 54.0 960.5970928668976 31.999999999999773 159.35499999999956 80.14499999999998
3.0 55.0 998.9634246826172 177.17500000000018 159.35499999999956 80.14499999999998
3.0 56.0 1011.0793931484222 176.6499999999994 159.35499999999956 80.14499999999998
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4543.38 242.38499999999954 304.3500000000006
0.0 1.0 6.40548300743103 88.90999999999894 200.96999999999935 180.85499999999956
0.0 2.0 10.763911008834839 47.47499999999991 178.97499999999945 184.95499999999993
0.0 3.0 17.98727035522461 247.74999999999955 178.97499999999945 184.95499999999993
0.0 4.0 23.571441888809204 73.97499999999991 176.3499999999999 131.10500000000002
0.0 5.0 29.444785594940186 17.134999999999764 211.82500000000073 61.934999999999945
0.0 6.0 35.61245608329773 57.70499999999947 158.76499999999987 43.72999999999956
0.0 7.0 42.2027862071991 326.7100000000005 158.76499999999987 43.72999999999956
0.0 8.0 48.178972244262695 36.1850000000004 232.57000000000016 115.28499999999985
0.0 9.0 53.321444511413574 130.61500000000024 150.98999999999955 70.73000000000002
0.0 10.0 69.16075682640076 171.02500000000032 150.98999999999955 70.73000000000002
0.0 11.0 76.10591697692871 113.97500000000036 150.98999999999955 70.73000000000002
0.0 12.0 92.78970193862915 239.75499999999965 150.98999999999955 70.73000000000002
0.0 13.0 98.71390414237976 210.1799999999996 150.98999999999955 70.73000000000002
0.0 14.0 103.68785667419434 76.0649999999996 150.98999999999955 70.73000000000002
0.0 15.0 109.83543562889099 110.40499999999975 153.19500000000016 62.914999999999736
0.0 16.0 116.71520256996155 391.5199999999995 266.9950000000008 101.33500000000004
0.0 17.0 191.97630286216736 285.74499999999944 266.9950000000008 101.33500000000004
1.0 18.0 202.74504375457764 117.12499999999955 199.32000000000016 45.30499999999938
1.0 19.0 226.4436388015747 352.03499999999985 203.83500000000026 51.22999999999956
1.0 20.0 351.97863841056824 367.99 203.83500000000026 51.22999999999956
1.0 21.0 471.48492193222046 285.16499999999974 203.83500000000026 51.22999999999956
1.0 22.0 494.79576420783997 98.82500000000027 157.97000000000048 84.7199999999998
1.0 23.0 643.7093646526337 79.50500000000011 157.97000000000048 84.7199999999998
1.0 24.0 651.3930695056915 51.88000000000011 169.35000000000036 47.664999999999964
1.0 25.0 773.6543996334076 101.59500000000025 169.35000000000036 47.664999999999964
1.0 26.0 1018.55526304245 155.69000000000028 169.35000000000036 47.664999999999964
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4601.28 182.42000000000007 99.0949999999998
0.0 1.0 5.941279411315918 72.49500000000035 221.38999999999965 140.36000000000013
0.0 2.0 11.682985544204712 58.375 251.48500000000035 174.51499999999987
0.0 3.0 17.448407649993896 290.65999999999985 251.48500000000035 174.51499999999987
0.0 4.0 21.78302025794983 46.495000000000346 263.885 68.82000000000016
0.0 5.0 31.192521810531616 143.76500000000033 283.43499999999926 64.19499999999994
0.0 6.0 36.04408097267151 57.48999999999978 316.4400000000003 98.49499999999944
0.0 7.0 53.68639802932739 458.74999999999955 316.4400000000003 98.49499999999944
0.0 8.0 59.516552686691284 93.0799999999997 212.6600000000003 114.08000000000038
0.0 9.0 63.61956572532654 161.1049999999991 244.01999999999953 80.07999999999993
0.0 10.0 70.30770778656006 196.8900000000001 244.01999999999953 80.07999999999993
0.0 11.0 76.00027537345886 196.8499999999999 244.01999999999953 80.07999999999993
0.0 12.0 83.93220806121826 646.8649999999998 244.01999999999953 80.07999999999993
0.0 13.0 93.51375675201416 267.56500000000005 244.01999999999953 80.07999999999993
0.0 14.0 98.85941123962402 300.9300000000003 297.96000000000004 108.20000000000027
0.0 15.0 105.5293345451355 178.54999999999927 283.43499999999926 101.33500000000004
0.0 16.0 110.62880444526672 402.22999999999956 261.2400000000007 155.68499999999995
0.0 17.0 115.45006084442139 202.14000000000033 261.2400000000007 155.68499999999995
1.0 18.0 119.85891056060791 180.54499999999962 258.2050000000004 182.99000000000024
1.0 19.0 125.33607292175293 398.5399999999995 238.9800000000007 164.7449999999999
1.0 20.0 129.66407775878906 365.9699999999998 238.9800000000007 164.7449999999999
1.0 21.0 135.78217315673828 285.9549999999999 238.9800000000007 164.7449999999999
1.0 22.0 141.41482305526733 116.67999999999984 219.115 123.38500000000022
1.0 23.0 145.94013619422913 58.674999999999955 219.115 123.38500000000022
1.0 24.0 150.67836236953735 84.48000000000093 240.49500000000035 86.86999999999989
1.0 25.0 175.87625789642334 169.61000000000035 240.49500000000035 86.86999999999989
1.0 26.0 187.9829878807068 207.59500000000003 240.49500000000035 86.86999999999989
1.0 27.0 200.22005677223206 68.83499999999958 176.8049999999996 164.51499999999987
1.0 28.0 219.74899172782898 143.76500000000033 190.14999999999986 123.38500000000022
1.0 29.0 224.26397728919983 177.4300000000003 190.14999999999986 123.38500000000022
1.0 30.0 229.67164397239685 92.78500000000031 320.29499999999985 437.6550000000002
1.0 31.0 235.38381934165955 178.62499999999977 320.29499999999985 362.15499999999884
1.0 32.0 243.12853908538818 203.6450000000002 320.29499999999985 362.15499999999884
1.0 33.0 250.22654843330383 50.845000000000255 272.4200000000003 131.9000000000001
1.0 34.0 548.7803950309753 37.63000000000011 266.2049999999995 99.44999999999982
2.0 35.0 955.352205991745 37.63000000000011 255.90999999999985 99.44999999999982
2.0 36.0 1122.8977274894714 310.4749999999999 194.17499999999927 122.41500000000042
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4647.05 165.74500000000035 87.39000000000033
0.0 1.0 6.666359186172485 27.854999999999563 181.25999999999976 87.39000000000033
0.0 2.0 11.625997066497803 45.69999999999982 212.6600000000003 124.90000000000009
0.0 3.0 16.841773509979248 384.1450000000002 212.6600000000003 124.90000000000009
0.0 4.0 21.983328819274902 70.03999999999951 173.74500000000057 82.36499999999978
0.0 5.0 27.08466410636902 123.19000000000005 158.07500000000005 82.36499999999978
0.0 6.0 32.40011262893677 139.51499999999987 177.32999999999925 94.67000000000007
0.0 7.0 39.48384165763855 503.47499999999945 177.32999999999925 94.67000000000007
0.0 8.0 44.18415856361389 35.27000000000021 158.54500000000007 114.66000000000031
0.0 9.0 49.806891441345215 146.625 177.3950000000002 124.90000000000009
0.0 10.0 56.67746329307556 197.98500000000035 177.3950000000002 124.90000000000009
0.0 11.0 62.86516094207764 213.08500000000004 177.3950000000002 124.90000000000009
0.0 12.0 69.60043597221375 381.30999999999995 177.3950000000002 124.90000000000009
0.0 13.0 75.36095523834229 239.37000000000012 177.3950000000002 124.90000000000009
0.0 14.0 80.88820934295654 171.26999999999953 168.80999999999972 89.03499999999985
0.0 15.0 86.1813132762909 89.79499999999916 132.91499999999996 127.36999999999989
0.0 16.0 91.46697926521301 621.0199999999995 307.9549999999997 205.85999999999967
0.0 17.0 101.33363318443298 257.23500000000035 307.9549999999997 205.85999999999967
1.0 18.0 111.83143973350525 99.39499999999998 179.72499999999968 143.54499999999962
1.0 19.0 119.70853281021118 539.5649999999996 199.96999999999957 185.32999999999947
1.0 20.0 132.78731608390808 329.1200000000001 199.96999999999957 185.32999999999947
1.0 21.0 139.73638200759888 127.00499999999988 199.96999999999957 185.32999999999947
1.0 22.0 147.44136571884155 285.41499999999974 241.38999999999987 162.27999999999975
1.0 23.0 161.6807417869568 336.81500000000005 241.38999999999987 162.27999999999975
1.0 24.0 191.42545771598816 109.48499999999967 196.90999999999963 123.49000000000024
1.0 25.0 273.7969317436218 284.98000000000025 196.90999999999963 123.49000000000024
1.0 26.0 315.4325532913208 279.5349999999996 196.90999999999963 123.49000000000024
1.0 27.0 322.0056302547455 45.775000000000546 181.5449999999994 101.52999999999975
1.0 28.0 329.21032762527466 336.10000000000036 193.60999999999967 100.50999999999976
1.0 29.0 345.2415144443512 205.66999999999985 193.60999999999967 100.50999999999976
1.0 30.0 428.58755803108215 139.51499999999987 218.87499999999955 126.01000000000022
1.0 31.0 776.8860619068146 250.40500000000043 182.28499999999985 114.66000000000031
1.0 32.0 1080.6107032299042 557.01 182.28499999999985 114.66000000000031
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4624.389999999999 189.11999999999944 92.17000000000007
0.0 1.0 5.564603567123413 27.854999999999563 181.48500000000013 47.874999999999545
0.0 2.0 10.72878384590149 42.94999999999982 160.1899999999996 49.379999999999654
0.0 3.0 17.343620777130127 286.9300000000003 160.1899999999996 49.379999999999654
0.0 4.0 22.287064790725708 70.61999999999989 179.34499999999957 64.19499999999994
0.0 5.0 27.897785902023315 22.639999999999418 171.3150000000005 49.22499999999991
0.0 6.0 33.84055209159851 41.61500000000069 196.14499999999998 51.22999999999956
0.0 7.0 39.805439949035645 252.05499999999984 196.14499999999998 51.22999999999956
0.0 8.0 45.545001745224 32.094999999999345 178.76499999999942 82.625
0.0 9.0 51.103675842285156 99.86499999999978 203.15000000000077 98.47499999999991
0.0 10.0 56.63527965545654 233.66499999999974 203.15000000000077 98.47499999999991
0.0 11.0 61.995683908462524 109.99000000000046 203.15000000000077 98.47499999999991
0.0 12.0 67.86743545532227 496.9199999999996 203.15000000000077 98.47499999999991
0.0 13.0 73.2881989479065 181.62000000000035 203.15000000000077 98.47499999999991
0.0 14.0 79.4580934047699 277.3299999999999 372.1349999999993 367.74999999999955
0.0 15.0 86.025075674057 126.78499999999985 215.93500000000017 115.03499999999985
0.0 16.0 90.87187600135803 398.5399999999995 142.10500000000002 83.00999999999976
0.0 17.0 96.05625629425049 133.89999999999986 142.10500000000002 83.00999999999976
1.0 18.0 100.52971839904785 157.0899999999997 128.94000000000028 83.00999999999976
1.0 19.0 105.02122378349304 402.22999999999956 186.63499999999976 107.30000000000018
1.0 20.0 109.87235379219055 266.4999999999998 186.63499999999976 107.30000000000018
1.0 21.0 114.24137449264526 286.6099999999997 186.63499999999976 107.30000000000018
1.0 22.0 119.03206586837769 121.01499999999965 181.76999999999953 139.48999999999978
1.0 23.0 124.15876698493958 91.75999999999954 181.76999999999953 139.48999999999978
1.0 24.0 128.83654499053955 171.19500000000016 266.05499999999984 155.1949999999997
1.0 25.0 133.55540490150452 285.2099999999998 266.05499999999984 155.1949999999997
1.0 26.0 138.77300596237183 194.15000000000032 266.05499999999984 155.1949999999997
1.0 27.0 143.8205873966217 67.57999999999947 235.70500000000015 154.52499999999964
1.0 28.0 200.66046333312988 84.375 381.8149999999998 209.25
1.0 29.0 209.62932419776917 384.0749999999996 381.8149999999998 209.25
1.0 30.0 222.11139488220215 54.66499999999951 201.2100000000005 80.07999999999993
1.0 31.0 230.3801727294922 155.29999999999927 199.6900000000005 84.33500000000004
1.0 32.0 237.0156602859497 423.24000000000024 199.6900000000005 84.33500000000004
1.0 33.0 297.92377066612244 61.57999999999993 203.83999999999992 73.08999999999992
1.0 34.0 304.473596572876 50.32499999999982 268.8149999999998 99.14499999999953
2.0 35.0 310.9239242076874 50.32499999999982 268.8149999999998 99.14499999999953
2.0 36.0 316.6229329109192 398.5399999999995 192.13499999999976 136.44999999999982
2.0 37.0 331.7892587184906 85.68999999999983 192.13499999999976 136.44999999999982
2.0 38.0 514.3752806186676 66.00499999999965 204.40000000000032 74.79999999999995
2.0 39.0 697.2693734169006 26.414999999999964 201.6700000000003 74.79999999999995
2.0 40.0 755.4971141815186 147.54999999999995 201.6700000000003 74.79999999999995
2.0 41.0 936.5461168289185 137.65499999999997 260.2550000000001 98.49499999999944
2.0 42.0 1096.5640029907227 66.52500000000009 266.2049999999995 98.49499999999944
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4561.75 225.2950000000003 65.39500000000021
0.0 1.0 5.791274547576904 24.7199999999998 190.8150000000005 83.68000000000029
0.0 2.0 11.036408185958862 50.225000000000136 239.89000000000055 68.02499999999986
0.0 3.0 15.95903754234314 370.93000000000006 239.89000000000055 68.02499999999986
0.0 4.0 21.102136850357056 64.01499999999942 231.60000000000082 94.67000000000007
0.0 5.0 27.213399410247803 93.72499999999945 212.6600000000003 94.67000000000007
0.0 6.0 33.49035167694092 101.86999999999944 192.1049999999991 89.03499999999985
0.0 7.0 40.94658970832825 489.93000000000006 192.1049999999991 89.03499999999985
0.0 8.0 46.817134380340576 90.8449999999998 187.74499999999944 120.53500000000031
0.0 9.0 52.23271298408508 134.6400000000001 199.43999999999937 126.01000000000022
0.0 10.0 58.20960855484009 125.3100000000004 199.43999999999937 126.01000000000022
0.0 11.0 64.0180766582489 168.95500000000015 199.43999999999937 126.01000000000022
0.0 12.0 69.88968825340271 516.8100000000002 199.43999999999937 126.01000000000022
0.0 13.0 75.12384819984436 248.86999999999966 199.43999999999937 126.01000000000022
0.0 14.0 80.63733696937561 65.92000000000053 220.7249999999999 45.30499999999938
0.0 15.0 86.27164888381958 104.57499999999936 277.02499999999986 57.84499999999957
0.0 16.0 91.84608697891235 310.8500000000006 190.9100000000003 89.03499999999985
0.0 17.0 102.37292098999023 225.51000000000022 190.9100000000003 89.03499999999985
1.0 18.0 107.78650999069214 66.00499999999965 351.98999999999955 105.18499999999995
1.0 19.0 114.08350372314453 407.2099999999991 183.08999999999992 141.04999999999882
1.0 20.0 128.96804022789001 503.7449999999999 183.08999999999992 141.04999999999882
1.0 21.0 134.40987062454224 348.0649999999996 183.08999999999992 141.04999999999882
1.0 22.0 139.8862648010254 137.65499999999997 199.03500000000054 139.24999999999955
1.0 23.0 174.29581499099731 141.13499999999976 199.03500000000054 139.24999999999955
1.0 24.0 180.52128911018372 79.75500000000011 192.42999999999984 139.24999999999955
1.0 25.0 187.0850613117218 161.99999999999977 192.42999999999984 139.24999999999955
1.0 26.0 243.79352855682373 104.42000000000007 192.42999999999984 139.24999999999955
1.0 27.0 249.2440948486328 112.79999999999973 192.42999999999984 139.24999999999955
1.0 28.0 424.6715421676636 21.69499999999971 346.47500000000036 112.99000000000024
1.0 29.0 581.9719955921173 456.67999999999984 346.47500000000036 112.99000000000024
1.0 30.0 644.2020933628082 59.46499999999969 195.47499999999968 113.96000000000004
1.0 31.0 925.752818107605 185.9849999999999 196.74500000000012 84.33500000000004
1.0 32.0 1087.4480135440826 419.0750000000003 196.74500000000012 84.33500000000004
Method "Max Step Size Order" "Min Step Size Order" "Run Time Limit" "Epoch Limit" "Mini Batch Size" "Learning rate" Parallelism Bias "L2 Lambda"
DIVIDE_AND_CONQUER 0 -1 1000 10 32 1 True False 0.001
epochs "sub epochs" "run time" "training objective" "test regret" "val regret" pred_Ys
0.0 0.0 0.0 4572.66 184.7899999999995 106.48500000000013
0.0 1.0 5.480476140975952 45.775000000000546 220.99499999999944 74.10000000000036
0.0 2.0 10.469762086868286 48.10500000000002 184.7899999999995 47.874999999999545
0.0 3.0 15.391479730606079 321.18499999999995 184.7899999999995 47.874999999999545
0.0 4.0 20.95144557952881 70.03999999999951 184.7899999999995 95.19999999999982
0.0 5.0 26.310131549835205 104.52500000000009 168.37499999999955 61.24499999999989
0.0 6.0 31.817461729049683 97.01999999999998 177.0249999999994 50.375
0.0 7.0 37.15255045890808 282.1350000000002 177.0249999999994 50.375
0.0 8.0 42.19848942756653 38.29500000000007 181.20000000000005 164.00500000000056
0.0 9.0 47.41215252876282 139.57000000000016 199.32000000000062 116.67999999999984
0.0 10.0 55.214635610580444 202.28999999999974 199.32000000000062 116.67999999999984
0.0 11.0 60.59730648994446 108.81500000000028 199.32000000000062 116.67999999999984
0.0 12.0 67.73018217086792 354.24000000000024 199.32000000000062 116.67999999999984
0.0 13.0 72.62591338157654 168.64999999999918 199.32000000000062 116.67999999999984
0.0 14.0 78.05829501152039 70.83000000000038 148.93500000000017 99.0949999999998
0.0 15.0 87.23594617843628 183.89499999999998 145.22000000000025 123.94500000000016
0.0 16.0 92.33298325538635 701.8699999999994 427.0500000000004 324.8050000000003
0.0 17.0 97.35017657279968 350.7500000000002 427.0500000000004 324.8050000000003
1.0 18.0 104.47593283653259 136.3399999999997 245.98500000000013 193.03499999999985
1.0 19.0 125.64948105812073 524.3200000000002 250.92500000000018 231.4699999999998
1.0 20.0 225.5997564792633 367.96000000000004 250.92500000000018 231.4699999999998
1.0 21.0 377.8245904445648 294.5749999999998 250.92500000000018 231.4699999999998
1.0 22.0 489.5509285926819 253.35000000000036 193.2249999999999 167.35500000000002
1.0 23.0 583.5408368110657 213.85999999999967 193.2249999999999 167.35500000000002
1.0 24.0 800.8858227729797 82.20499999999993 193.2249999999999 166.875
1.0 25.0 1286.376886844635 276.56999999999994 193.2249999999999 166.875
